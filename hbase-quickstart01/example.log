[2017-05-18 20:56:15,588][main][INFO ]:Process identifier=hconnection-0x5810d963 connecting to ZooKeeper ensemble=localhost:2181
[2017-05-18 20:56:15,620][main][INFO ]:Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
[2017-05-18 20:56:15,620][main][INFO ]:Client environment:host.name=FANGMING-THINK
[2017-05-18 20:56:15,621][main][INFO ]:Client environment:java.version=1.7.0_79
[2017-05-18 20:56:15,621][main][INFO ]:Client environment:java.vendor=Oracle Corporation
[2017-05-18 20:56:15,621][main][INFO ]:Client environment:java.home=C:\Program Files\Java\jdk7\jre
[2017-05-18 20:56:15,622][main][INFO ]:Client environment:java.class.path=D:\dev\java\workspaces\hadoop\hbase-quickstart01\target\test-classes;D:\dev\java\workspaces\hadoop\hbase-quickstart01\target\classes;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-client\1.3.1\hbase-client-1.3.1.jar;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-annotations\1.3.1\hbase-annotations-1.3.1.jar;C:\Users\FangMing\.m2\repository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;C:\Users\FangMing\.m2\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-common\1.3.1\hbase-common-1.3.1.jar;C:\Users\FangMing\.m2\repository\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;C:\Users\FangMing\.m2\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-protocol\1.3.1\hbase-protocol-1.3.1.jar;C:\Users\FangMing\.m2\repository\commons-codec\commons-codec\1.9\commons-codec-1.9.jar;C:\Users\FangMing\.m2\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;C:\Users\FangMing\.m2\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;C:\Users\FangMing\.m2\repository\commons-logging\commons-logging\1.2\commons-logging-1.2.jar;C:\Users\FangMing\.m2\repository\com\google\guava\guava\12.0.1\guava-12.0.1.jar;C:\Users\FangMing\.m2\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;C:\Users\FangMing\.m2\repository\io\netty\netty-all\4.0.23.Final\netty-all-4.0.23.Final.jar;C:\Users\FangMing\.m2\repository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;C:\Users\FangMing\.m2\repository\org\slf4j\slf4j-api\1.6.1\slf4j-api-1.6.1.jar;C:\Users\FangMing\.m2\repository\org\slf4j\slf4j-log4j12\1.6.1\slf4j-log4j12-1.6.1.jar;C:\Users\FangMing\.m2\repository\org\apache\htrace\htrace-core\3.1.0-incubating\htrace-core-3.1.0-incubating.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jackson\jackson-mapper-asl\1.9.13\jackson-mapper-asl-1.9.13.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;C:\Users\FangMing\.m2\repository\org\jruby\jcodings\jcodings\1.0.8\jcodings-1.0.8.jar;C:\Users\FangMing\.m2\repository\org\jruby\joni\joni\2.1.2\joni-2.1.2.jar;C:\Users\FangMing\.m2\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-auth\2.5.1\hadoop-auth-2.5.1.jar;C:\Users\FangMing\.m2\repository\org\apache\httpcomponents\httpclient\4.2.5\httpclient-4.2.5.jar;C:\Users\FangMing\.m2\repository\org\apache\httpcomponents\httpcore\4.2.4\httpcore-4.2.4.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\server\apacheds-kerberos-codec\2.0.0-M15\apacheds-kerberos-codec-2.0.0-M15.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\server\apacheds-i18n\2.0.0-M15\apacheds-i18n-2.0.0-M15.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\api\api-asn1-api\1.0.0-M20\api-asn1-api-1.0.0-M20.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\api\api-util\1.0.0-M20\api-util-1.0.0-M20.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-common\2.5.1\hadoop-common-2.5.1.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-annotations\2.5.1\hadoop-annotations-2.5.1.jar;C:\Users\FangMing\.m2\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;C:\Users\FangMing\.m2\repository\org\apache\commons\commons-math3\3.1.1\commons-math3-3.1.1.jar;C:\Users\FangMing\.m2\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;C:\Users\FangMing\.m2\repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;C:\Users\FangMing\.m2\repository\commons-net\commons-net\3.1\commons-net-3.1.jar;C:\Users\FangMing\.m2\repository\commons-el\commons-el\1.0\commons-el-1.0.jar;C:\Users\FangMing\.m2\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;C:\Users\FangMing\.m2\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;C:\Users\FangMing\.m2\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;C:\Users\FangMing\.m2\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;C:\Users\FangMing\.m2\repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;C:\Users\FangMing\.m2\repository\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;C:\Users\FangMing\.m2\repository\org\xerial\snappy\snappy-java\1.0.4.1\snappy-java-1.0.4.1.jar;C:\Users\FangMing\.m2\repository\com\jcraft\jsch\0.1.42\jsch-0.1.42.jar;C:\Users\FangMing\.m2\repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;C:\Users\FangMing\.m2\repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;C:\Users\FangMing\.m2\repository\org\tukaani\xz\1.0\xz-1.0.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.5.1\hadoop-mapreduce-client-core-2.5.1.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-yarn-common\2.5.1\hadoop-yarn-common-2.5.1.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-yarn-api\2.5.1\hadoop-yarn-api-2.5.1.jar;C:\Users\FangMing\.m2\repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;C:\Users\FangMing\.m2\repository\javax\xml\stream\stax-api\1.0-2\stax-api-1.0-2.jar;C:\Users\FangMing\.m2\repository\javax\activation\activation\1.1\activation-1.1.jar;C:\Users\FangMing\.m2\repository\io\netty\netty\3.6.2.Final\netty-3.6.2.Final.jar;C:\Program Files\Java\jdk\lib\tools.jar;C:\Users\FangMing\.m2\repository\junit\junit\4.12\junit-4.12.jar;C:\Users\FangMing\.m2\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;/D:/dev/java/eclipseNeon2/eclipse/configuration/org.eclipse.osgi/389/0/.cp/;/D:/dev/java/eclipseNeon2/eclipse/configuration/org.eclipse.osgi/388/0/.cp/
[2017-05-18 20:56:15,624][main][INFO ]:Client environment:java.library.path=C:\Program Files\Java\jdk7\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:/Program Files/Java/jre/bin/server;C:/Program Files/Java/jre/bin;C:/Program Files/Java/jre/lib/amd64;.;D:\dev\java\libs\hadoop\hadoop-2.7.3\bin;C:\ProgramData\Oracle\Java\javapath;D:\Dev\scripts;E:\study\maven\apache-maven-3.3.9\bin;e:\study\groovy\groovy-2.4.6\bin;E:/study/gradle/gradle-default/bin;C:\Program Files\Java\jdk\bin;E:\Study\ant\apache-ant-1.9.2\bin;C:\oracle\product\11.2.0\client_1;C:\oracle\product\11.2.0\client_1\bin;C:\Program Files (x86)\AMD APP\bin\x86_64;C:\Program Files (x86)\AMD APP\bin\x86;C:\Program Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\Microsoft SQL Server\100\Tools\Binn\;C:\Program Files\Microsoft SQL Server\100\Tools\Binn\;C:\Program Files\Microsoft SQL Server\100\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\100\Tools\Binn\VSShell\Common7\IDE\;C:\Program Files (x86)\Microsoft SQL Server\100\DTS\Binn\;C:\Program Files (x86)\Microsoft Visual Studio 9.0\Common7\IDE\PrivateAssemblies\;C:\Program Files\TortoiseSVN\bin;C:\Program Files\ThinkPad\Bluetooth Software\;C:\Program Files\ThinkPad\Bluetooth Software\syswow64;C:\Program Files\VisualSVN Server\bin;C:\Program Files\Git\cmd;C:\Users\FangMing\AppData\Local\Programs\Python\Python36\Scripts\;C:\Users\FangMing\AppData\Local\Programs\Python\Python36\;D:\dev\java\eclipseNeon2\eclipse;;.
[2017-05-18 20:56:15,625][main][INFO ]:Client environment:java.io.tmpdir=C:\Users\FangMing\AppData\Local\Temp\
[2017-05-18 20:56:15,626][main][INFO ]:Client environment:java.compiler=<NA>
[2017-05-18 20:56:15,626][main][INFO ]:Client environment:os.name=Windows 7
[2017-05-18 20:56:15,626][main][INFO ]:Client environment:os.arch=amd64
[2017-05-18 20:56:15,627][main][INFO ]:Client environment:os.version=6.1
[2017-05-18 20:56:15,627][main][INFO ]:Client environment:user.name=FangMing
[2017-05-18 20:56:15,627][main][INFO ]:Client environment:user.home=C:\Users\FangMing
[2017-05-18 20:56:15,628][main][INFO ]:Client environment:user.dir=D:\dev\java\workspaces\hadoop\hbase-quickstart01
[2017-05-18 20:56:15,635][main][INFO ]:Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@5449a5ba
[2017-05-18 20:56:16,030][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 20:56:17,039][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 20:56:18,279][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 20:56:19,281][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 20:56:20,382][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 20:56:21,384][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 20:56:22,486][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 20:56:23,488][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 20:56:24,589][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 20:56:25,596][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 20:56:26,697][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 20:56:27,699][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 20:56:28,800][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 20:56:29,803][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 20:56:30,910][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 20:56:32,056][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 20:56:33,161][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 20:56:34,167][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 20:56:34,296][main][ERROR]:ZooKeeper exists failed after 4 attempts
[2017-05-18 20:56:34,297][main][WARN ]:hconnection-0x5810d9630x0, quorum=localhost:2181, baseZNode=/hbase Unable to set watcher on znode (/hbase/hbaseid)
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/hbaseid
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.exists(ZooKeeper.java:1045)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.exists(RecoverableZooKeeper.java:220)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.checkExists(ZKUtil.java:420)
	at org.apache.hadoop.hbase.zookeeper.ZKClusterId.readClusterIdZNode(ZKClusterId.java:65)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getClusterId(ZooKeeperRegistry.java:105)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.retrieveClusterId(ConnectionManager.java:907)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.<init>(ConnectionManager.java:691)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:238)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:218)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:119)
	at com.fsmflying.hbase01.HbaseTest01.before(HbaseTest01.java:35)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:86)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:459)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:678)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192)
[2017-05-18 20:56:34,303][main][ERROR]:hconnection-0x5810d9630x0, quorum=localhost:2181, baseZNode=/hbase Received unexpected KeeperException, re-throwing exception
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/hbaseid
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.exists(ZooKeeper.java:1045)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.exists(RecoverableZooKeeper.java:220)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.checkExists(ZKUtil.java:420)
	at org.apache.hadoop.hbase.zookeeper.ZKClusterId.readClusterIdZNode(ZKClusterId.java:65)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getClusterId(ZooKeeperRegistry.java:105)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.retrieveClusterId(ConnectionManager.java:907)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.<init>(ConnectionManager.java:691)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:238)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:218)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:119)
	at com.fsmflying.hbase01.HbaseTest01.before(HbaseTest01.java:35)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:86)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:459)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:678)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192)
[2017-05-18 20:56:34,308][main][WARN ]:Can't retrieve clusterId from Zookeeper
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/hbaseid
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.exists(ZooKeeper.java:1045)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.exists(RecoverableZooKeeper.java:220)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.checkExists(ZKUtil.java:420)
	at org.apache.hadoop.hbase.zookeeper.ZKClusterId.readClusterIdZNode(ZKClusterId.java:65)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getClusterId(ZooKeeperRegistry.java:105)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.retrieveClusterId(ConnectionManager.java:907)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.<init>(ConnectionManager.java:691)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:238)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:218)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:119)
	at com.fsmflying.hbase01.HbaseTest01.before(HbaseTest01.java:35)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:86)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:459)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:678)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192)
[2017-05-18 20:56:35,296][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 20:56:36,297][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 20:56:37,398][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 20:56:38,407][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 20:56:39,543][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 20:56:40,547][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 20:56:41,650][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 20:56:42,652][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 20:56:43,753][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 20:56:44,753][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 20:56:46,031][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 20:56:47,034][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 20:56:48,135][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 20:56:49,137][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 20:56:50,238][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 20:56:51,238][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 20:56:52,339][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 20:56:53,341][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 20:56:53,442][main][ERROR]:ZooKeeper getData failed after 4 attempts
[2017-05-18 20:56:53,442][main][WARN ]:hconnection-0x5810d9630x0, quorum=localhost:2181, baseZNode=/hbase Unable to get data of znode /hbase/meta-region-server
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/meta-region-server
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.getData(RecoverableZooKeeper.java:354)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.getData(ZKUtil.java:624)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.getMetaRegionState(MetaTableLocator.java:486)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.getMetaRegionLocation(MetaTableLocator.java:167)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:606)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:587)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:560)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getMetaRegionLocation(ZooKeeperRegistry.java:61)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateMeta(ConnectionManager.java:1213)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateRegion(ConnectionManager.java:1180)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas.getRegionLocations(RpcRetryingCallerWithReadReplicas.java:305)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:156)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:60)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:212)
	at org.apache.hadoop.hbase.client.ClientScanner.call(ClientScanner.java:314)
	at org.apache.hadoop.hbase.client.ClientScanner.nextScanner(ClientScanner.java:289)
	at org.apache.hadoop.hbase.client.ClientScanner.initializeScannerInConstruction(ClientScanner.java:164)
	at org.apache.hadoop.hbase.client.ClientScanner.<init>(ClientScanner.java:159)
	at org.apache.hadoop.hbase.client.HTable.getScanner(HTable.java:796)
	at org.apache.hadoop.hbase.MetaTableAccessor.fullScan(MetaTableAccessor.java:602)
	at org.apache.hadoop.hbase.MetaTableAccessor.tableExists(MetaTableAccessor.java:366)
	at org.apache.hadoop.hbase.client.HBaseAdmin.tableExists(HBaseAdmin.java:408)
	at com.fsmflying.hbase01.HbaseTest01.test01_createTables(HbaseTest01.java:57)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:86)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:459)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:678)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192)
[2017-05-18 20:56:53,444][main][ERROR]:hconnection-0x5810d9630x0, quorum=localhost:2181, baseZNode=/hbase Received unexpected KeeperException, re-throwing exception
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/meta-region-server
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.getData(RecoverableZooKeeper.java:354)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.getData(ZKUtil.java:624)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.getMetaRegionState(MetaTableLocator.java:486)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.getMetaRegionLocation(MetaTableLocator.java:167)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:606)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:587)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:560)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getMetaRegionLocation(ZooKeeperRegistry.java:61)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateMeta(ConnectionManager.java:1213)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateRegion(ConnectionManager.java:1180)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas.getRegionLocations(RpcRetryingCallerWithReadReplicas.java:305)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:156)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:60)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:212)
	at org.apache.hadoop.hbase.client.ClientScanner.call(ClientScanner.java:314)
	at org.apache.hadoop.hbase.client.ClientScanner.nextScanner(ClientScanner.java:289)
	at org.apache.hadoop.hbase.client.ClientScanner.initializeScannerInConstruction(ClientScanner.java:164)
	at org.apache.hadoop.hbase.client.ClientScanner.<init>(ClientScanner.java:159)
	at org.apache.hadoop.hbase.client.HTable.getScanner(HTable.java:796)
	at org.apache.hadoop.hbase.MetaTableAccessor.fullScan(MetaTableAccessor.java:602)
	at org.apache.hadoop.hbase.MetaTableAccessor.tableExists(MetaTableAccessor.java:366)
	at org.apache.hadoop.hbase.client.HBaseAdmin.tableExists(HBaseAdmin.java:408)
	at com.fsmflying.hbase01.HbaseTest01.test01_createTables(HbaseTest01.java:57)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:86)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:459)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:678)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192)
[2017-05-18 20:56:54,442][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 20:56:55,443][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 20:56:56,546][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 20:56:57,547][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 20:56:58,648][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 20:56:59,648][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 20:57:00,749][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 20:57:01,770][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 20:57:02,871][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 20:57:04,088][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 20:57:05,189][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 20:57:06,183][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 20:57:07,283][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 20:57:08,284][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 20:57:09,385][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 20:57:10,385][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 20:57:11,486][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 20:57:12,482][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 20:57:12,585][main][ERROR]:ZooKeeper getData failed after 4 attempts
[2017-05-18 20:57:12,586][main][WARN ]:hconnection-0x5810d9630x0, quorum=localhost:2181, baseZNode=/hbase Unable to get data of znode /hbase/meta-region-server
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/meta-region-server
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.getData(RecoverableZooKeeper.java:354)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.getData(ZKUtil.java:624)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.getMetaRegionState(MetaTableLocator.java:486)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.getMetaRegionLocation(MetaTableLocator.java:167)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:606)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:587)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:560)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getMetaRegionLocation(ZooKeeperRegistry.java:61)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateMeta(ConnectionManager.java:1213)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateRegion(ConnectionManager.java:1180)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas.getRegionLocations(RpcRetryingCallerWithReadReplicas.java:305)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:156)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:60)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:212)
	at org.apache.hadoop.hbase.client.ClientScanner.call(ClientScanner.java:314)
	at org.apache.hadoop.hbase.client.ClientScanner.nextScanner(ClientScanner.java:289)
	at org.apache.hadoop.hbase.client.ClientScanner.initializeScannerInConstruction(ClientScanner.java:164)
	at org.apache.hadoop.hbase.client.ClientScanner.<init>(ClientScanner.java:159)
	at org.apache.hadoop.hbase.client.HTable.getScanner(HTable.java:796)
	at org.apache.hadoop.hbase.MetaTableAccessor.fullScan(MetaTableAccessor.java:602)
	at org.apache.hadoop.hbase.MetaTableAccessor.tableExists(MetaTableAccessor.java:366)
	at org.apache.hadoop.hbase.client.HBaseAdmin.tableExists(HBaseAdmin.java:408)
	at com.fsmflying.hbase01.HbaseTest01.test01_createTables(HbaseTest01.java:57)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:86)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:459)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:678)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192)
[2017-05-18 20:57:12,587][main][ERROR]:hconnection-0x5810d9630x0, quorum=localhost:2181, baseZNode=/hbase Received unexpected KeeperException, re-throwing exception
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/meta-region-server
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.getData(RecoverableZooKeeper.java:354)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.getData(ZKUtil.java:624)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.getMetaRegionState(MetaTableLocator.java:486)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.getMetaRegionLocation(MetaTableLocator.java:167)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:606)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:587)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:560)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getMetaRegionLocation(ZooKeeperRegistry.java:61)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateMeta(ConnectionManager.java:1213)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateRegion(ConnectionManager.java:1180)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas.getRegionLocations(RpcRetryingCallerWithReadReplicas.java:305)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:156)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:60)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:212)
	at org.apache.hadoop.hbase.client.ClientScanner.call(ClientScanner.java:314)
	at org.apache.hadoop.hbase.client.ClientScanner.nextScanner(ClientScanner.java:289)
	at org.apache.hadoop.hbase.client.ClientScanner.initializeScannerInConstruction(ClientScanner.java:164)
	at org.apache.hadoop.hbase.client.ClientScanner.<init>(ClientScanner.java:159)
	at org.apache.hadoop.hbase.client.HTable.getScanner(HTable.java:796)
	at org.apache.hadoop.hbase.MetaTableAccessor.fullScan(MetaTableAccessor.java:602)
	at org.apache.hadoop.hbase.MetaTableAccessor.tableExists(MetaTableAccessor.java:366)
	at org.apache.hadoop.hbase.client.HBaseAdmin.tableExists(HBaseAdmin.java:408)
	at com.fsmflying.hbase01.HbaseTest01.test01_createTables(HbaseTest01.java:57)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:86)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:459)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:678)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192)
[2017-05-18 20:57:13,586][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 20:57:14,596][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 20:57:15,701][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 20:57:16,702][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 20:57:17,803][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 20:57:18,804][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 20:57:19,904][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 20:57:20,905][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 20:57:22,010][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 20:57:23,011][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 20:57:24,145][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 20:57:25,146][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 20:57:26,247][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 20:57:27,250][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 20:57:28,350][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 20:57:29,351][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 20:57:30,452][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 20:57:31,455][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 20:57:31,555][main][ERROR]:ZooKeeper getData failed after 4 attempts
[2017-05-18 20:57:31,555][main][WARN ]:hconnection-0x5810d9630x0, quorum=localhost:2181, baseZNode=/hbase Unable to get data of znode /hbase/meta-region-server
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/meta-region-server
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.getData(RecoverableZooKeeper.java:354)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.getData(ZKUtil.java:624)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.getMetaRegionState(MetaTableLocator.java:486)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.getMetaRegionLocation(MetaTableLocator.java:167)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:606)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:587)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:560)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getMetaRegionLocation(ZooKeeperRegistry.java:61)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateMeta(ConnectionManager.java:1213)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateRegion(ConnectionManager.java:1180)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas.getRegionLocations(RpcRetryingCallerWithReadReplicas.java:305)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:156)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:60)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:212)
	at org.apache.hadoop.hbase.client.ClientScanner.call(ClientScanner.java:314)
	at org.apache.hadoop.hbase.client.ClientScanner.nextScanner(ClientScanner.java:289)
	at org.apache.hadoop.hbase.client.ClientScanner.initializeScannerInConstruction(ClientScanner.java:164)
	at org.apache.hadoop.hbase.client.ClientScanner.<init>(ClientScanner.java:159)
	at org.apache.hadoop.hbase.client.HTable.getScanner(HTable.java:796)
	at org.apache.hadoop.hbase.MetaTableAccessor.fullScan(MetaTableAccessor.java:602)
	at org.apache.hadoop.hbase.MetaTableAccessor.tableExists(MetaTableAccessor.java:366)
	at org.apache.hadoop.hbase.client.HBaseAdmin.tableExists(HBaseAdmin.java:408)
	at com.fsmflying.hbase01.HbaseTest01.test01_createTables(HbaseTest01.java:57)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:86)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:459)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:678)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192)
[2017-05-18 20:57:31,557][main][ERROR]:hconnection-0x5810d9630x0, quorum=localhost:2181, baseZNode=/hbase Received unexpected KeeperException, re-throwing exception
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/meta-region-server
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.getData(RecoverableZooKeeper.java:354)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.getData(ZKUtil.java:624)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.getMetaRegionState(MetaTableLocator.java:486)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.getMetaRegionLocation(MetaTableLocator.java:167)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:606)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:587)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:560)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getMetaRegionLocation(ZooKeeperRegistry.java:61)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateMeta(ConnectionManager.java:1213)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateRegion(ConnectionManager.java:1180)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas.getRegionLocations(RpcRetryingCallerWithReadReplicas.java:305)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:156)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:60)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:212)
	at org.apache.hadoop.hbase.client.ClientScanner.call(ClientScanner.java:314)
	at org.apache.hadoop.hbase.client.ClientScanner.nextScanner(ClientScanner.java:289)
	at org.apache.hadoop.hbase.client.ClientScanner.initializeScannerInConstruction(ClientScanner.java:164)
	at org.apache.hadoop.hbase.client.ClientScanner.<init>(ClientScanner.java:159)
	at org.apache.hadoop.hbase.client.HTable.getScanner(HTable.java:796)
	at org.apache.hadoop.hbase.MetaTableAccessor.fullScan(MetaTableAccessor.java:602)
	at org.apache.hadoop.hbase.MetaTableAccessor.tableExists(MetaTableAccessor.java:366)
	at org.apache.hadoop.hbase.client.HBaseAdmin.tableExists(HBaseAdmin.java:408)
	at com.fsmflying.hbase01.HbaseTest01.test01_createTables(HbaseTest01.java:57)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:86)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:459)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:678)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192)
[2017-05-18 20:57:32,556][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 20:57:33,557][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 20:57:34,657][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 20:57:35,657][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 20:57:36,758][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 20:57:37,819][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 20:57:38,920][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 20:57:39,921][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 20:57:41,022][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 20:57:42,022][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 20:57:43,123][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 20:57:44,123][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 20:57:45,224][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 20:57:46,226][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 20:57:47,327][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 20:57:48,322][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 20:57:49,422][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 20:57:50,427][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 20:57:50,530][main][ERROR]:ZooKeeper getData failed after 4 attempts
[2017-05-18 20:57:50,531][main][WARN ]:hconnection-0x5810d9630x0, quorum=localhost:2181, baseZNode=/hbase Unable to get data of znode /hbase/meta-region-server
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/meta-region-server
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.getData(RecoverableZooKeeper.java:354)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.getData(ZKUtil.java:624)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.getMetaRegionState(MetaTableLocator.java:486)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.getMetaRegionLocation(MetaTableLocator.java:167)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:606)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:587)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:560)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getMetaRegionLocation(ZooKeeperRegistry.java:61)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateMeta(ConnectionManager.java:1213)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateRegion(ConnectionManager.java:1180)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas.getRegionLocations(RpcRetryingCallerWithReadReplicas.java:305)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:156)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:60)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:212)
	at org.apache.hadoop.hbase.client.ClientScanner.call(ClientScanner.java:314)
	at org.apache.hadoop.hbase.client.ClientScanner.nextScanner(ClientScanner.java:289)
	at org.apache.hadoop.hbase.client.ClientScanner.initializeScannerInConstruction(ClientScanner.java:164)
	at org.apache.hadoop.hbase.client.ClientScanner.<init>(ClientScanner.java:159)
	at org.apache.hadoop.hbase.client.HTable.getScanner(HTable.java:796)
	at org.apache.hadoop.hbase.MetaTableAccessor.fullScan(MetaTableAccessor.java:602)
	at org.apache.hadoop.hbase.MetaTableAccessor.tableExists(MetaTableAccessor.java:366)
	at org.apache.hadoop.hbase.client.HBaseAdmin.tableExists(HBaseAdmin.java:408)
	at com.fsmflying.hbase01.HbaseTest01.test01_createTables(HbaseTest01.java:57)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:86)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:459)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:678)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192)
[2017-05-18 20:57:50,532][main][ERROR]:hconnection-0x5810d9630x0, quorum=localhost:2181, baseZNode=/hbase Received unexpected KeeperException, re-throwing exception
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/meta-region-server
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.getData(RecoverableZooKeeper.java:354)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.getData(ZKUtil.java:624)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.getMetaRegionState(MetaTableLocator.java:486)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.getMetaRegionLocation(MetaTableLocator.java:167)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:606)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:587)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:560)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getMetaRegionLocation(ZooKeeperRegistry.java:61)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateMeta(ConnectionManager.java:1213)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateRegion(ConnectionManager.java:1180)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas.getRegionLocations(RpcRetryingCallerWithReadReplicas.java:305)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:156)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:60)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:212)
	at org.apache.hadoop.hbase.client.ClientScanner.call(ClientScanner.java:314)
	at org.apache.hadoop.hbase.client.ClientScanner.nextScanner(ClientScanner.java:289)
	at org.apache.hadoop.hbase.client.ClientScanner.initializeScannerInConstruction(ClientScanner.java:164)
	at org.apache.hadoop.hbase.client.ClientScanner.<init>(ClientScanner.java:159)
	at org.apache.hadoop.hbase.client.HTable.getScanner(HTable.java:796)
	at org.apache.hadoop.hbase.MetaTableAccessor.fullScan(MetaTableAccessor.java:602)
	at org.apache.hadoop.hbase.MetaTableAccessor.tableExists(MetaTableAccessor.java:366)
	at org.apache.hadoop.hbase.client.HBaseAdmin.tableExists(HBaseAdmin.java:408)
	at com.fsmflying.hbase01.HbaseTest01.test01_createTables(HbaseTest01.java:57)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:86)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:459)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:678)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192)
[2017-05-18 20:57:50,922][main][INFO ]:Closing zookeeper sessionid=0x0
[2017-05-18 20:57:51,530][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 20:57:52,632][main][INFO ]:Session: 0x0 closed
[2017-05-18 20:57:52,632][main-EventThread][INFO ]:EventThread shut down
[2017-05-18 21:04:57,870][main][INFO ]:Process identifier=hconnection-0x28b2eca9 connecting to ZooKeeper ensemble=localhost:2181
[2017-05-18 21:04:57,893][main][INFO ]:Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
[2017-05-18 21:04:57,893][main][INFO ]:Client environment:host.name=FANGMING-THINK
[2017-05-18 21:04:57,894][main][INFO ]:Client environment:java.version=1.7.0_79
[2017-05-18 21:04:57,894][main][INFO ]:Client environment:java.vendor=Oracle Corporation
[2017-05-18 21:04:57,894][main][INFO ]:Client environment:java.home=C:\Program Files\Java\jdk7\jre
[2017-05-18 21:04:57,894][main][INFO ]:Client environment:java.class.path=D:\dev\java\workspaces\hadoop\hbase-quickstart01\target\test-classes;D:\dev\java\workspaces\hadoop\hbase-quickstart01\target\classes;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-client\1.3.1\hbase-client-1.3.1.jar;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-annotations\1.3.1\hbase-annotations-1.3.1.jar;C:\Users\FangMing\.m2\repository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;C:\Users\FangMing\.m2\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-common\1.3.1\hbase-common-1.3.1.jar;C:\Users\FangMing\.m2\repository\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;C:\Users\FangMing\.m2\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-protocol\1.3.1\hbase-protocol-1.3.1.jar;C:\Users\FangMing\.m2\repository\commons-codec\commons-codec\1.9\commons-codec-1.9.jar;C:\Users\FangMing\.m2\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;C:\Users\FangMing\.m2\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;C:\Users\FangMing\.m2\repository\commons-logging\commons-logging\1.2\commons-logging-1.2.jar;C:\Users\FangMing\.m2\repository\com\google\guava\guava\12.0.1\guava-12.0.1.jar;C:\Users\FangMing\.m2\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;C:\Users\FangMing\.m2\repository\io\netty\netty-all\4.0.23.Final\netty-all-4.0.23.Final.jar;C:\Users\FangMing\.m2\repository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;C:\Users\FangMing\.m2\repository\org\slf4j\slf4j-api\1.6.1\slf4j-api-1.6.1.jar;C:\Users\FangMing\.m2\repository\org\slf4j\slf4j-log4j12\1.6.1\slf4j-log4j12-1.6.1.jar;C:\Users\FangMing\.m2\repository\org\apache\htrace\htrace-core\3.1.0-incubating\htrace-core-3.1.0-incubating.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jackson\jackson-mapper-asl\1.9.13\jackson-mapper-asl-1.9.13.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;C:\Users\FangMing\.m2\repository\org\jruby\jcodings\jcodings\1.0.8\jcodings-1.0.8.jar;C:\Users\FangMing\.m2\repository\org\jruby\joni\joni\2.1.2\joni-2.1.2.jar;C:\Users\FangMing\.m2\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-auth\2.5.1\hadoop-auth-2.5.1.jar;C:\Users\FangMing\.m2\repository\org\apache\httpcomponents\httpclient\4.2.5\httpclient-4.2.5.jar;C:\Users\FangMing\.m2\repository\org\apache\httpcomponents\httpcore\4.2.4\httpcore-4.2.4.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\server\apacheds-kerberos-codec\2.0.0-M15\apacheds-kerberos-codec-2.0.0-M15.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\server\apacheds-i18n\2.0.0-M15\apacheds-i18n-2.0.0-M15.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\api\api-asn1-api\1.0.0-M20\api-asn1-api-1.0.0-M20.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\api\api-util\1.0.0-M20\api-util-1.0.0-M20.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-common\2.5.1\hadoop-common-2.5.1.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-annotations\2.5.1\hadoop-annotations-2.5.1.jar;C:\Users\FangMing\.m2\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;C:\Users\FangMing\.m2\repository\org\apache\commons\commons-math3\3.1.1\commons-math3-3.1.1.jar;C:\Users\FangMing\.m2\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;C:\Users\FangMing\.m2\repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;C:\Users\FangMing\.m2\repository\commons-net\commons-net\3.1\commons-net-3.1.jar;C:\Users\FangMing\.m2\repository\commons-el\commons-el\1.0\commons-el-1.0.jar;C:\Users\FangMing\.m2\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;C:\Users\FangMing\.m2\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;C:\Users\FangMing\.m2\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;C:\Users\FangMing\.m2\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;C:\Users\FangMing\.m2\repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;C:\Users\FangMing\.m2\repository\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;C:\Users\FangMing\.m2\repository\org\xerial\snappy\snappy-java\1.0.4.1\snappy-java-1.0.4.1.jar;C:\Users\FangMing\.m2\repository\com\jcraft\jsch\0.1.42\jsch-0.1.42.jar;C:\Users\FangMing\.m2\repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;C:\Users\FangMing\.m2\repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;C:\Users\FangMing\.m2\repository\org\tukaani\xz\1.0\xz-1.0.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.5.1\hadoop-mapreduce-client-core-2.5.1.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-yarn-common\2.5.1\hadoop-yarn-common-2.5.1.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-yarn-api\2.5.1\hadoop-yarn-api-2.5.1.jar;C:\Users\FangMing\.m2\repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;C:\Users\FangMing\.m2\repository\javax\xml\stream\stax-api\1.0-2\stax-api-1.0-2.jar;C:\Users\FangMing\.m2\repository\javax\activation\activation\1.1\activation-1.1.jar;C:\Users\FangMing\.m2\repository\io\netty\netty\3.6.2.Final\netty-3.6.2.Final.jar;C:\Program Files\Java\jdk\lib\tools.jar;C:\Users\FangMing\.m2\repository\junit\junit\4.12\junit-4.12.jar;C:\Users\FangMing\.m2\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;/D:/dev/java/eclipseNeon2/eclipse/configuration/org.eclipse.osgi/389/0/.cp/;/D:/dev/java/eclipseNeon2/eclipse/configuration/org.eclipse.osgi/388/0/.cp/
[2017-05-18 21:04:57,895][main][INFO ]:Client environment:java.library.path=C:\Program Files\Java\jdk7\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:/Program Files/Java/jre/bin/server;C:/Program Files/Java/jre/bin;C:/Program Files/Java/jre/lib/amd64;.;D:\dev\java\libs\hadoop\hadoop-2.7.3\bin;C:\ProgramData\Oracle\Java\javapath;D:\Dev\scripts;E:\study\maven\apache-maven-3.3.9\bin;e:\study\groovy\groovy-2.4.6\bin;E:/study/gradle/gradle-default/bin;C:\Program Files\Java\jdk\bin;E:\Study\ant\apache-ant-1.9.2\bin;C:\oracle\product\11.2.0\client_1;C:\oracle\product\11.2.0\client_1\bin;C:\Program Files (x86)\AMD APP\bin\x86_64;C:\Program Files (x86)\AMD APP\bin\x86;C:\Program Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\Microsoft SQL Server\100\Tools\Binn\;C:\Program Files\Microsoft SQL Server\100\Tools\Binn\;C:\Program Files\Microsoft SQL Server\100\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\100\Tools\Binn\VSShell\Common7\IDE\;C:\Program Files (x86)\Microsoft SQL Server\100\DTS\Binn\;C:\Program Files (x86)\Microsoft Visual Studio 9.0\Common7\IDE\PrivateAssemblies\;C:\Program Files\TortoiseSVN\bin;C:\Program Files\ThinkPad\Bluetooth Software\;C:\Program Files\ThinkPad\Bluetooth Software\syswow64;C:\Program Files\VisualSVN Server\bin;C:\Program Files\Git\cmd;C:\Users\FangMing\AppData\Local\Programs\Python\Python36\Scripts\;C:\Users\FangMing\AppData\Local\Programs\Python\Python36\;D:\dev\java\eclipseNeon2\eclipse;;.
[2017-05-18 21:04:57,896][main][INFO ]:Client environment:java.io.tmpdir=C:\Users\FangMing\AppData\Local\Temp\
[2017-05-18 21:04:57,896][main][INFO ]:Client environment:java.compiler=<NA>
[2017-05-18 21:04:57,896][main][INFO ]:Client environment:os.name=Windows 7
[2017-05-18 21:04:57,896][main][INFO ]:Client environment:os.arch=amd64
[2017-05-18 21:04:57,896][main][INFO ]:Client environment:os.version=6.1
[2017-05-18 21:04:57,896][main][INFO ]:Client environment:user.name=FangMing
[2017-05-18 21:04:57,896][main][INFO ]:Client environment:user.home=C:\Users\FangMing
[2017-05-18 21:04:57,897][main][INFO ]:Client environment:user.dir=D:\dev\java\workspaces\hadoop\hbase-quickstart01
[2017-05-18 21:04:57,898][main][INFO ]:Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@3929880d
[2017-05-18 21:04:57,954][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 21:04:58,956][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 21:05:00,062][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 21:05:01,062][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 21:05:02,163][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 21:05:03,164][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 21:05:04,264][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 21:05:05,265][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 21:05:06,366][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 21:05:07,364][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 21:05:08,464][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 21:05:09,475][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 21:05:10,575][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 21:05:11,576][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 21:05:12,676][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 21:05:13,677][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 21:05:14,779][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 21:05:15,780][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 21:05:15,881][main][ERROR]:ZooKeeper exists failed after 4 attempts
[2017-05-18 21:05:15,881][main][WARN ]:hconnection-0x28b2eca90x0, quorum=localhost:2181, baseZNode=/hbase Unable to set watcher on znode (/hbase/hbaseid)
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/hbaseid
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.exists(ZooKeeper.java:1045)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.exists(RecoverableZooKeeper.java:220)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.checkExists(ZKUtil.java:420)
	at org.apache.hadoop.hbase.zookeeper.ZKClusterId.readClusterIdZNode(ZKClusterId.java:65)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getClusterId(ZooKeeperRegistry.java:105)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.retrieveClusterId(ConnectionManager.java:907)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.<init>(ConnectionManager.java:691)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:238)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:218)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:119)
	at com.fsmflying.hbase01.HbaseTest01.before(HbaseTest01.java:35)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:86)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:459)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:678)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192)
[2017-05-18 21:05:15,885][main][ERROR]:hconnection-0x28b2eca90x0, quorum=localhost:2181, baseZNode=/hbase Received unexpected KeeperException, re-throwing exception
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/hbaseid
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.exists(ZooKeeper.java:1045)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.exists(RecoverableZooKeeper.java:220)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.checkExists(ZKUtil.java:420)
	at org.apache.hadoop.hbase.zookeeper.ZKClusterId.readClusterIdZNode(ZKClusterId.java:65)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getClusterId(ZooKeeperRegistry.java:105)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.retrieveClusterId(ConnectionManager.java:907)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.<init>(ConnectionManager.java:691)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:238)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:218)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:119)
	at com.fsmflying.hbase01.HbaseTest01.before(HbaseTest01.java:35)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:86)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:459)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:678)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192)
[2017-05-18 21:05:15,887][main][WARN ]:Can't retrieve clusterId from Zookeeper
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/hbaseid
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.exists(ZooKeeper.java:1045)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.exists(RecoverableZooKeeper.java:220)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.checkExists(ZKUtil.java:420)
	at org.apache.hadoop.hbase.zookeeper.ZKClusterId.readClusterIdZNode(ZKClusterId.java:65)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getClusterId(ZooKeeperRegistry.java:105)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.retrieveClusterId(ConnectionManager.java:907)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.<init>(ConnectionManager.java:691)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:238)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:218)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:119)
	at com.fsmflying.hbase01.HbaseTest01.before(HbaseTest01.java:35)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:86)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:459)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:678)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192)
[2017-05-18 21:05:16,881][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 21:05:17,882][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 21:05:18,982][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 21:05:19,983][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 21:05:21,084][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 21:05:22,083][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 21:05:23,184][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 21:05:24,185][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 21:05:25,286][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 21:05:26,286][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 21:05:27,387][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 21:05:28,387][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 21:05:29,497][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 21:05:30,499][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 21:05:31,599][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 21:05:32,600][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 21:05:33,701][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 21:05:34,701][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 21:05:34,802][main][ERROR]:ZooKeeper getData failed after 4 attempts
[2017-05-18 21:05:34,802][main][WARN ]:hconnection-0x28b2eca90x0, quorum=localhost:2181, baseZNode=/hbase Unable to get data of znode /hbase/meta-region-server
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/meta-region-server
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.getData(RecoverableZooKeeper.java:354)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.getData(ZKUtil.java:624)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.getMetaRegionState(MetaTableLocator.java:486)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.getMetaRegionLocation(MetaTableLocator.java:167)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:606)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:587)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:560)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getMetaRegionLocation(ZooKeeperRegistry.java:61)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateMeta(ConnectionManager.java:1213)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateRegion(ConnectionManager.java:1180)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas.getRegionLocations(RpcRetryingCallerWithReadReplicas.java:305)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:156)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:60)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:212)
	at org.apache.hadoop.hbase.client.ClientScanner.call(ClientScanner.java:314)
	at org.apache.hadoop.hbase.client.ClientScanner.nextScanner(ClientScanner.java:289)
	at org.apache.hadoop.hbase.client.ClientScanner.initializeScannerInConstruction(ClientScanner.java:164)
	at org.apache.hadoop.hbase.client.ClientScanner.<init>(ClientScanner.java:159)
	at org.apache.hadoop.hbase.client.HTable.getScanner(HTable.java:796)
	at org.apache.hadoop.hbase.MetaTableAccessor.fullScan(MetaTableAccessor.java:602)
	at org.apache.hadoop.hbase.MetaTableAccessor.tableExists(MetaTableAccessor.java:366)
	at org.apache.hadoop.hbase.client.HBaseAdmin.tableExists(HBaseAdmin.java:408)
	at com.fsmflying.hbase01.HbaseTest01.test01_createTables(HbaseTest01.java:57)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:86)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:459)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:678)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192)
[2017-05-18 21:05:34,803][main][ERROR]:hconnection-0x28b2eca90x0, quorum=localhost:2181, baseZNode=/hbase Received unexpected KeeperException, re-throwing exception
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/meta-region-server
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.getData(RecoverableZooKeeper.java:354)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.getData(ZKUtil.java:624)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.getMetaRegionState(MetaTableLocator.java:486)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.getMetaRegionLocation(MetaTableLocator.java:167)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:606)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:587)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:560)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getMetaRegionLocation(ZooKeeperRegistry.java:61)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateMeta(ConnectionManager.java:1213)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateRegion(ConnectionManager.java:1180)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas.getRegionLocations(RpcRetryingCallerWithReadReplicas.java:305)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:156)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:60)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:212)
	at org.apache.hadoop.hbase.client.ClientScanner.call(ClientScanner.java:314)
	at org.apache.hadoop.hbase.client.ClientScanner.nextScanner(ClientScanner.java:289)
	at org.apache.hadoop.hbase.client.ClientScanner.initializeScannerInConstruction(ClientScanner.java:164)
	at org.apache.hadoop.hbase.client.ClientScanner.<init>(ClientScanner.java:159)
	at org.apache.hadoop.hbase.client.HTable.getScanner(HTable.java:796)
	at org.apache.hadoop.hbase.MetaTableAccessor.fullScan(MetaTableAccessor.java:602)
	at org.apache.hadoop.hbase.MetaTableAccessor.tableExists(MetaTableAccessor.java:366)
	at org.apache.hadoop.hbase.client.HBaseAdmin.tableExists(HBaseAdmin.java:408)
	at com.fsmflying.hbase01.HbaseTest01.test01_createTables(HbaseTest01.java:57)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:86)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:459)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:678)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192)
[2017-05-18 21:05:35,802][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 21:05:36,803][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 21:05:37,904][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 21:05:38,915][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 21:05:40,015][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 21:05:41,024][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 21:05:42,124][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 21:05:43,127][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 21:05:44,227][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 21:05:45,228][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 21:05:46,329][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 21:05:47,329][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 21:05:48,435][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 21:05:49,436][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 21:05:50,537][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 21:05:51,538][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 21:05:52,639][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 21:05:53,650][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 21:05:53,750][main][ERROR]:ZooKeeper getData failed after 4 attempts
[2017-05-18 21:05:53,750][main][WARN ]:hconnection-0x28b2eca90x0, quorum=localhost:2181, baseZNode=/hbase Unable to get data of znode /hbase/meta-region-server
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/meta-region-server
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.getData(RecoverableZooKeeper.java:354)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.getData(ZKUtil.java:624)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.getMetaRegionState(MetaTableLocator.java:486)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.getMetaRegionLocation(MetaTableLocator.java:167)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:606)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:587)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:560)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getMetaRegionLocation(ZooKeeperRegistry.java:61)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateMeta(ConnectionManager.java:1213)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateRegion(ConnectionManager.java:1180)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas.getRegionLocations(RpcRetryingCallerWithReadReplicas.java:305)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:156)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:60)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:212)
	at org.apache.hadoop.hbase.client.ClientScanner.call(ClientScanner.java:314)
	at org.apache.hadoop.hbase.client.ClientScanner.nextScanner(ClientScanner.java:289)
	at org.apache.hadoop.hbase.client.ClientScanner.initializeScannerInConstruction(ClientScanner.java:164)
	at org.apache.hadoop.hbase.client.ClientScanner.<init>(ClientScanner.java:159)
	at org.apache.hadoop.hbase.client.HTable.getScanner(HTable.java:796)
	at org.apache.hadoop.hbase.MetaTableAccessor.fullScan(MetaTableAccessor.java:602)
	at org.apache.hadoop.hbase.MetaTableAccessor.tableExists(MetaTableAccessor.java:366)
	at org.apache.hadoop.hbase.client.HBaseAdmin.tableExists(HBaseAdmin.java:408)
	at com.fsmflying.hbase01.HbaseTest01.test01_createTables(HbaseTest01.java:57)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:86)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:459)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:678)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192)
[2017-05-18 21:05:53,752][main][ERROR]:hconnection-0x28b2eca90x0, quorum=localhost:2181, baseZNode=/hbase Received unexpected KeeperException, re-throwing exception
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/meta-region-server
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.getData(RecoverableZooKeeper.java:354)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.getData(ZKUtil.java:624)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.getMetaRegionState(MetaTableLocator.java:486)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.getMetaRegionLocation(MetaTableLocator.java:167)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:606)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:587)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:560)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getMetaRegionLocation(ZooKeeperRegistry.java:61)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateMeta(ConnectionManager.java:1213)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateRegion(ConnectionManager.java:1180)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas.getRegionLocations(RpcRetryingCallerWithReadReplicas.java:305)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:156)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:60)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:212)
	at org.apache.hadoop.hbase.client.ClientScanner.call(ClientScanner.java:314)
	at org.apache.hadoop.hbase.client.ClientScanner.nextScanner(ClientScanner.java:289)
	at org.apache.hadoop.hbase.client.ClientScanner.initializeScannerInConstruction(ClientScanner.java:164)
	at org.apache.hadoop.hbase.client.ClientScanner.<init>(ClientScanner.java:159)
	at org.apache.hadoop.hbase.client.HTable.getScanner(HTable.java:796)
	at org.apache.hadoop.hbase.MetaTableAccessor.fullScan(MetaTableAccessor.java:602)
	at org.apache.hadoop.hbase.MetaTableAccessor.tableExists(MetaTableAccessor.java:366)
	at org.apache.hadoop.hbase.client.HBaseAdmin.tableExists(HBaseAdmin.java:408)
	at com.fsmflying.hbase01.HbaseTest01.test01_createTables(HbaseTest01.java:57)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:86)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:459)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:678)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192)
[2017-05-18 21:05:54,750][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 21:05:55,751][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 21:05:56,852][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 21:05:57,852][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 21:05:58,953][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 21:05:59,963][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 21:06:01,065][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 21:06:02,066][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 21:06:03,166][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 21:06:04,167][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 21:06:05,268][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 21:06:06,268][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 21:06:07,369][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 21:06:08,373][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 21:06:09,473][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 21:06:10,474][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 21:06:11,580][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 21:06:12,581][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 21:06:12,682][main][ERROR]:ZooKeeper getData failed after 4 attempts
[2017-05-18 21:06:12,682][main][WARN ]:hconnection-0x28b2eca90x0, quorum=localhost:2181, baseZNode=/hbase Unable to get data of znode /hbase/meta-region-server
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/meta-region-server
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.getData(RecoverableZooKeeper.java:354)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.getData(ZKUtil.java:624)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.getMetaRegionState(MetaTableLocator.java:486)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.getMetaRegionLocation(MetaTableLocator.java:167)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:606)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:587)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:560)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getMetaRegionLocation(ZooKeeperRegistry.java:61)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateMeta(ConnectionManager.java:1213)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateRegion(ConnectionManager.java:1180)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas.getRegionLocations(RpcRetryingCallerWithReadReplicas.java:305)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:156)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:60)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:212)
	at org.apache.hadoop.hbase.client.ClientScanner.call(ClientScanner.java:314)
	at org.apache.hadoop.hbase.client.ClientScanner.nextScanner(ClientScanner.java:289)
	at org.apache.hadoop.hbase.client.ClientScanner.initializeScannerInConstruction(ClientScanner.java:164)
	at org.apache.hadoop.hbase.client.ClientScanner.<init>(ClientScanner.java:159)
	at org.apache.hadoop.hbase.client.HTable.getScanner(HTable.java:796)
	at org.apache.hadoop.hbase.MetaTableAccessor.fullScan(MetaTableAccessor.java:602)
	at org.apache.hadoop.hbase.MetaTableAccessor.tableExists(MetaTableAccessor.java:366)
	at org.apache.hadoop.hbase.client.HBaseAdmin.tableExists(HBaseAdmin.java:408)
	at com.fsmflying.hbase01.HbaseTest01.test01_createTables(HbaseTest01.java:57)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:86)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:459)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:678)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192)
[2017-05-18 21:06:12,685][main][ERROR]:hconnection-0x28b2eca90x0, quorum=localhost:2181, baseZNode=/hbase Received unexpected KeeperException, re-throwing exception
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/meta-region-server
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.getData(RecoverableZooKeeper.java:354)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.getData(ZKUtil.java:624)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.getMetaRegionState(MetaTableLocator.java:486)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.getMetaRegionLocation(MetaTableLocator.java:167)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:606)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:587)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:560)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getMetaRegionLocation(ZooKeeperRegistry.java:61)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateMeta(ConnectionManager.java:1213)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateRegion(ConnectionManager.java:1180)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas.getRegionLocations(RpcRetryingCallerWithReadReplicas.java:305)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:156)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:60)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:212)
	at org.apache.hadoop.hbase.client.ClientScanner.call(ClientScanner.java:314)
	at org.apache.hadoop.hbase.client.ClientScanner.nextScanner(ClientScanner.java:289)
	at org.apache.hadoop.hbase.client.ClientScanner.initializeScannerInConstruction(ClientScanner.java:164)
	at org.apache.hadoop.hbase.client.ClientScanner.<init>(ClientScanner.java:159)
	at org.apache.hadoop.hbase.client.HTable.getScanner(HTable.java:796)
	at org.apache.hadoop.hbase.MetaTableAccessor.fullScan(MetaTableAccessor.java:602)
	at org.apache.hadoop.hbase.MetaTableAccessor.tableExists(MetaTableAccessor.java:366)
	at org.apache.hadoop.hbase.client.HBaseAdmin.tableExists(HBaseAdmin.java:408)
	at com.fsmflying.hbase01.HbaseTest01.test01_createTables(HbaseTest01.java:57)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:86)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:459)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:678)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192)
[2017-05-18 21:06:13,682][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 21:06:14,682][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 21:06:15,783][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 21:06:16,778][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 21:06:17,879][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 21:06:18,880][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 21:06:19,988][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 21:06:20,989][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 21:06:22,089][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 21:06:23,090][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 21:06:24,191][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 21:06:25,191][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 21:06:26,297][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 21:06:27,300][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 21:06:28,401][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 21:06:29,401][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 21:06:30,502][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 21:06:31,500][main-SendThread(127.0.0.1:2181)][WARN ]:Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[2017-05-18 21:06:31,601][main][ERROR]:ZooKeeper getData failed after 4 attempts
[2017-05-18 21:06:31,601][main][WARN ]:hconnection-0x28b2eca90x0, quorum=localhost:2181, baseZNode=/hbase Unable to get data of znode /hbase/meta-region-server
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/meta-region-server
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.getData(RecoverableZooKeeper.java:354)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.getData(ZKUtil.java:624)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.getMetaRegionState(MetaTableLocator.java:486)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.getMetaRegionLocation(MetaTableLocator.java:167)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:606)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:587)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:560)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getMetaRegionLocation(ZooKeeperRegistry.java:61)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateMeta(ConnectionManager.java:1213)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateRegion(ConnectionManager.java:1180)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas.getRegionLocations(RpcRetryingCallerWithReadReplicas.java:305)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:156)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:60)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:212)
	at org.apache.hadoop.hbase.client.ClientScanner.call(ClientScanner.java:314)
	at org.apache.hadoop.hbase.client.ClientScanner.nextScanner(ClientScanner.java:289)
	at org.apache.hadoop.hbase.client.ClientScanner.initializeScannerInConstruction(ClientScanner.java:164)
	at org.apache.hadoop.hbase.client.ClientScanner.<init>(ClientScanner.java:159)
	at org.apache.hadoop.hbase.client.HTable.getScanner(HTable.java:796)
	at org.apache.hadoop.hbase.MetaTableAccessor.fullScan(MetaTableAccessor.java:602)
	at org.apache.hadoop.hbase.MetaTableAccessor.tableExists(MetaTableAccessor.java:366)
	at org.apache.hadoop.hbase.client.HBaseAdmin.tableExists(HBaseAdmin.java:408)
	at com.fsmflying.hbase01.HbaseTest01.test01_createTables(HbaseTest01.java:57)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:86)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:459)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:678)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192)
[2017-05-18 21:06:31,604][main][ERROR]:hconnection-0x28b2eca90x0, quorum=localhost:2181, baseZNode=/hbase Received unexpected KeeperException, re-throwing exception
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/meta-region-server
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.getData(RecoverableZooKeeper.java:354)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.getData(ZKUtil.java:624)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.getMetaRegionState(MetaTableLocator.java:486)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.getMetaRegionLocation(MetaTableLocator.java:167)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:606)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:587)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:560)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getMetaRegionLocation(ZooKeeperRegistry.java:61)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateMeta(ConnectionManager.java:1213)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateRegion(ConnectionManager.java:1180)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas.getRegionLocations(RpcRetryingCallerWithReadReplicas.java:305)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:156)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:60)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:212)
	at org.apache.hadoop.hbase.client.ClientScanner.call(ClientScanner.java:314)
	at org.apache.hadoop.hbase.client.ClientScanner.nextScanner(ClientScanner.java:289)
	at org.apache.hadoop.hbase.client.ClientScanner.initializeScannerInConstruction(ClientScanner.java:164)
	at org.apache.hadoop.hbase.client.ClientScanner.<init>(ClientScanner.java:159)
	at org.apache.hadoop.hbase.client.HTable.getScanner(HTable.java:796)
	at org.apache.hadoop.hbase.MetaTableAccessor.fullScan(MetaTableAccessor.java:602)
	at org.apache.hadoop.hbase.MetaTableAccessor.tableExists(MetaTableAccessor.java:366)
	at org.apache.hadoop.hbase.client.HBaseAdmin.tableExists(HBaseAdmin.java:408)
	at com.fsmflying.hbase01.HbaseTest01.test01_createTables(HbaseTest01.java:57)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:86)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:459)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:678)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192)
[2017-05-18 21:06:31,609][main][INFO ]:Closing zookeeper sessionid=0x0
[2017-05-18 21:06:32,601][main-SendThread(127.0.0.1:2181)][INFO ]:Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 21:06:33,708][main][INFO ]:Session: 0x0 closed
[2017-05-18 21:06:33,709][main-EventThread][INFO ]:EventThread shut down
[2017-05-18 21:45:49,693][main][INFO ]:Process identifier=hconnection-0x623bbf83 connecting to ZooKeeper ensemble=master.hadoop:2181
[2017-05-18 21:45:49,707][main][INFO ]:Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
[2017-05-18 21:45:49,707][main][INFO ]:Client environment:host.name=FANGMING-THINK
[2017-05-18 21:45:49,708][main][INFO ]:Client environment:java.version=1.7.0_79
[2017-05-18 21:45:49,708][main][INFO ]:Client environment:java.vendor=Oracle Corporation
[2017-05-18 21:45:49,708][main][INFO ]:Client environment:java.home=C:\Program Files\Java\jdk7\jre
[2017-05-18 21:45:49,708][main][INFO ]:Client environment:java.class.path=D:\dev\java\workspaces\hadoop\hbase-quickstart01\target\test-classes;D:\dev\java\workspaces\hadoop\hbase-quickstart01\target\classes;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-client\1.3.1\hbase-client-1.3.1.jar;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-annotations\1.3.1\hbase-annotations-1.3.1.jar;C:\Users\FangMing\.m2\repository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;C:\Users\FangMing\.m2\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-common\1.3.1\hbase-common-1.3.1.jar;C:\Users\FangMing\.m2\repository\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;C:\Users\FangMing\.m2\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-protocol\1.3.1\hbase-protocol-1.3.1.jar;C:\Users\FangMing\.m2\repository\commons-codec\commons-codec\1.9\commons-codec-1.9.jar;C:\Users\FangMing\.m2\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;C:\Users\FangMing\.m2\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;C:\Users\FangMing\.m2\repository\commons-logging\commons-logging\1.2\commons-logging-1.2.jar;C:\Users\FangMing\.m2\repository\com\google\guava\guava\12.0.1\guava-12.0.1.jar;C:\Users\FangMing\.m2\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;C:\Users\FangMing\.m2\repository\io\netty\netty-all\4.0.23.Final\netty-all-4.0.23.Final.jar;C:\Users\FangMing\.m2\repository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;C:\Users\FangMing\.m2\repository\org\slf4j\slf4j-api\1.6.1\slf4j-api-1.6.1.jar;C:\Users\FangMing\.m2\repository\org\slf4j\slf4j-log4j12\1.6.1\slf4j-log4j12-1.6.1.jar;C:\Users\FangMing\.m2\repository\org\apache\htrace\htrace-core\3.1.0-incubating\htrace-core-3.1.0-incubating.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jackson\jackson-mapper-asl\1.9.13\jackson-mapper-asl-1.9.13.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;C:\Users\FangMing\.m2\repository\org\jruby\jcodings\jcodings\1.0.8\jcodings-1.0.8.jar;C:\Users\FangMing\.m2\repository\org\jruby\joni\joni\2.1.2\joni-2.1.2.jar;C:\Users\FangMing\.m2\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-auth\2.5.1\hadoop-auth-2.5.1.jar;C:\Users\FangMing\.m2\repository\org\apache\httpcomponents\httpclient\4.2.5\httpclient-4.2.5.jar;C:\Users\FangMing\.m2\repository\org\apache\httpcomponents\httpcore\4.2.4\httpcore-4.2.4.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\server\apacheds-kerberos-codec\2.0.0-M15\apacheds-kerberos-codec-2.0.0-M15.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\server\apacheds-i18n\2.0.0-M15\apacheds-i18n-2.0.0-M15.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\api\api-asn1-api\1.0.0-M20\api-asn1-api-1.0.0-M20.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\api\api-util\1.0.0-M20\api-util-1.0.0-M20.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-common\2.5.1\hadoop-common-2.5.1.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-annotations\2.5.1\hadoop-annotations-2.5.1.jar;C:\Users\FangMing\.m2\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;C:\Users\FangMing\.m2\repository\org\apache\commons\commons-math3\3.1.1\commons-math3-3.1.1.jar;C:\Users\FangMing\.m2\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;C:\Users\FangMing\.m2\repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;C:\Users\FangMing\.m2\repository\commons-net\commons-net\3.1\commons-net-3.1.jar;C:\Users\FangMing\.m2\repository\commons-el\commons-el\1.0\commons-el-1.0.jar;C:\Users\FangMing\.m2\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;C:\Users\FangMing\.m2\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;C:\Users\FangMing\.m2\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;C:\Users\FangMing\.m2\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;C:\Users\FangMing\.m2\repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;C:\Users\FangMing\.m2\repository\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;C:\Users\FangMing\.m2\repository\org\xerial\snappy\snappy-java\1.0.4.1\snappy-java-1.0.4.1.jar;C:\Users\FangMing\.m2\repository\com\jcraft\jsch\0.1.42\jsch-0.1.42.jar;C:\Users\FangMing\.m2\repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;C:\Users\FangMing\.m2\repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;C:\Users\FangMing\.m2\repository\org\tukaani\xz\1.0\xz-1.0.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.5.1\hadoop-mapreduce-client-core-2.5.1.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-yarn-common\2.5.1\hadoop-yarn-common-2.5.1.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-yarn-api\2.5.1\hadoop-yarn-api-2.5.1.jar;C:\Users\FangMing\.m2\repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;C:\Users\FangMing\.m2\repository\javax\xml\stream\stax-api\1.0-2\stax-api-1.0-2.jar;C:\Users\FangMing\.m2\repository\javax\activation\activation\1.1\activation-1.1.jar;C:\Users\FangMing\.m2\repository\io\netty\netty\3.6.2.Final\netty-3.6.2.Final.jar;C:\Program Files\Java\jdk\lib\tools.jar;C:\Users\FangMing\.m2\repository\junit\junit\4.12\junit-4.12.jar;C:\Users\FangMing\.m2\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;/D:/dev/java/eclipseNeon2/eclipse/configuration/org.eclipse.osgi/389/0/.cp/;/D:/dev/java/eclipseNeon2/eclipse/configuration/org.eclipse.osgi/388/0/.cp/
[2017-05-18 21:45:49,708][main][INFO ]:Client environment:java.library.path=C:\Program Files\Java\jdk7\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:/Program Files/Java/jre/bin/server;C:/Program Files/Java/jre/bin;C:/Program Files/Java/jre/lib/amd64;.;D:\dev\java\libs\hadoop\hadoop-2.7.3\bin;C:\ProgramData\Oracle\Java\javapath;D:\Dev\scripts;E:\study\maven\apache-maven-3.3.9\bin;e:\study\groovy\groovy-2.4.6\bin;E:/study/gradle/gradle-default/bin;C:\Program Files\Java\jdk\bin;E:\Study\ant\apache-ant-1.9.2\bin;C:\oracle\product\11.2.0\client_1;C:\oracle\product\11.2.0\client_1\bin;C:\Program Files (x86)\AMD APP\bin\x86_64;C:\Program Files (x86)\AMD APP\bin\x86;C:\Program Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\Microsoft SQL Server\100\Tools\Binn\;C:\Program Files\Microsoft SQL Server\100\Tools\Binn\;C:\Program Files\Microsoft SQL Server\100\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\100\Tools\Binn\VSShell\Common7\IDE\;C:\Program Files (x86)\Microsoft SQL Server\100\DTS\Binn\;C:\Program Files (x86)\Microsoft Visual Studio 9.0\Common7\IDE\PrivateAssemblies\;C:\Program Files\TortoiseSVN\bin;C:\Program Files\ThinkPad\Bluetooth Software\;C:\Program Files\ThinkPad\Bluetooth Software\syswow64;C:\Program Files\VisualSVN Server\bin;C:\Program Files\Git\cmd;C:\Users\FangMing\AppData\Local\Programs\Python\Python36\Scripts\;C:\Users\FangMing\AppData\Local\Programs\Python\Python36\;D:\dev\java\eclipseNeon2\eclipse;;.
[2017-05-18 21:45:49,709][main][INFO ]:Client environment:java.io.tmpdir=C:\Users\FangMing\AppData\Local\Temp\
[2017-05-18 21:45:49,709][main][INFO ]:Client environment:java.compiler=<NA>
[2017-05-18 21:45:49,709][main][INFO ]:Client environment:os.name=Windows 7
[2017-05-18 21:45:49,709][main][INFO ]:Client environment:os.arch=amd64
[2017-05-18 21:45:49,709][main][INFO ]:Client environment:os.version=6.1
[2017-05-18 21:45:49,710][main][INFO ]:Client environment:user.name=FangMing
[2017-05-18 21:45:49,710][main][INFO ]:Client environment:user.home=C:\Users\FangMing
[2017-05-18 21:45:49,710][main][INFO ]:Client environment:user.dir=D:\dev\java\workspaces\hadoop\hbase-quickstart01
[2017-05-18 21:45:49,712][main][INFO ]:Initiating client connection, connectString=master.hadoop:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@28193ba0
[2017-05-18 21:45:49,769][main-SendThread(master.hadoop:2181)][INFO ]:Opening socket connection to server master.hadoop/192.168.1.104:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 21:45:49,774][main-SendThread(master.hadoop:2181)][INFO ]:Socket connection established to master.hadoop/192.168.1.104:2181, initiating session
[2017-05-18 21:45:49,856][main-SendThread(master.hadoop:2181)][INFO ]:Session establishment complete on server master.hadoop/192.168.1.104:2181, sessionid = 0x15c1afbf5890007, negotiated timeout = 90000
[2017-05-18 21:45:50,106][main][WARN ]:Failed to identify the fs of dir hdfs://master.hadoop:9000/hbase/lib, ignored
java.io.IOException: No FileSystem for scheme: hdfs
	at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2579)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2586)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:89)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2625)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2607)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:368)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:296)
	at org.apache.hadoop.hbase.util.DynamicClassLoader.initTempDir(DynamicClassLoader.java:120)
	at org.apache.hadoop.hbase.util.DynamicClassLoader.<init>(DynamicClassLoader.java:98)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.<clinit>(ProtobufUtil.java:246)
	at org.apache.hadoop.hbase.ClusterId.parseFrom(ClusterId.java:64)
	at org.apache.hadoop.hbase.zookeeper.ZKClusterId.readClusterIdZNode(ZKClusterId.java:75)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getClusterId(ZooKeeperRegistry.java:105)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.retrieveClusterId(ConnectionManager.java:907)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.<init>(ConnectionManager.java:691)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:238)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:218)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:119)
	at com.fsmflying.hbase01.HbaseTest01.before(HbaseTest01.java:38)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:86)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:459)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:678)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192)
[2017-05-18 21:46:59,037][main][INFO ]:Closing zookeeper sessionid=0x15c1afbf5890007
[2017-05-18 21:46:59,151][main][INFO ]:Session: 0x15c1afbf5890007 closed
[2017-05-18 21:46:59,153][main-EventThread][INFO ]:EventThread shut down
[2017-05-18 21:59:47,967][main][INFO ]:Process identifier=hconnection-0x374d9243 connecting to ZooKeeper ensemble=master.hadoop:2181
[2017-05-18 21:59:47,975][main][INFO ]:Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
[2017-05-18 21:59:47,975][main][INFO ]:Client environment:host.name=FANGMING-THINK
[2017-05-18 21:59:47,976][main][INFO ]:Client environment:java.version=1.7.0_79
[2017-05-18 21:59:47,976][main][INFO ]:Client environment:java.vendor=Oracle Corporation
[2017-05-18 21:59:47,976][main][INFO ]:Client environment:java.home=C:\Program Files\Java\jdk7\jre
[2017-05-18 21:59:47,976][main][INFO ]:Client environment:java.class.path=D:\dev\java\workspaces\hadoop\hbase-quickstart01\target\test-classes;D:\dev\java\workspaces\hadoop\hbase-quickstart01\target\classes;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-client\1.3.1\hbase-client-1.3.1.jar;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-annotations\1.3.1\hbase-annotations-1.3.1.jar;C:\Users\FangMing\.m2\repository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-common\1.3.1\hbase-common-1.3.1.jar;C:\Users\FangMing\.m2\repository\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-protocol\1.3.1\hbase-protocol-1.3.1.jar;C:\Users\FangMing\.m2\repository\commons-codec\commons-codec\1.9\commons-codec-1.9.jar;C:\Users\FangMing\.m2\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;C:\Users\FangMing\.m2\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;C:\Users\FangMing\.m2\repository\commons-logging\commons-logging\1.2\commons-logging-1.2.jar;C:\Users\FangMing\.m2\repository\com\google\guava\guava\12.0.1\guava-12.0.1.jar;C:\Users\FangMing\.m2\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;C:\Users\FangMing\.m2\repository\io\netty\netty-all\4.0.23.Final\netty-all-4.0.23.Final.jar;C:\Users\FangMing\.m2\repository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;C:\Users\FangMing\.m2\repository\org\slf4j\slf4j-api\1.6.1\slf4j-api-1.6.1.jar;C:\Users\FangMing\.m2\repository\org\slf4j\slf4j-log4j12\1.6.1\slf4j-log4j12-1.6.1.jar;C:\Users\FangMing\.m2\repository\org\apache\htrace\htrace-core\3.1.0-incubating\htrace-core-3.1.0-incubating.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jackson\jackson-mapper-asl\1.9.13\jackson-mapper-asl-1.9.13.jar;C:\Users\FangMing\.m2\repository\org\jruby\jcodings\jcodings\1.0.8\jcodings-1.0.8.jar;C:\Users\FangMing\.m2\repository\org\jruby\joni\joni\2.1.2\joni-2.1.2.jar;C:\Users\FangMing\.m2\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-auth\2.5.1\hadoop-auth-2.5.1.jar;C:\Users\FangMing\.m2\repository\org\apache\httpcomponents\httpclient\4.2.5\httpclient-4.2.5.jar;C:\Users\FangMing\.m2\repository\org\apache\httpcomponents\httpcore\4.2.4\httpcore-4.2.4.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\server\apacheds-kerberos-codec\2.0.0-M15\apacheds-kerberos-codec-2.0.0-M15.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\server\apacheds-i18n\2.0.0-M15\apacheds-i18n-2.0.0-M15.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\api\api-asn1-api\1.0.0-M20\api-asn1-api-1.0.0-M20.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\api\api-util\1.0.0-M20\api-util-1.0.0-M20.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-common\2.5.1\hadoop-common-2.5.1.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-annotations\2.5.1\hadoop-annotations-2.5.1.jar;C:\Users\FangMing\.m2\repository\org\apache\commons\commons-math3\3.1.1\commons-math3-3.1.1.jar;C:\Users\FangMing\.m2\repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;C:\Users\FangMing\.m2\repository\commons-net\commons-net\3.1\commons-net-3.1.jar;C:\Users\FangMing\.m2\repository\commons-el\commons-el\1.0\commons-el-1.0.jar;C:\Users\FangMing\.m2\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;C:\Users\FangMing\.m2\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;C:\Users\FangMing\.m2\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;C:\Users\FangMing\.m2\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;C:\Users\FangMing\.m2\repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;C:\Users\FangMing\.m2\repository\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;C:\Users\FangMing\.m2\repository\org\xerial\snappy\snappy-java\1.0.4.1\snappy-java-1.0.4.1.jar;C:\Users\FangMing\.m2\repository\com\jcraft\jsch\0.1.42\jsch-0.1.42.jar;C:\Users\FangMing\.m2\repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;C:\Users\FangMing\.m2\repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;C:\Users\FangMing\.m2\repository\org\tukaani\xz\1.0\xz-1.0.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.5.1\hadoop-mapreduce-client-core-2.5.1.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-yarn-common\2.5.1\hadoop-yarn-common-2.5.1.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-yarn-api\2.5.1\hadoop-yarn-api-2.5.1.jar;C:\Users\FangMing\.m2\repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;C:\Users\FangMing\.m2\repository\javax\xml\stream\stax-api\1.0-2\stax-api-1.0-2.jar;C:\Users\FangMing\.m2\repository\javax\activation\activation\1.1\activation-1.1.jar;C:\Program Files\Java\jdk\lib\tools.jar;C:\Users\FangMing\.m2\repository\junit\junit\4.12\junit-4.12.jar;C:\Users\FangMing\.m2\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-hdfs\2.5.1\hadoop-hdfs-2.5.1.jar;C:\Users\FangMing\.m2\repository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;C:\Users\FangMing\.m2\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;C:\Users\FangMing\.m2\repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;C:\Users\FangMing\.m2\repository\com\sun\jersey\jersey-server\1.9\jersey-server-1.9.jar;C:\Users\FangMing\.m2\repository\asm\asm\3.1\asm-3.1.jar;C:\Users\FangMing\.m2\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;C:\Users\FangMing\.m2\repository\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;C:\Users\FangMing\.m2\repository\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;C:\Users\FangMing\.m2\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;C:\Users\FangMing\.m2\repository\javax\servlet\servlet-api\2.5\servlet-api-2.5.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;C:\Users\FangMing\.m2\repository\tomcat\jasper-runtime\5.5.23\jasper-runtime-5.5.23.jar;C:\Users\FangMing\.m2\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;C:\Users\FangMing\.m2\repository\io\netty\netty\3.6.2.Final\netty-3.6.2.Final.jar;/D:/dev/java/eclipseNeon2/eclipse/configuration/org.eclipse.osgi/389/0/.cp/;/D:/dev/java/eclipseNeon2/eclipse/configuration/org.eclipse.osgi/388/0/.cp/
[2017-05-18 21:59:47,976][main][INFO ]:Client environment:java.library.path=C:\Program Files\Java\jdk7\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:/Program Files/Java/jre/bin/server;C:/Program Files/Java/jre/bin;C:/Program Files/Java/jre/lib/amd64;.;D:\dev\java\libs\hadoop\hadoop-2.7.3\bin;C:\ProgramData\Oracle\Java\javapath;D:\Dev\scripts;E:\study\maven\apache-maven-3.3.9\bin;e:\study\groovy\groovy-2.4.6\bin;E:/study/gradle/gradle-default/bin;C:\Program Files\Java\jdk\bin;E:\Study\ant\apache-ant-1.9.2\bin;C:\oracle\product\11.2.0\client_1;C:\oracle\product\11.2.0\client_1\bin;C:\Program Files (x86)\AMD APP\bin\x86_64;C:\Program Files (x86)\AMD APP\bin\x86;C:\Program Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\Microsoft SQL Server\100\Tools\Binn\;C:\Program Files\Microsoft SQL Server\100\Tools\Binn\;C:\Program Files\Microsoft SQL Server\100\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\100\Tools\Binn\VSShell\Common7\IDE\;C:\Program Files (x86)\Microsoft SQL Server\100\DTS\Binn\;C:\Program Files (x86)\Microsoft Visual Studio 9.0\Common7\IDE\PrivateAssemblies\;C:\Program Files\TortoiseSVN\bin;C:\Program Files\ThinkPad\Bluetooth Software\;C:\Program Files\ThinkPad\Bluetooth Software\syswow64;C:\Program Files\VisualSVN Server\bin;C:\Program Files\Git\cmd;C:\Users\FangMing\AppData\Local\Programs\Python\Python36\Scripts\;C:\Users\FangMing\AppData\Local\Programs\Python\Python36\;D:\dev\java\eclipseNeon2\eclipse;;.
[2017-05-18 21:59:47,977][main][INFO ]:Client environment:java.io.tmpdir=C:\Users\FangMing\AppData\Local\Temp\
[2017-05-18 21:59:47,977][main][INFO ]:Client environment:java.compiler=<NA>
[2017-05-18 21:59:47,977][main][INFO ]:Client environment:os.name=Windows 7
[2017-05-18 21:59:47,977][main][INFO ]:Client environment:os.arch=amd64
[2017-05-18 21:59:47,977][main][INFO ]:Client environment:os.version=6.1
[2017-05-18 21:59:47,977][main][INFO ]:Client environment:user.name=FangMing
[2017-05-18 21:59:47,977][main][INFO ]:Client environment:user.home=C:\Users\FangMing
[2017-05-18 21:59:47,977][main][INFO ]:Client environment:user.dir=D:\dev\java\workspaces\hadoop\hbase-quickstart01
[2017-05-18 21:59:47,978][main][INFO ]:Initiating client connection, connectString=master.hadoop:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@439f9baf
[2017-05-18 21:59:48,034][main-SendThread(master.hadoop:2181)][INFO ]:Opening socket connection to server master.hadoop/192.168.1.104:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 21:59:48,038][main-SendThread(master.hadoop:2181)][INFO ]:Socket connection established to master.hadoop/192.168.1.104:2181, initiating session
[2017-05-18 21:59:48,120][main-SendThread(master.hadoop:2181)][INFO ]:Session establishment complete on server master.hadoop/192.168.1.104:2181, sessionid = 0x15c1afbf5890008, negotiated timeout = 90000
[2017-05-18 21:59:48,275][main][INFO ]:Closing zookeeper sessionid=0x15c1afbf5890008
[2017-05-18 21:59:48,374][main][INFO ]:Session: 0x15c1afbf5890008 closed
[2017-05-18 21:59:48,374][main-EventThread][INFO ]:EventThread shut down
[2017-05-18 22:19:18,231][main][INFO ]:Process identifier=hconnection-0x45bd8912 connecting to ZooKeeper ensemble=master.hadoop:2181
[2017-05-18 22:19:18,240][main][INFO ]:Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
[2017-05-18 22:19:18,240][main][INFO ]:Client environment:host.name=FANGMING-THINK
[2017-05-18 22:19:18,240][main][INFO ]:Client environment:java.version=1.7.0_79
[2017-05-18 22:19:18,240][main][INFO ]:Client environment:java.vendor=Oracle Corporation
[2017-05-18 22:19:18,240][main][INFO ]:Client environment:java.home=C:\Program Files\Java\jdk7\jre
[2017-05-18 22:19:18,240][main][INFO ]:Client environment:java.class.path=D:\dev\java\workspaces\hadoop\hbase-quickstart01\target\test-classes;D:\dev\java\workspaces\hadoop\hbase-quickstart01\target\classes;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-client\1.3.1\hbase-client-1.3.1.jar;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-annotations\1.3.1\hbase-annotations-1.3.1.jar;C:\Users\FangMing\.m2\repository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-common\1.3.1\hbase-common-1.3.1.jar;C:\Users\FangMing\.m2\repository\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-protocol\1.3.1\hbase-protocol-1.3.1.jar;C:\Users\FangMing\.m2\repository\commons-codec\commons-codec\1.9\commons-codec-1.9.jar;C:\Users\FangMing\.m2\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;C:\Users\FangMing\.m2\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;C:\Users\FangMing\.m2\repository\commons-logging\commons-logging\1.2\commons-logging-1.2.jar;C:\Users\FangMing\.m2\repository\com\google\guava\guava\12.0.1\guava-12.0.1.jar;C:\Users\FangMing\.m2\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;C:\Users\FangMing\.m2\repository\io\netty\netty-all\4.0.23.Final\netty-all-4.0.23.Final.jar;C:\Users\FangMing\.m2\repository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;C:\Users\FangMing\.m2\repository\org\slf4j\slf4j-api\1.6.1\slf4j-api-1.6.1.jar;C:\Users\FangMing\.m2\repository\org\slf4j\slf4j-log4j12\1.6.1\slf4j-log4j12-1.6.1.jar;C:\Users\FangMing\.m2\repository\org\apache\htrace\htrace-core\3.1.0-incubating\htrace-core-3.1.0-incubating.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jackson\jackson-mapper-asl\1.9.13\jackson-mapper-asl-1.9.13.jar;C:\Users\FangMing\.m2\repository\org\jruby\jcodings\jcodings\1.0.8\jcodings-1.0.8.jar;C:\Users\FangMing\.m2\repository\org\jruby\joni\joni\2.1.2\joni-2.1.2.jar;C:\Users\FangMing\.m2\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-auth\2.5.1\hadoop-auth-2.5.1.jar;C:\Users\FangMing\.m2\repository\org\apache\httpcomponents\httpclient\4.2.5\httpclient-4.2.5.jar;C:\Users\FangMing\.m2\repository\org\apache\httpcomponents\httpcore\4.2.4\httpcore-4.2.4.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\server\apacheds-kerberos-codec\2.0.0-M15\apacheds-kerberos-codec-2.0.0-M15.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\server\apacheds-i18n\2.0.0-M15\apacheds-i18n-2.0.0-M15.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\api\api-asn1-api\1.0.0-M20\api-asn1-api-1.0.0-M20.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\api\api-util\1.0.0-M20\api-util-1.0.0-M20.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-common\2.5.1\hadoop-common-2.5.1.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-annotations\2.5.1\hadoop-annotations-2.5.1.jar;C:\Users\FangMing\.m2\repository\org\apache\commons\commons-math3\3.1.1\commons-math3-3.1.1.jar;C:\Users\FangMing\.m2\repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;C:\Users\FangMing\.m2\repository\commons-net\commons-net\3.1\commons-net-3.1.jar;C:\Users\FangMing\.m2\repository\commons-el\commons-el\1.0\commons-el-1.0.jar;C:\Users\FangMing\.m2\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;C:\Users\FangMing\.m2\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;C:\Users\FangMing\.m2\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;C:\Users\FangMing\.m2\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;C:\Users\FangMing\.m2\repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;C:\Users\FangMing\.m2\repository\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;C:\Users\FangMing\.m2\repository\org\xerial\snappy\snappy-java\1.0.4.1\snappy-java-1.0.4.1.jar;C:\Users\FangMing\.m2\repository\com\jcraft\jsch\0.1.42\jsch-0.1.42.jar;C:\Users\FangMing\.m2\repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;C:\Users\FangMing\.m2\repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;C:\Users\FangMing\.m2\repository\org\tukaani\xz\1.0\xz-1.0.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.5.1\hadoop-mapreduce-client-core-2.5.1.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-yarn-common\2.5.1\hadoop-yarn-common-2.5.1.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-yarn-api\2.5.1\hadoop-yarn-api-2.5.1.jar;C:\Users\FangMing\.m2\repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;C:\Users\FangMing\.m2\repository\javax\xml\stream\stax-api\1.0-2\stax-api-1.0-2.jar;C:\Users\FangMing\.m2\repository\javax\activation\activation\1.1\activation-1.1.jar;C:\Program Files\Java\jdk\lib\tools.jar;C:\Users\FangMing\.m2\repository\junit\junit\4.12\junit-4.12.jar;C:\Users\FangMing\.m2\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-hdfs\2.5.1\hadoop-hdfs-2.5.1.jar;C:\Users\FangMing\.m2\repository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;C:\Users\FangMing\.m2\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;C:\Users\FangMing\.m2\repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;C:\Users\FangMing\.m2\repository\com\sun\jersey\jersey-server\1.9\jersey-server-1.9.jar;C:\Users\FangMing\.m2\repository\asm\asm\3.1\asm-3.1.jar;C:\Users\FangMing\.m2\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;C:\Users\FangMing\.m2\repository\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;C:\Users\FangMing\.m2\repository\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;C:\Users\FangMing\.m2\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;C:\Users\FangMing\.m2\repository\javax\servlet\servlet-api\2.5\servlet-api-2.5.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;C:\Users\FangMing\.m2\repository\tomcat\jasper-runtime\5.5.23\jasper-runtime-5.5.23.jar;C:\Users\FangMing\.m2\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;C:\Users\FangMing\.m2\repository\io\netty\netty\3.6.2.Final\netty-3.6.2.Final.jar;/D:/dev/java/eclipseNeon2/eclipse/configuration/org.eclipse.osgi/389/0/.cp/;/D:/dev/java/eclipseNeon2/eclipse/configuration/org.eclipse.osgi/388/0/.cp/
[2017-05-18 22:19:18,241][main][INFO ]:Client environment:java.library.path=C:\Program Files\Java\jdk7\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:/Program Files/Java/jre/bin/server;C:/Program Files/Java/jre/bin;C:/Program Files/Java/jre/lib/amd64;.;D:\dev\java\libs\hadoop\hadoop-2.7.3\bin;C:\ProgramData\Oracle\Java\javapath;D:\Dev\scripts;E:\study\maven\apache-maven-3.3.9\bin;e:\study\groovy\groovy-2.4.6\bin;E:/study/gradle/gradle-default/bin;C:\Program Files\Java\jdk\bin;E:\Study\ant\apache-ant-1.9.2\bin;C:\oracle\product\11.2.0\client_1;C:\oracle\product\11.2.0\client_1\bin;C:\Program Files (x86)\AMD APP\bin\x86_64;C:\Program Files (x86)\AMD APP\bin\x86;C:\Program Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\Microsoft SQL Server\100\Tools\Binn\;C:\Program Files\Microsoft SQL Server\100\Tools\Binn\;C:\Program Files\Microsoft SQL Server\100\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\100\Tools\Binn\VSShell\Common7\IDE\;C:\Program Files (x86)\Microsoft SQL Server\100\DTS\Binn\;C:\Program Files (x86)\Microsoft Visual Studio 9.0\Common7\IDE\PrivateAssemblies\;C:\Program Files\TortoiseSVN\bin;C:\Program Files\ThinkPad\Bluetooth Software\;C:\Program Files\ThinkPad\Bluetooth Software\syswow64;C:\Program Files\VisualSVN Server\bin;C:\Program Files\Git\cmd;C:\Users\FangMing\AppData\Local\Programs\Python\Python36\Scripts\;C:\Users\FangMing\AppData\Local\Programs\Python\Python36\;D:\dev\java\eclipseNeon2\eclipse;;.
[2017-05-18 22:19:18,241][main][INFO ]:Client environment:java.io.tmpdir=C:\Users\FangMing\AppData\Local\Temp\
[2017-05-18 22:19:18,241][main][INFO ]:Client environment:java.compiler=<NA>
[2017-05-18 22:19:18,241][main][INFO ]:Client environment:os.name=Windows 7
[2017-05-18 22:19:18,241][main][INFO ]:Client environment:os.arch=amd64
[2017-05-18 22:19:18,242][main][INFO ]:Client environment:os.version=6.1
[2017-05-18 22:19:18,242][main][INFO ]:Client environment:user.name=FangMing
[2017-05-18 22:19:18,242][main][INFO ]:Client environment:user.home=C:\Users\FangMing
[2017-05-18 22:19:18,242][main][INFO ]:Client environment:user.dir=D:\dev\java\workspaces\hadoop\hbase-quickstart01
[2017-05-18 22:19:18,244][main][INFO ]:Initiating client connection, connectString=master.hadoop:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@23a620d8
[2017-05-18 22:19:18,310][main-SendThread(master.hadoop:2181)][INFO ]:Opening socket connection to server master.hadoop/192.168.1.104:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 22:19:18,321][main-SendThread(master.hadoop:2181)][INFO ]:Socket connection established to master.hadoop/192.168.1.104:2181, initiating session
[2017-05-18 22:19:18,638][main-SendThread(master.hadoop:2181)][INFO ]:Session establishment complete on server master.hadoop/192.168.1.104:2181, sessionid = 0x15c1afbf5890009, negotiated timeout = 90000
[2017-05-18 22:19:18,804][main][WARN ]:Failed to identify the fs of dir hdfs://master.hadoop:9000/hbase/lib, ignored
java.io.IOException: No FileSystem for scheme: hdfs
	at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2579)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2586)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:89)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2625)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2607)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:368)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:296)
	at org.apache.hadoop.hbase.util.DynamicClassLoader.initTempDir(DynamicClassLoader.java:120)
	at org.apache.hadoop.hbase.util.DynamicClassLoader.<init>(DynamicClassLoader.java:98)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.<clinit>(ProtobufUtil.java:246)
	at org.apache.hadoop.hbase.ClusterId.parseFrom(ClusterId.java:64)
	at org.apache.hadoop.hbase.zookeeper.ZKClusterId.readClusterIdZNode(ZKClusterId.java:75)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getClusterId(ZooKeeperRegistry.java:105)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.retrieveClusterId(ConnectionManager.java:907)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.<init>(ConnectionManager.java:691)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:238)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:218)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:119)
	at com.fsmflying.hbase01.HbaseTest01.before(HbaseTest01.java:38)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:86)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:459)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:678)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192)
[2017-05-18 22:20:27,579][main][INFO ]:Closing zookeeper sessionid=0x15c1afbf5890009
[2017-05-18 22:20:27,627][main][INFO ]:Session: 0x15c1afbf5890009 closed
[2017-05-18 22:20:27,629][main-EventThread][INFO ]:EventThread shut down
[2017-05-18 22:23:03,425][main][INFO ]:Process identifier=hconnection-0x643b0560 connecting to ZooKeeper ensemble=master.hadoop:2181
[2017-05-18 22:23:03,532][main][INFO ]:Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
[2017-05-18 22:23:03,533][main][INFO ]:Client environment:host.name=FANGMING-THINK
[2017-05-18 22:23:03,534][main][INFO ]:Client environment:java.version=1.7.0_79
[2017-05-18 22:23:03,534][main][INFO ]:Client environment:java.vendor=Oracle Corporation
[2017-05-18 22:23:03,534][main][INFO ]:Client environment:java.home=C:\Program Files\Java\jdk7\jre
[2017-05-18 22:23:03,535][main][INFO ]:Client environment:java.class.path=D:\dev\java\workspaces\hadoop\hbase-quickstart01\target\test-classes;D:\dev\java\workspaces\hadoop\hbase-quickstart01\target\classes;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-client\1.3.1\hbase-client-1.3.1.jar;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-annotations\1.3.1\hbase-annotations-1.3.1.jar;C:\Users\FangMing\.m2\repository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-common\1.3.1\hbase-common-1.3.1.jar;C:\Users\FangMing\.m2\repository\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-protocol\1.3.1\hbase-protocol-1.3.1.jar;C:\Users\FangMing\.m2\repository\commons-codec\commons-codec\1.9\commons-codec-1.9.jar;C:\Users\FangMing\.m2\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;C:\Users\FangMing\.m2\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;C:\Users\FangMing\.m2\repository\commons-logging\commons-logging\1.2\commons-logging-1.2.jar;C:\Users\FangMing\.m2\repository\com\google\guava\guava\12.0.1\guava-12.0.1.jar;C:\Users\FangMing\.m2\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;C:\Users\FangMing\.m2\repository\io\netty\netty-all\4.0.23.Final\netty-all-4.0.23.Final.jar;C:\Users\FangMing\.m2\repository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;C:\Users\FangMing\.m2\repository\org\slf4j\slf4j-api\1.6.1\slf4j-api-1.6.1.jar;C:\Users\FangMing\.m2\repository\org\slf4j\slf4j-log4j12\1.6.1\slf4j-log4j12-1.6.1.jar;C:\Users\FangMing\.m2\repository\org\apache\htrace\htrace-core\3.1.0-incubating\htrace-core-3.1.0-incubating.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jackson\jackson-mapper-asl\1.9.13\jackson-mapper-asl-1.9.13.jar;C:\Users\FangMing\.m2\repository\org\jruby\jcodings\jcodings\1.0.8\jcodings-1.0.8.jar;C:\Users\FangMing\.m2\repository\org\jruby\joni\joni\2.1.2\joni-2.1.2.jar;C:\Users\FangMing\.m2\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-auth\2.5.1\hadoop-auth-2.5.1.jar;C:\Users\FangMing\.m2\repository\org\apache\httpcomponents\httpclient\4.2.5\httpclient-4.2.5.jar;C:\Users\FangMing\.m2\repository\org\apache\httpcomponents\httpcore\4.2.4\httpcore-4.2.4.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\server\apacheds-kerberos-codec\2.0.0-M15\apacheds-kerberos-codec-2.0.0-M15.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\server\apacheds-i18n\2.0.0-M15\apacheds-i18n-2.0.0-M15.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\api\api-asn1-api\1.0.0-M20\api-asn1-api-1.0.0-M20.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\api\api-util\1.0.0-M20\api-util-1.0.0-M20.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-common\2.5.1\hadoop-common-2.5.1.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-annotations\2.5.1\hadoop-annotations-2.5.1.jar;C:\Users\FangMing\.m2\repository\org\apache\commons\commons-math3\3.1.1\commons-math3-3.1.1.jar;C:\Users\FangMing\.m2\repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;C:\Users\FangMing\.m2\repository\commons-net\commons-net\3.1\commons-net-3.1.jar;C:\Users\FangMing\.m2\repository\commons-el\commons-el\1.0\commons-el-1.0.jar;C:\Users\FangMing\.m2\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;C:\Users\FangMing\.m2\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;C:\Users\FangMing\.m2\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;C:\Users\FangMing\.m2\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;C:\Users\FangMing\.m2\repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;C:\Users\FangMing\.m2\repository\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;C:\Users\FangMing\.m2\repository\org\xerial\snappy\snappy-java\1.0.4.1\snappy-java-1.0.4.1.jar;C:\Users\FangMing\.m2\repository\com\jcraft\jsch\0.1.42\jsch-0.1.42.jar;C:\Users\FangMing\.m2\repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;C:\Users\FangMing\.m2\repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;C:\Users\FangMing\.m2\repository\org\tukaani\xz\1.0\xz-1.0.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.5.1\hadoop-mapreduce-client-core-2.5.1.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-yarn-common\2.5.1\hadoop-yarn-common-2.5.1.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-yarn-api\2.5.1\hadoop-yarn-api-2.5.1.jar;C:\Users\FangMing\.m2\repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;C:\Users\FangMing\.m2\repository\javax\xml\stream\stax-api\1.0-2\stax-api-1.0-2.jar;C:\Users\FangMing\.m2\repository\javax\activation\activation\1.1\activation-1.1.jar;C:\Program Files\Java\jdk\lib\tools.jar;C:\Users\FangMing\.m2\repository\junit\junit\4.12\junit-4.12.jar;C:\Users\FangMing\.m2\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-hdfs\2.5.1\hadoop-hdfs-2.5.1.jar;C:\Users\FangMing\.m2\repository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;C:\Users\FangMing\.m2\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;C:\Users\FangMing\.m2\repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;C:\Users\FangMing\.m2\repository\com\sun\jersey\jersey-server\1.9\jersey-server-1.9.jar;C:\Users\FangMing\.m2\repository\asm\asm\3.1\asm-3.1.jar;C:\Users\FangMing\.m2\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;C:\Users\FangMing\.m2\repository\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;C:\Users\FangMing\.m2\repository\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;C:\Users\FangMing\.m2\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;C:\Users\FangMing\.m2\repository\javax\servlet\servlet-api\2.5\servlet-api-2.5.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;C:\Users\FangMing\.m2\repository\tomcat\jasper-runtime\5.5.23\jasper-runtime-5.5.23.jar;C:\Users\FangMing\.m2\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;C:\Users\FangMing\.m2\repository\io\netty\netty\3.6.2.Final\netty-3.6.2.Final.jar;/D:/dev/java/eclipseNeon2/eclipse/configuration/org.eclipse.osgi/389/0/.cp/;/D:/dev/java/eclipseNeon2/eclipse/configuration/org.eclipse.osgi/388/0/.cp/
[2017-05-18 22:23:03,537][main][INFO ]:Client environment:java.library.path=C:\Program Files\Java\jdk7\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:/Program Files/Java/jre/bin/server;C:/Program Files/Java/jre/bin;C:/Program Files/Java/jre/lib/amd64;.;D:\dev\java\libs\hadoop\hadoop-2.7.3\bin;C:\ProgramData\Oracle\Java\javapath;D:\Dev\scripts;E:\study\maven\apache-maven-3.3.9\bin;e:\study\groovy\groovy-2.4.6\bin;E:/study/gradle/gradle-default/bin;C:\Program Files\Java\jdk\bin;E:\Study\ant\apache-ant-1.9.2\bin;C:\oracle\product\11.2.0\client_1;C:\oracle\product\11.2.0\client_1\bin;C:\Program Files (x86)\AMD APP\bin\x86_64;C:\Program Files (x86)\AMD APP\bin\x86;C:\Program Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\Microsoft SQL Server\100\Tools\Binn\;C:\Program Files\Microsoft SQL Server\100\Tools\Binn\;C:\Program Files\Microsoft SQL Server\100\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\100\Tools\Binn\VSShell\Common7\IDE\;C:\Program Files (x86)\Microsoft SQL Server\100\DTS\Binn\;C:\Program Files (x86)\Microsoft Visual Studio 9.0\Common7\IDE\PrivateAssemblies\;C:\Program Files\TortoiseSVN\bin;C:\Program Files\ThinkPad\Bluetooth Software\;C:\Program Files\ThinkPad\Bluetooth Software\syswow64;C:\Program Files\VisualSVN Server\bin;C:\Program Files\Git\cmd;C:\Users\FangMing\AppData\Local\Programs\Python\Python36\Scripts\;C:\Users\FangMing\AppData\Local\Programs\Python\Python36\;D:\dev\java\eclipseNeon2\eclipse;;.
[2017-05-18 22:23:03,539][main][INFO ]:Client environment:java.io.tmpdir=C:\Users\FangMing\AppData\Local\Temp\
[2017-05-18 22:23:03,541][main][INFO ]:Client environment:java.compiler=<NA>
[2017-05-18 22:23:03,541][main][INFO ]:Client environment:os.name=Windows 7
[2017-05-18 22:23:03,542][main][INFO ]:Client environment:os.arch=amd64
[2017-05-18 22:23:03,542][main][INFO ]:Client environment:os.version=6.1
[2017-05-18 22:23:03,542][main][INFO ]:Client environment:user.name=FangMing
[2017-05-18 22:23:03,543][main][INFO ]:Client environment:user.home=C:\Users\FangMing
[2017-05-18 22:23:03,543][main][INFO ]:Client environment:user.dir=D:\dev\java\workspaces\hadoop\hbase-quickstart01
[2017-05-18 22:23:03,552][main][INFO ]:Initiating client connection, connectString=master.hadoop:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@29c19925
[2017-05-18 22:23:04,119][main-SendThread(master.hadoop:2181)][INFO ]:Opening socket connection to server master.hadoop/192.168.1.104:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 22:23:04,136][main-SendThread(master.hadoop:2181)][INFO ]:Socket connection established to master.hadoop/192.168.1.104:2181, initiating session
[2017-05-18 22:23:04,293][main-SendThread(master.hadoop:2181)][INFO ]:Session establishment complete on server master.hadoop/192.168.1.104:2181, sessionid = 0x15c1afbf589000a, negotiated timeout = 90000
[2017-05-18 22:23:05,233][main][INFO ]:Closing zookeeper sessionid=0x15c1afbf589000a
[2017-05-18 22:23:05,308][main][INFO ]:Session: 0x15c1afbf589000a closed
[2017-05-18 22:23:05,354][main-EventThread][INFO ]:EventThread shut down
[2017-05-18 22:25:52,134][main][INFO ]:Process identifier=hconnection-0x33bd9009 connecting to ZooKeeper ensemble=master.hadoop:2181
[2017-05-18 22:25:52,142][main][INFO ]:Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
[2017-05-18 22:25:52,142][main][INFO ]:Client environment:host.name=FANGMING-THINK
[2017-05-18 22:25:52,143][main][INFO ]:Client environment:java.version=1.7.0_79
[2017-05-18 22:25:52,143][main][INFO ]:Client environment:java.vendor=Oracle Corporation
[2017-05-18 22:25:52,143][main][INFO ]:Client environment:java.home=C:\Program Files\Java\jdk7\jre
[2017-05-18 22:25:52,143][main][INFO ]:Client environment:java.class.path=D:\dev\java\workspaces\hadoop\hbase-quickstart01\target\test-classes;D:\dev\java\workspaces\hadoop\hbase-quickstart01\target\classes;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-client\1.3.1\hbase-client-1.3.1.jar;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-annotations\1.3.1\hbase-annotations-1.3.1.jar;C:\Users\FangMing\.m2\repository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-common\1.3.1\hbase-common-1.3.1.jar;C:\Users\FangMing\.m2\repository\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-protocol\1.3.1\hbase-protocol-1.3.1.jar;C:\Users\FangMing\.m2\repository\commons-codec\commons-codec\1.9\commons-codec-1.9.jar;C:\Users\FangMing\.m2\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;C:\Users\FangMing\.m2\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;C:\Users\FangMing\.m2\repository\commons-logging\commons-logging\1.2\commons-logging-1.2.jar;C:\Users\FangMing\.m2\repository\com\google\guava\guava\12.0.1\guava-12.0.1.jar;C:\Users\FangMing\.m2\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;C:\Users\FangMing\.m2\repository\io\netty\netty-all\4.0.23.Final\netty-all-4.0.23.Final.jar;C:\Users\FangMing\.m2\repository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;C:\Users\FangMing\.m2\repository\org\slf4j\slf4j-api\1.6.1\slf4j-api-1.6.1.jar;C:\Users\FangMing\.m2\repository\org\slf4j\slf4j-log4j12\1.6.1\slf4j-log4j12-1.6.1.jar;C:\Users\FangMing\.m2\repository\org\apache\htrace\htrace-core\3.1.0-incubating\htrace-core-3.1.0-incubating.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jackson\jackson-mapper-asl\1.9.13\jackson-mapper-asl-1.9.13.jar;C:\Users\FangMing\.m2\repository\org\jruby\jcodings\jcodings\1.0.8\jcodings-1.0.8.jar;C:\Users\FangMing\.m2\repository\org\jruby\joni\joni\2.1.2\joni-2.1.2.jar;C:\Users\FangMing\.m2\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-auth\2.5.1\hadoop-auth-2.5.1.jar;C:\Users\FangMing\.m2\repository\org\apache\httpcomponents\httpclient\4.2.5\httpclient-4.2.5.jar;C:\Users\FangMing\.m2\repository\org\apache\httpcomponents\httpcore\4.2.4\httpcore-4.2.4.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\server\apacheds-kerberos-codec\2.0.0-M15\apacheds-kerberos-codec-2.0.0-M15.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\server\apacheds-i18n\2.0.0-M15\apacheds-i18n-2.0.0-M15.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\api\api-asn1-api\1.0.0-M20\api-asn1-api-1.0.0-M20.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\api\api-util\1.0.0-M20\api-util-1.0.0-M20.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-common\2.5.1\hadoop-common-2.5.1.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-annotations\2.5.1\hadoop-annotations-2.5.1.jar;C:\Users\FangMing\.m2\repository\org\apache\commons\commons-math3\3.1.1\commons-math3-3.1.1.jar;C:\Users\FangMing\.m2\repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;C:\Users\FangMing\.m2\repository\commons-net\commons-net\3.1\commons-net-3.1.jar;C:\Users\FangMing\.m2\repository\commons-el\commons-el\1.0\commons-el-1.0.jar;C:\Users\FangMing\.m2\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;C:\Users\FangMing\.m2\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;C:\Users\FangMing\.m2\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;C:\Users\FangMing\.m2\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;C:\Users\FangMing\.m2\repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;C:\Users\FangMing\.m2\repository\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;C:\Users\FangMing\.m2\repository\org\xerial\snappy\snappy-java\1.0.4.1\snappy-java-1.0.4.1.jar;C:\Users\FangMing\.m2\repository\com\jcraft\jsch\0.1.42\jsch-0.1.42.jar;C:\Users\FangMing\.m2\repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;C:\Users\FangMing\.m2\repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;C:\Users\FangMing\.m2\repository\org\tukaani\xz\1.0\xz-1.0.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.5.1\hadoop-mapreduce-client-core-2.5.1.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-yarn-common\2.5.1\hadoop-yarn-common-2.5.1.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-yarn-api\2.5.1\hadoop-yarn-api-2.5.1.jar;C:\Users\FangMing\.m2\repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;C:\Users\FangMing\.m2\repository\javax\xml\stream\stax-api\1.0-2\stax-api-1.0-2.jar;C:\Users\FangMing\.m2\repository\javax\activation\activation\1.1\activation-1.1.jar;C:\Program Files\Java\jdk\lib\tools.jar;C:\Users\FangMing\.m2\repository\junit\junit\4.12\junit-4.12.jar;C:\Users\FangMing\.m2\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-hdfs\2.7.3\hadoop-hdfs-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;C:\Users\FangMing\.m2\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;C:\Users\FangMing\.m2\repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;C:\Users\FangMing\.m2\repository\com\sun\jersey\jersey-server\1.9\jersey-server-1.9.jar;C:\Users\FangMing\.m2\repository\asm\asm\3.1\asm-3.1.jar;C:\Users\FangMing\.m2\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;C:\Users\FangMing\.m2\repository\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;C:\Users\FangMing\.m2\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;C:\Users\FangMing\.m2\repository\javax\servlet\servlet-api\2.5\servlet-api-2.5.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;C:\Users\FangMing\.m2\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;C:\Users\FangMing\.m2\repository\io\netty\netty\3.6.2.Final\netty-3.6.2.Final.jar;C:\Users\FangMing\.m2\repository\xerces\xercesImpl\2.9.1\xercesImpl-2.9.1.jar;C:\Users\FangMing\.m2\repository\xml-apis\xml-apis\1.3.04\xml-apis-1.3.04.jar;C:\Users\FangMing\.m2\repository\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;/D:/dev/java/eclipseNeon2/eclipse/configuration/org.eclipse.osgi/389/0/.cp/;/D:/dev/java/eclipseNeon2/eclipse/configuration/org.eclipse.osgi/388/0/.cp/
[2017-05-18 22:25:52,143][main][INFO ]:Client environment:java.library.path=C:\Program Files\Java\jdk7\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:/Program Files/Java/jre/bin/server;C:/Program Files/Java/jre/bin;C:/Program Files/Java/jre/lib/amd64;.;D:\dev\java\libs\hadoop\hadoop-2.7.3\bin;C:\ProgramData\Oracle\Java\javapath;D:\Dev\scripts;E:\study\maven\apache-maven-3.3.9\bin;e:\study\groovy\groovy-2.4.6\bin;E:/study/gradle/gradle-default/bin;C:\Program Files\Java\jdk\bin;E:\Study\ant\apache-ant-1.9.2\bin;C:\oracle\product\11.2.0\client_1;C:\oracle\product\11.2.0\client_1\bin;C:\Program Files (x86)\AMD APP\bin\x86_64;C:\Program Files (x86)\AMD APP\bin\x86;C:\Program Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\Microsoft SQL Server\100\Tools\Binn\;C:\Program Files\Microsoft SQL Server\100\Tools\Binn\;C:\Program Files\Microsoft SQL Server\100\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\100\Tools\Binn\VSShell\Common7\IDE\;C:\Program Files (x86)\Microsoft SQL Server\100\DTS\Binn\;C:\Program Files (x86)\Microsoft Visual Studio 9.0\Common7\IDE\PrivateAssemblies\;C:\Program Files\TortoiseSVN\bin;C:\Program Files\ThinkPad\Bluetooth Software\;C:\Program Files\ThinkPad\Bluetooth Software\syswow64;C:\Program Files\VisualSVN Server\bin;C:\Program Files\Git\cmd;C:\Users\FangMing\AppData\Local\Programs\Python\Python36\Scripts\;C:\Users\FangMing\AppData\Local\Programs\Python\Python36\;D:\dev\java\eclipseNeon2\eclipse;;.
[2017-05-18 22:25:52,144][main][INFO ]:Client environment:java.io.tmpdir=C:\Users\FangMing\AppData\Local\Temp\
[2017-05-18 22:25:52,144][main][INFO ]:Client environment:java.compiler=<NA>
[2017-05-18 22:25:52,144][main][INFO ]:Client environment:os.name=Windows 7
[2017-05-18 22:25:52,144][main][INFO ]:Client environment:os.arch=amd64
[2017-05-18 22:25:52,144][main][INFO ]:Client environment:os.version=6.1
[2017-05-18 22:25:52,144][main][INFO ]:Client environment:user.name=FangMing
[2017-05-18 22:25:52,144][main][INFO ]:Client environment:user.home=C:\Users\FangMing
[2017-05-18 22:25:52,144][main][INFO ]:Client environment:user.dir=D:\dev\java\workspaces\hadoop\hbase-quickstart01
[2017-05-18 22:25:52,146][main][INFO ]:Initiating client connection, connectString=master.hadoop:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@755fd06f
[2017-05-18 22:25:52,191][main-SendThread(master.hadoop:2181)][INFO ]:Opening socket connection to server master.hadoop/192.168.1.104:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 22:25:52,209][main-SendThread(master.hadoop:2181)][INFO ]:Socket connection established to master.hadoop/192.168.1.104:2181, initiating session
[2017-05-18 22:25:52,375][main-SendThread(master.hadoop:2181)][INFO ]:Session establishment complete on server master.hadoop/192.168.1.104:2181, sessionid = 0x15c1afbf589000b, negotiated timeout = 90000
[2017-05-18 22:25:53,168][main][INFO ]:Closing zookeeper sessionid=0x15c1afbf589000b
[2017-05-18 22:25:53,172][main][INFO ]:Session: 0x15c1afbf589000b closed
[2017-05-18 22:25:53,177][main-EventThread][INFO ]:EventThread shut down
[2017-05-18 22:39:03,420][main][INFO ]:Process identifier=hconnection-0xfcad25c connecting to ZooKeeper ensemble=master.hadoop:2181
[2017-05-18 22:39:03,427][main][INFO ]:Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
[2017-05-18 22:39:03,428][main][INFO ]:Client environment:host.name=FANGMING-THINK
[2017-05-18 22:39:03,428][main][INFO ]:Client environment:java.version=1.7.0_79
[2017-05-18 22:39:03,428][main][INFO ]:Client environment:java.vendor=Oracle Corporation
[2017-05-18 22:39:03,428][main][INFO ]:Client environment:java.home=C:\Program Files\Java\jdk7\jre
[2017-05-18 22:39:03,428][main][INFO ]:Client environment:java.class.path=D:\dev\java\workspaces\hadoop\hbase-quickstart01\target\test-classes;D:\dev\java\workspaces\hadoop\hbase-quickstart01\target\classes;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-client\1.3.1\hbase-client-1.3.1.jar;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-annotations\1.3.1\hbase-annotations-1.3.1.jar;C:\Users\FangMing\.m2\repository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-common\1.3.1\hbase-common-1.3.1.jar;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-protocol\1.3.1\hbase-protocol-1.3.1.jar;C:\Users\FangMing\.m2\repository\commons-codec\commons-codec\1.9\commons-codec-1.9.jar;C:\Users\FangMing\.m2\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;C:\Users\FangMing\.m2\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;C:\Users\FangMing\.m2\repository\commons-logging\commons-logging\1.2\commons-logging-1.2.jar;C:\Users\FangMing\.m2\repository\com\google\guava\guava\12.0.1\guava-12.0.1.jar;C:\Users\FangMing\.m2\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;C:\Users\FangMing\.m2\repository\io\netty\netty-all\4.0.23.Final\netty-all-4.0.23.Final.jar;C:\Users\FangMing\.m2\repository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;C:\Users\FangMing\.m2\repository\org\apache\htrace\htrace-core\3.1.0-incubating\htrace-core-3.1.0-incubating.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jackson\jackson-mapper-asl\1.9.13\jackson-mapper-asl-1.9.13.jar;C:\Users\FangMing\.m2\repository\org\jruby\jcodings\jcodings\1.0.8\jcodings-1.0.8.jar;C:\Users\FangMing\.m2\repository\org\jruby\joni\joni\2.1.2\joni-2.1.2.jar;C:\Users\FangMing\.m2\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\Program Files\Java\jdk\lib\tools.jar;C:\Users\FangMing\.m2\repository\junit\junit\4.12\junit-4.12.jar;C:\Users\FangMing\.m2\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-common\2.7.3\hadoop-common-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-annotations\2.7.3\hadoop-annotations-2.7.3.jar;C:\Users\FangMing\.m2\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;C:\Users\FangMing\.m2\repository\org\apache\commons\commons-math3\3.1.1\commons-math3-3.1.1.jar;C:\Users\FangMing\.m2\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;C:\Users\FangMing\.m2\repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;C:\Users\FangMing\.m2\repository\commons-net\commons-net\3.1\commons-net-3.1.jar;C:\Users\FangMing\.m2\repository\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;C:\Users\FangMing\.m2\repository\javax\servlet\servlet-api\2.5\servlet-api-2.5.jar;C:\Users\FangMing\.m2\repository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;C:\Users\FangMing\.m2\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;C:\Users\FangMing\.m2\repository\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;C:\Users\FangMing\.m2\repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;C:\Users\FangMing\.m2\repository\com\sun\jersey\jersey-json\1.9\jersey-json-1.9.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;C:\Users\FangMing\.m2\repository\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;C:\Users\FangMing\.m2\repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;C:\Users\FangMing\.m2\repository\javax\xml\stream\stax-api\1.0-2\stax-api-1.0-2.jar;C:\Users\FangMing\.m2\repository\javax\activation\activation\1.1\activation-1.1.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jackson\jackson-jaxrs\1.8.3\jackson-jaxrs-1.8.3.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jackson\jackson-xc\1.8.3\jackson-xc-1.8.3.jar;C:\Users\FangMing\.m2\repository\com\sun\jersey\jersey-server\1.9\jersey-server-1.9.jar;C:\Users\FangMing\.m2\repository\asm\asm\3.1\asm-3.1.jar;C:\Users\FangMing\.m2\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;C:\Users\FangMing\.m2\repository\net\java\dev\jets3t\jets3t\0.9.0\jets3t-0.9.0.jar;C:\Users\FangMing\.m2\repository\org\apache\httpcomponents\httpclient\4.1.2\httpclient-4.1.2.jar;C:\Users\FangMing\.m2\repository\org\apache\httpcomponents\httpcore\4.1.2\httpcore-4.1.2.jar;C:\Users\FangMing\.m2\repository\com\jamesmurty\utils\java-xmlbuilder\0.4\java-xmlbuilder-0.4.jar;C:\Users\FangMing\.m2\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;C:\Users\FangMing\.m2\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;C:\Users\FangMing\.m2\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;C:\Users\FangMing\.m2\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;C:\Users\FangMing\.m2\repository\org\slf4j\slf4j-api\1.7.10\slf4j-api-1.7.10.jar;C:\Users\FangMing\.m2\repository\org\slf4j\slf4j-log4j12\1.7.10\slf4j-log4j12-1.7.10.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;C:\Users\FangMing\.m2\repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;C:\Users\FangMing\.m2\repository\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;C:\Users\FangMing\.m2\repository\org\xerial\snappy\snappy-java\1.0.4.1\snappy-java-1.0.4.1.jar;C:\Users\FangMing\.m2\repository\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-auth\2.7.3\hadoop-auth-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\server\apacheds-kerberos-codec\2.0.0-M15\apacheds-kerberos-codec-2.0.0-M15.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\server\apacheds-i18n\2.0.0-M15\apacheds-i18n-2.0.0-M15.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\api\api-asn1-api\1.0.0-M20\api-asn1-api-1.0.0-M20.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\api\api-util\1.0.0-M20\api-util-1.0.0-M20.jar;C:\Users\FangMing\.m2\repository\org\apache\curator\curator-framework\2.7.1\curator-framework-2.7.1.jar;C:\Users\FangMing\.m2\repository\com\jcraft\jsch\0.1.42\jsch-0.1.42.jar;C:\Users\FangMing\.m2\repository\org\apache\curator\curator-client\2.7.1\curator-client-2.7.1.jar;C:\Users\FangMing\.m2\repository\org\apache\curator\curator-recipes\2.7.1\curator-recipes-2.7.1.jar;C:\Users\FangMing\.m2\repository\com\google\code\findbugs\jsr305\3.0.0\jsr305-3.0.0.jar;C:\Users\FangMing\.m2\repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;C:\Users\FangMing\.m2\repository\org\tukaani\xz\1.0\xz-1.0.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-client\2.7.3\hadoop-client-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-hdfs\2.7.3\hadoop-hdfs-2.7.3.jar;C:\Users\FangMing\.m2\repository\io\netty\netty\3.6.2.Final\netty-3.6.2.Final.jar;C:\Users\FangMing\.m2\repository\xerces\xercesImpl\2.9.1\xercesImpl-2.9.1.jar;C:\Users\FangMing\.m2\repository\xml-apis\xml-apis\1.3.04\xml-apis-1.3.04.jar;C:\Users\FangMing\.m2\repository\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.7.3\hadoop-mapreduce-client-app-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.7.3\hadoop-mapreduce-client-common-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-yarn-client\2.7.3\hadoop-yarn-client-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-yarn-server-common\2.7.3\hadoop-yarn-server-common-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.7.3\hadoop-mapreduce-client-shuffle-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-yarn-api\2.7.3\hadoop-yarn-api-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.7.3\hadoop-mapreduce-client-core-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-yarn-common\2.7.3\hadoop-yarn-common-2.7.3.jar;C:\Users\FangMing\.m2\repository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.7.3\hadoop-mapreduce-client-jobclient-2.7.3.jar;/D:/dev/java/eclipseNeon2/eclipse/configuration/org.eclipse.osgi/389/0/.cp/;/D:/dev/java/eclipseNeon2/eclipse/configuration/org.eclipse.osgi/388/0/.cp/
[2017-05-18 22:39:03,429][main][INFO ]:Client environment:java.library.path=C:\Program Files\Java\jdk7\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:/Program Files/Java/jre/bin/server;C:/Program Files/Java/jre/bin;C:/Program Files/Java/jre/lib/amd64;.;D:\dev\java\libs\hadoop\hadoop-2.7.3\bin;C:\ProgramData\Oracle\Java\javapath;D:\Dev\scripts;E:\study\maven\apache-maven-3.3.9\bin;e:\study\groovy\groovy-2.4.6\bin;E:/study/gradle/gradle-default/bin;C:\Program Files\Java\jdk\bin;E:\Study\ant\apache-ant-1.9.2\bin;C:\oracle\product\11.2.0\client_1;C:\oracle\product\11.2.0\client_1\bin;C:\Program Files (x86)\AMD APP\bin\x86_64;C:\Program Files (x86)\AMD APP\bin\x86;C:\Program Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\Microsoft SQL Server\100\Tools\Binn\;C:\Program Files\Microsoft SQL Server\100\Tools\Binn\;C:\Program Files\Microsoft SQL Server\100\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\100\Tools\Binn\VSShell\Common7\IDE\;C:\Program Files (x86)\Microsoft SQL Server\100\DTS\Binn\;C:\Program Files (x86)\Microsoft Visual Studio 9.0\Common7\IDE\PrivateAssemblies\;C:\Program Files\TortoiseSVN\bin;C:\Program Files\ThinkPad\Bluetooth Software\;C:\Program Files\ThinkPad\Bluetooth Software\syswow64;C:\Program Files\VisualSVN Server\bin;C:\Program Files\Git\cmd;C:\Users\FangMing\AppData\Local\Programs\Python\Python36\Scripts\;C:\Users\FangMing\AppData\Local\Programs\Python\Python36\;D:\dev\java\eclipseNeon2\eclipse;;.
[2017-05-18 22:39:03,429][main][INFO ]:Client environment:java.io.tmpdir=C:\Users\FangMing\AppData\Local\Temp\
[2017-05-18 22:39:03,429][main][INFO ]:Client environment:java.compiler=<NA>
[2017-05-18 22:39:03,429][main][INFO ]:Client environment:os.name=Windows 7
[2017-05-18 22:39:03,429][main][INFO ]:Client environment:os.arch=amd64
[2017-05-18 22:39:03,429][main][INFO ]:Client environment:os.version=6.1
[2017-05-18 22:39:03,429][main][INFO ]:Client environment:user.name=FangMing
[2017-05-18 22:39:03,429][main][INFO ]:Client environment:user.home=C:\Users\FangMing
[2017-05-18 22:39:03,429][main][INFO ]:Client environment:user.dir=D:\dev\java\workspaces\hadoop\hbase-quickstart01
[2017-05-18 22:39:03,430][main][INFO ]:Initiating client connection, connectString=master.hadoop:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@78281cee
[2017-05-18 22:39:03,470][main-SendThread(master.hadoop:2181)][INFO ]:Opening socket connection to server master.hadoop/192.168.1.104:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 22:39:03,472][main-SendThread(master.hadoop:2181)][INFO ]:Socket connection established to master.hadoop/192.168.1.104:2181, initiating session
[2017-05-18 22:39:03,725][main-SendThread(master.hadoop:2181)][INFO ]:Session establishment complete on server master.hadoop/192.168.1.104:2181, sessionid = 0x15c1afbf589000c, negotiated timeout = 90000
[2017-05-18 22:40:15,895][main][INFO ]:Closing zookeeper sessionid=0x15c1afbf589000c
[2017-05-18 22:40:16,014][main][INFO ]:Session: 0x15c1afbf589000c closed
[2017-05-18 22:40:16,017][main-EventThread][INFO ]:EventThread shut down
[2017-05-18 22:40:48,913][main][INFO ]:Process identifier=hconnection-0x4635bd2a connecting to ZooKeeper ensemble=master.hadoop:2181
[2017-05-18 22:40:48,923][main][INFO ]:Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
[2017-05-18 22:40:48,923][main][INFO ]:Client environment:host.name=FANGMING-THINK
[2017-05-18 22:40:48,923][main][INFO ]:Client environment:java.version=1.7.0_79
[2017-05-18 22:40:48,923][main][INFO ]:Client environment:java.vendor=Oracle Corporation
[2017-05-18 22:40:48,923][main][INFO ]:Client environment:java.home=C:\Program Files\Java\jdk7\jre
[2017-05-18 22:40:48,923][main][INFO ]:Client environment:java.class.path=D:\dev\java\workspaces\hadoop\hbase-quickstart01\target\test-classes;D:\dev\java\workspaces\hadoop\hbase-quickstart01\target\classes;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-client\1.3.1\hbase-client-1.3.1.jar;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-annotations\1.3.1\hbase-annotations-1.3.1.jar;C:\Users\FangMing\.m2\repository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-common\1.3.1\hbase-common-1.3.1.jar;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-protocol\1.3.1\hbase-protocol-1.3.1.jar;C:\Users\FangMing\.m2\repository\commons-codec\commons-codec\1.9\commons-codec-1.9.jar;C:\Users\FangMing\.m2\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;C:\Users\FangMing\.m2\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;C:\Users\FangMing\.m2\repository\commons-logging\commons-logging\1.2\commons-logging-1.2.jar;C:\Users\FangMing\.m2\repository\com\google\guava\guava\12.0.1\guava-12.0.1.jar;C:\Users\FangMing\.m2\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;C:\Users\FangMing\.m2\repository\io\netty\netty-all\4.0.23.Final\netty-all-4.0.23.Final.jar;C:\Users\FangMing\.m2\repository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;C:\Users\FangMing\.m2\repository\org\apache\htrace\htrace-core\3.1.0-incubating\htrace-core-3.1.0-incubating.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jackson\jackson-mapper-asl\1.9.13\jackson-mapper-asl-1.9.13.jar;C:\Users\FangMing\.m2\repository\org\jruby\jcodings\jcodings\1.0.8\jcodings-1.0.8.jar;C:\Users\FangMing\.m2\repository\org\jruby\joni\joni\2.1.2\joni-2.1.2.jar;C:\Users\FangMing\.m2\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\Program Files\Java\jdk\lib\tools.jar;C:\Users\FangMing\.m2\repository\junit\junit\4.12\junit-4.12.jar;C:\Users\FangMing\.m2\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-common\2.7.3\hadoop-common-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-annotations\2.7.3\hadoop-annotations-2.7.3.jar;C:\Users\FangMing\.m2\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;C:\Users\FangMing\.m2\repository\org\apache\commons\commons-math3\3.1.1\commons-math3-3.1.1.jar;C:\Users\FangMing\.m2\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;C:\Users\FangMing\.m2\repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;C:\Users\FangMing\.m2\repository\commons-net\commons-net\3.1\commons-net-3.1.jar;C:\Users\FangMing\.m2\repository\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;C:\Users\FangMing\.m2\repository\javax\servlet\servlet-api\2.5\servlet-api-2.5.jar;C:\Users\FangMing\.m2\repository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;C:\Users\FangMing\.m2\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;C:\Users\FangMing\.m2\repository\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;C:\Users\FangMing\.m2\repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;C:\Users\FangMing\.m2\repository\com\sun\jersey\jersey-json\1.9\jersey-json-1.9.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;C:\Users\FangMing\.m2\repository\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;C:\Users\FangMing\.m2\repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;C:\Users\FangMing\.m2\repository\javax\xml\stream\stax-api\1.0-2\stax-api-1.0-2.jar;C:\Users\FangMing\.m2\repository\javax\activation\activation\1.1\activation-1.1.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jackson\jackson-jaxrs\1.8.3\jackson-jaxrs-1.8.3.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jackson\jackson-xc\1.8.3\jackson-xc-1.8.3.jar;C:\Users\FangMing\.m2\repository\com\sun\jersey\jersey-server\1.9\jersey-server-1.9.jar;C:\Users\FangMing\.m2\repository\asm\asm\3.1\asm-3.1.jar;C:\Users\FangMing\.m2\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;C:\Users\FangMing\.m2\repository\net\java\dev\jets3t\jets3t\0.9.0\jets3t-0.9.0.jar;C:\Users\FangMing\.m2\repository\org\apache\httpcomponents\httpclient\4.1.2\httpclient-4.1.2.jar;C:\Users\FangMing\.m2\repository\org\apache\httpcomponents\httpcore\4.1.2\httpcore-4.1.2.jar;C:\Users\FangMing\.m2\repository\com\jamesmurty\utils\java-xmlbuilder\0.4\java-xmlbuilder-0.4.jar;C:\Users\FangMing\.m2\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;C:\Users\FangMing\.m2\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;C:\Users\FangMing\.m2\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;C:\Users\FangMing\.m2\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;C:\Users\FangMing\.m2\repository\org\slf4j\slf4j-api\1.7.10\slf4j-api-1.7.10.jar;C:\Users\FangMing\.m2\repository\org\slf4j\slf4j-log4j12\1.7.10\slf4j-log4j12-1.7.10.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;C:\Users\FangMing\.m2\repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;C:\Users\FangMing\.m2\repository\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;C:\Users\FangMing\.m2\repository\org\xerial\snappy\snappy-java\1.0.4.1\snappy-java-1.0.4.1.jar;C:\Users\FangMing\.m2\repository\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-auth\2.7.3\hadoop-auth-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\server\apacheds-kerberos-codec\2.0.0-M15\apacheds-kerberos-codec-2.0.0-M15.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\server\apacheds-i18n\2.0.0-M15\apacheds-i18n-2.0.0-M15.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\api\api-asn1-api\1.0.0-M20\api-asn1-api-1.0.0-M20.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\api\api-util\1.0.0-M20\api-util-1.0.0-M20.jar;C:\Users\FangMing\.m2\repository\org\apache\curator\curator-framework\2.7.1\curator-framework-2.7.1.jar;C:\Users\FangMing\.m2\repository\com\jcraft\jsch\0.1.42\jsch-0.1.42.jar;C:\Users\FangMing\.m2\repository\org\apache\curator\curator-client\2.7.1\curator-client-2.7.1.jar;C:\Users\FangMing\.m2\repository\org\apache\curator\curator-recipes\2.7.1\curator-recipes-2.7.1.jar;C:\Users\FangMing\.m2\repository\com\google\code\findbugs\jsr305\3.0.0\jsr305-3.0.0.jar;C:\Users\FangMing\.m2\repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;C:\Users\FangMing\.m2\repository\org\tukaani\xz\1.0\xz-1.0.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-client\2.7.3\hadoop-client-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-hdfs\2.7.3\hadoop-hdfs-2.7.3.jar;C:\Users\FangMing\.m2\repository\io\netty\netty\3.6.2.Final\netty-3.6.2.Final.jar;C:\Users\FangMing\.m2\repository\xerces\xercesImpl\2.9.1\xercesImpl-2.9.1.jar;C:\Users\FangMing\.m2\repository\xml-apis\xml-apis\1.3.04\xml-apis-1.3.04.jar;C:\Users\FangMing\.m2\repository\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.7.3\hadoop-mapreduce-client-app-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.7.3\hadoop-mapreduce-client-common-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-yarn-client\2.7.3\hadoop-yarn-client-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-yarn-server-common\2.7.3\hadoop-yarn-server-common-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.7.3\hadoop-mapreduce-client-shuffle-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-yarn-api\2.7.3\hadoop-yarn-api-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.7.3\hadoop-mapreduce-client-core-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-yarn-common\2.7.3\hadoop-yarn-common-2.7.3.jar;C:\Users\FangMing\.m2\repository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.7.3\hadoop-mapreduce-client-jobclient-2.7.3.jar;/D:/dev/java/eclipseNeon2/eclipse/configuration/org.eclipse.osgi/389/0/.cp/;/D:/dev/java/eclipseNeon2/eclipse/configuration/org.eclipse.osgi/388/0/.cp/
[2017-05-18 22:40:48,924][main][INFO ]:Client environment:java.library.path=C:\Program Files\Java\jdk7\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:/Program Files/Java/jre/bin/server;C:/Program Files/Java/jre/bin;C:/Program Files/Java/jre/lib/amd64;.;D:\dev\java\libs\hadoop\hadoop-2.7.3\bin;C:\ProgramData\Oracle\Java\javapath;D:\Dev\scripts;E:\study\maven\apache-maven-3.3.9\bin;e:\study\groovy\groovy-2.4.6\bin;E:/study/gradle/gradle-default/bin;C:\Program Files\Java\jdk\bin;E:\Study\ant\apache-ant-1.9.2\bin;C:\oracle\product\11.2.0\client_1;C:\oracle\product\11.2.0\client_1\bin;C:\Program Files (x86)\AMD APP\bin\x86_64;C:\Program Files (x86)\AMD APP\bin\x86;C:\Program Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\Microsoft SQL Server\100\Tools\Binn\;C:\Program Files\Microsoft SQL Server\100\Tools\Binn\;C:\Program Files\Microsoft SQL Server\100\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\100\Tools\Binn\VSShell\Common7\IDE\;C:\Program Files (x86)\Microsoft SQL Server\100\DTS\Binn\;C:\Program Files (x86)\Microsoft Visual Studio 9.0\Common7\IDE\PrivateAssemblies\;C:\Program Files\TortoiseSVN\bin;C:\Program Files\ThinkPad\Bluetooth Software\;C:\Program Files\ThinkPad\Bluetooth Software\syswow64;C:\Program Files\VisualSVN Server\bin;C:\Program Files\Git\cmd;C:\Users\FangMing\AppData\Local\Programs\Python\Python36\Scripts\;C:\Users\FangMing\AppData\Local\Programs\Python\Python36\;D:\dev\java\eclipseNeon2\eclipse;;.
[2017-05-18 22:40:48,924][main][INFO ]:Client environment:java.io.tmpdir=C:\Users\FangMing\AppData\Local\Temp\
[2017-05-18 22:40:48,924][main][INFO ]:Client environment:java.compiler=<NA>
[2017-05-18 22:40:48,924][main][INFO ]:Client environment:os.name=Windows 7
[2017-05-18 22:40:48,924][main][INFO ]:Client environment:os.arch=amd64
[2017-05-18 22:40:48,924][main][INFO ]:Client environment:os.version=6.1
[2017-05-18 22:40:48,924][main][INFO ]:Client environment:user.name=FangMing
[2017-05-18 22:40:48,924][main][INFO ]:Client environment:user.home=C:\Users\FangMing
[2017-05-18 22:40:48,924][main][INFO ]:Client environment:user.dir=D:\dev\java\workspaces\hadoop\hbase-quickstart01
[2017-05-18 22:40:48,925][main][INFO ]:Initiating client connection, connectString=master.hadoop:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@7d6a05fd
[2017-05-18 22:40:48,965][main-SendThread(master.hadoop:2181)][INFO ]:Opening socket connection to server master.hadoop/192.168.1.104:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-18 22:40:48,997][main-SendThread(master.hadoop:2181)][INFO ]:Socket connection established to master.hadoop/192.168.1.104:2181, initiating session
[2017-05-18 22:40:49,147][main-SendThread(master.hadoop:2181)][INFO ]:Session establishment complete on server master.hadoop/192.168.1.104:2181, sessionid = 0x15c1afbf589000d, negotiated timeout = 90000
[2017-05-18 22:41:59,264][main][INFO ]:Closing zookeeper sessionid=0x15c1afbf589000d
[2017-05-18 22:41:59,379][main][INFO ]:Session: 0x15c1afbf589000d closed
[2017-05-18 22:41:59,381][main-EventThread][INFO ]:EventThread shut down
[2017-05-19 00:54:51,328][main][DEBUG]: Creating new Groups object
[2017-05-19 00:54:51,515][main][DEBUG]:Trying to load the custom-built native-hadoop library...
[2017-05-19 00:54:51,567][main][DEBUG]:Loaded the native-hadoop library
[2017-05-19 00:54:51,568][main][DEBUG]:Using JniBasedUnixGroupsMapping for Group resolution
[2017-05-19 00:54:51,568][main][DEBUG]:Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
[2017-05-19 00:54:51,828][main][DEBUG]:Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
[2017-05-19 00:54:52,272][main][DEBUG]:field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[Rate of successful kerberos logins and latency (milliseconds)], type=DEFAULT, always=false, sampleName=Ops)
[2017-05-19 00:54:52,291][main][DEBUG]:field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[Rate of failed kerberos logins and latency (milliseconds)], type=DEFAULT, always=false, sampleName=Ops)
[2017-05-19 00:54:52,291][main][DEBUG]:field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[GetGroups], type=DEFAULT, always=false, sampleName=Ops)
[2017-05-19 00:54:52,293][main][DEBUG]:UgiMetrics, User and group related metrics
[2017-05-19 00:54:52,759][main][DEBUG]:Kerberos krb5 configuration not found, setting default realm to empty
[2017-05-19 00:54:52,811][main][DEBUG]:hadoop login
[2017-05-19 00:54:52,812][main][DEBUG]:hadoop login commit
[2017-05-19 00:54:52,833][main][DEBUG]:using local user:NTUserPrincipal: FangMing
[2017-05-19 00:54:52,833][main][DEBUG]:Using user: "NTUserPrincipal: FangMing" with name FangMing
[2017-05-19 00:54:52,833][main][DEBUG]:User entry: "FangMing"
[2017-05-19 00:54:52,835][main][DEBUG]:UGI loginUser:FangMing (auth:SIMPLE)
[2017-05-19 00:54:53,532][main][INFO ]:Process identifier=hconnection-0x142c7195 connecting to ZooKeeper ensemble=master.hadoop:2181
[2017-05-19 00:54:53,546][main][INFO ]:Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
[2017-05-19 00:54:53,546][main][INFO ]:Client environment:host.name=FANGMING-THINK
[2017-05-19 00:54:53,546][main][INFO ]:Client environment:java.version=1.7.0_79
[2017-05-19 00:54:53,546][main][INFO ]:Client environment:java.vendor=Oracle Corporation
[2017-05-19 00:54:53,546][main][INFO ]:Client environment:java.home=C:\Program Files\Java\jdk7\jre
[2017-05-19 00:54:53,546][main][INFO ]:Client environment:java.class.path=D:\dev\java\workspaces\hadoop\hbase-quickstart01\target\test-classes;D:\dev\java\workspaces\hadoop\hbase-quickstart01\target\classes;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-client\1.3.1\hbase-client-1.3.1.jar;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-annotations\1.3.1\hbase-annotations-1.3.1.jar;C:\Users\FangMing\.m2\repository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-common\1.3.1\hbase-common-1.3.1.jar;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-protocol\1.3.1\hbase-protocol-1.3.1.jar;C:\Users\FangMing\.m2\repository\commons-codec\commons-codec\1.9\commons-codec-1.9.jar;C:\Users\FangMing\.m2\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;C:\Users\FangMing\.m2\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;C:\Users\FangMing\.m2\repository\commons-logging\commons-logging\1.2\commons-logging-1.2.jar;C:\Users\FangMing\.m2\repository\com\google\guava\guava\12.0.1\guava-12.0.1.jar;C:\Users\FangMing\.m2\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;C:\Users\FangMing\.m2\repository\io\netty\netty-all\4.0.23.Final\netty-all-4.0.23.Final.jar;C:\Users\FangMing\.m2\repository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;C:\Users\FangMing\.m2\repository\org\apache\htrace\htrace-core\3.1.0-incubating\htrace-core-3.1.0-incubating.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jackson\jackson-mapper-asl\1.9.13\jackson-mapper-asl-1.9.13.jar;C:\Users\FangMing\.m2\repository\org\jruby\jcodings\jcodings\1.0.8\jcodings-1.0.8.jar;C:\Users\FangMing\.m2\repository\org\jruby\joni\joni\2.1.2\joni-2.1.2.jar;C:\Users\FangMing\.m2\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\Program Files\Java\jdk\lib\tools.jar;C:\Users\FangMing\.m2\repository\junit\junit\4.12\junit-4.12.jar;C:\Users\FangMing\.m2\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-common\2.7.3\hadoop-common-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-annotations\2.7.3\hadoop-annotations-2.7.3.jar;C:\Users\FangMing\.m2\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;C:\Users\FangMing\.m2\repository\org\apache\commons\commons-math3\3.1.1\commons-math3-3.1.1.jar;C:\Users\FangMing\.m2\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;C:\Users\FangMing\.m2\repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;C:\Users\FangMing\.m2\repository\commons-net\commons-net\3.1\commons-net-3.1.jar;C:\Users\FangMing\.m2\repository\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;C:\Users\FangMing\.m2\repository\javax\servlet\servlet-api\2.5\servlet-api-2.5.jar;C:\Users\FangMing\.m2\repository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;C:\Users\FangMing\.m2\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;C:\Users\FangMing\.m2\repository\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;C:\Users\FangMing\.m2\repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;C:\Users\FangMing\.m2\repository\com\sun\jersey\jersey-json\1.9\jersey-json-1.9.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;C:\Users\FangMing\.m2\repository\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jackson\jackson-jaxrs\1.8.3\jackson-jaxrs-1.8.3.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jackson\jackson-xc\1.8.3\jackson-xc-1.8.3.jar;C:\Users\FangMing\.m2\repository\com\sun\jersey\jersey-server\1.9\jersey-server-1.9.jar;C:\Users\FangMing\.m2\repository\asm\asm\3.1\asm-3.1.jar;C:\Users\FangMing\.m2\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;C:\Users\FangMing\.m2\repository\net\java\dev\jets3t\jets3t\0.9.0\jets3t-0.9.0.jar;C:\Users\FangMing\.m2\repository\org\apache\httpcomponents\httpcore\4.1.2\httpcore-4.1.2.jar;C:\Users\FangMing\.m2\repository\com\jamesmurty\utils\java-xmlbuilder\0.4\java-xmlbuilder-0.4.jar;C:\Users\FangMing\.m2\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;C:\Users\FangMing\.m2\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;C:\Users\FangMing\.m2\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;C:\Users\FangMing\.m2\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;C:\Users\FangMing\.m2\repository\org\slf4j\slf4j-api\1.7.10\slf4j-api-1.7.10.jar;C:\Users\FangMing\.m2\repository\org\slf4j\slf4j-log4j12\1.7.10\slf4j-log4j12-1.7.10.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;C:\Users\FangMing\.m2\repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;C:\Users\FangMing\.m2\repository\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;C:\Users\FangMing\.m2\repository\org\xerial\snappy\snappy-java\1.0.4.1\snappy-java-1.0.4.1.jar;C:\Users\FangMing\.m2\repository\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;C:\Users\FangMing\.m2\repository\com\jcraft\jsch\0.1.42\jsch-0.1.42.jar;C:\Users\FangMing\.m2\repository\org\apache\curator\curator-client\2.7.1\curator-client-2.7.1.jar;C:\Users\FangMing\.m2\repository\org\apache\curator\curator-recipes\2.7.1\curator-recipes-2.7.1.jar;C:\Users\FangMing\.m2\repository\com\google\code\findbugs\jsr305\3.0.0\jsr305-3.0.0.jar;C:\Users\FangMing\.m2\repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;C:\Users\FangMing\.m2\repository\org\tukaani\xz\1.0\xz-1.0.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-client\2.7.3\hadoop-client-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-hdfs\2.7.3\hadoop-hdfs-2.7.3.jar;C:\Users\FangMing\.m2\repository\xerces\xercesImpl\2.9.1\xercesImpl-2.9.1.jar;C:\Users\FangMing\.m2\repository\xml-apis\xml-apis\1.3.04\xml-apis-1.3.04.jar;C:\Users\FangMing\.m2\repository\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.7.3\hadoop-mapreduce-client-app-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.7.3\hadoop-mapreduce-client-common-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-yarn-client\2.7.3\hadoop-yarn-client-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-yarn-server-common\2.7.3\hadoop-yarn-server-common-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.7.3\hadoop-mapreduce-client-shuffle-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-yarn-api\2.7.3\hadoop-yarn-api-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.7.3\hadoop-mapreduce-client-jobclient-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.7.3\hadoop-mapreduce-client-core-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-yarn-common\2.7.3\hadoop-yarn-common-2.7.3.jar;C:\Users\FangMing\.m2\repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;C:\Users\FangMing\.m2\repository\javax\xml\stream\stax-api\1.0-2\stax-api-1.0-2.jar;C:\Users\FangMing\.m2\repository\javax\activation\activation\1.1\activation-1.1.jar;C:\Users\FangMing\.m2\repository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;C:\Users\FangMing\.m2\repository\com\google\inject\guice\3.0\guice-3.0.jar;C:\Users\FangMing\.m2\repository\javax\inject\javax.inject\1\javax.inject-1.jar;C:\Users\FangMing\.m2\repository\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;C:\Users\FangMing\.m2\repository\com\sun\jersey\contribs\jersey-guice\1.9\jersey-guice-1.9.jar;C:\Users\FangMing\.m2\repository\com\google\inject\extensions\guice-servlet\3.0\guice-servlet-3.0.jar;C:\Users\FangMing\.m2\repository\io\netty\netty\3.6.2.Final\netty-3.6.2.Final.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-auth\2.7.3\hadoop-auth-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\httpcomponents\httpclient\4.2.5\httpclient-4.2.5.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\server\apacheds-kerberos-codec\2.0.0-M15\apacheds-kerberos-codec-2.0.0-M15.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\server\apacheds-i18n\2.0.0-M15\apacheds-i18n-2.0.0-M15.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\api\api-asn1-api\1.0.0-M20\api-asn1-api-1.0.0-M20.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\api\api-util\1.0.0-M20\api-util-1.0.0-M20.jar;C:\Users\FangMing\.m2\repository\org\apache\curator\curator-framework\2.7.1\curator-framework-2.7.1.jar;/D:/dev/java/eclipseNeon2/eclipse/configuration/org.eclipse.osgi/389/0/.cp/;/D:/dev/java/eclipseNeon2/eclipse/configuration/org.eclipse.osgi/388/0/.cp/
[2017-05-19 00:54:53,547][main][INFO ]:Client environment:java.library.path=C:\Program Files\Java\jdk7\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:/Program Files/Java/jre/bin/server;C:/Program Files/Java/jre/bin;C:/Program Files/Java/jre/lib/amd64;.;D:\dev\java\libs\hadoop\hadoop-2.7.3\bin;C:\ProgramData\Oracle\Java\javapath;D:\Dev\scripts;E:\study\maven\apache-maven-3.3.9\bin;e:\study\groovy\groovy-2.4.6\bin;E:/study/gradle/gradle-default/bin;C:\Program Files\Java\jdk\bin;E:\Study\ant\apache-ant-1.9.2\bin;C:\oracle\product\11.2.0\client_1;C:\oracle\product\11.2.0\client_1\bin;C:\Program Files (x86)\AMD APP\bin\x86_64;C:\Program Files (x86)\AMD APP\bin\x86;C:\Program Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\Microsoft SQL Server\100\Tools\Binn\;C:\Program Files\Microsoft SQL Server\100\Tools\Binn\;C:\Program Files\Microsoft SQL Server\100\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\100\Tools\Binn\VSShell\Common7\IDE\;C:\Program Files (x86)\Microsoft SQL Server\100\DTS\Binn\;C:\Program Files (x86)\Microsoft Visual Studio 9.0\Common7\IDE\PrivateAssemblies\;C:\Program Files\TortoiseSVN\bin;C:\Program Files\ThinkPad\Bluetooth Software\;C:\Program Files\ThinkPad\Bluetooth Software\syswow64;C:\Program Files\VisualSVN Server\bin;C:\Program Files\Git\cmd;C:\Users\FangMing\AppData\Local\Programs\Python\Python36\Scripts\;C:\Users\FangMing\AppData\Local\Programs\Python\Python36\;D:\dev\java\eclipseNeon2\eclipse;;.
[2017-05-19 00:54:53,548][main][INFO ]:Client environment:java.io.tmpdir=C:\Users\FangMing\AppData\Local\Temp\
[2017-05-19 00:54:53,548][main][INFO ]:Client environment:java.compiler=<NA>
[2017-05-19 00:54:53,548][main][INFO ]:Client environment:os.name=Windows 7
[2017-05-19 00:54:53,548][main][INFO ]:Client environment:os.arch=amd64
[2017-05-19 00:54:53,548][main][INFO ]:Client environment:os.version=6.1
[2017-05-19 00:54:53,548][main][INFO ]:Client environment:user.name=FangMing
[2017-05-19 00:54:53,548][main][INFO ]:Client environment:user.home=C:\Users\FangMing
[2017-05-19 00:54:53,548][main][INFO ]:Client environment:user.dir=D:\dev\java\workspaces\hadoop\hbase-quickstart01
[2017-05-19 00:54:53,550][main][INFO ]:Initiating client connection, connectString=master.hadoop:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@654a1209
[2017-05-19 00:54:53,556][main][DEBUG]:zookeeper.disableAutoWatchReset is false
[2017-05-19 00:54:53,746][main-SendThread(master.hadoop:2181)][INFO ]:Opening socket connection to server master.hadoop/192.168.1.104:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-19 00:54:53,749][main-SendThread(master.hadoop:2181)][INFO ]:Socket connection established to master.hadoop/192.168.1.104:2181, initiating session
[2017-05-19 00:54:53,754][main-SendThread(master.hadoop:2181)][DEBUG]:Session establishment request sent on master.hadoop/192.168.1.104:2181
[2017-05-19 00:54:53,921][main-SendThread(master.hadoop:2181)][INFO ]:Session establishment complete on server master.hadoop/192.168.1.104:2181, sessionid = 0x15c1c68faa20006, negotiated timeout = 90000
[2017-05-19 00:54:53,938][main-EventThread][DEBUG]:hconnection-0x142c71950x0, quorum=master.hadoop:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
[2017-05-19 00:54:53,939][main-EventThread][DEBUG]:hconnection-0x142c7195-0x15c1c68faa20006 connected
[2017-05-19 00:54:53,952][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20006, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,238,0  request:: '/hbase/hbaseid,F  response:: s{17,201,1495101357287,1495125278719,1,0,0,0,67,0,17} 
[2017-05-19 00:54:53,956][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20006, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,238,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffffa1ffffffee3fffffffb5fffffff8ffffff95ffffffeeffffffc350425546a2465636135643364302d656165392d346238332d396665612d613662653530373465623331,s{17,201,1495101357287,1495125278719,1,0,0,0,67,0,17} 
[2017-05-19 00:54:54,525][main][DEBUG]:dfs.client.use.legacy.blockreader.local = false
[2017-05-19 00:54:54,525][main][DEBUG]:dfs.client.read.shortcircuit = false
[2017-05-19 00:54:54,525][main][DEBUG]:dfs.client.domain.socket.data.traffic = false
[2017-05-19 00:54:54,525][main][DEBUG]:dfs.domain.socket.path = 
[2017-05-19 00:54:54,653][main][DEBUG]:multipleLinearRandomRetry = null
[2017-05-19 00:54:54,691][main][DEBUG]:rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@70d109de
[2017-05-19 00:54:55,163][main][DEBUG]:getting client out of cache: org.apache.hadoop.ipc.Client@4715f3c5
[2017-05-19 00:54:55,634][main][DEBUG]:Both short-circuit local reads and UNIX domain socket are disabled.
[2017-05-19 00:54:55,643][main][DEBUG]:DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
[2017-05-19 00:54:55,772][main][DEBUG]:Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@55df60a, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
[2017-05-19 00:54:55,933][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20006, packet:: clientPath:null serverPath:null finished:false header:: 3,4  replyHeader:: 3,238,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136323031fffffff366ffffffeeffffff9affffffc71525ffffffcb50425546a19ad6d61737465722e6861646f6f7010ffffffc97e18ffffff87ffffffa8ffffffa4ffffffe3ffffffc12b100183,s{216,216,1495125288124,1495125288124,0,0,0,0,66,0,216} 
[2017-05-19 00:54:56,003][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20006, packet:: clientPath:null serverPath:null finished:false header:: 4,8  replyHeader:: 4,238,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
[2017-05-19 00:54:56,543][hconnection-0x142c7195-shared--pool1-t1][DEBUG]:Use SIMPLE authentication for service ClientService, sasl=false
[2017-05-19 00:54:56,624][hconnection-0x142c7195-shared--pool1-t1][DEBUG]:Connecting to master.hadoop/192.168.1.104:16201
[2017-05-19 00:55:06,737][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20006, packet:: clientPath:null serverPath:null finished:false header:: 5,4  replyHeader:: 5,238,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136323031fffffff366ffffffeeffffff9affffffc71525ffffffcb50425546a19ad6d61737465722e6861646f6f7010ffffffc97e18ffffff87ffffffa8ffffffa4ffffffe3ffffffc12b100183,s{216,216,1495125288124,1495125288124,0,0,0,0,66,0,216} 
[2017-05-19 00:55:06,738][main-SendThread(master.hadoop:2181)][DEBUG]:Got ping response for sessionid: 0x15c1c68faa20006 after 2ms
[2017-05-19 00:55:06,739][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20006, packet:: clientPath:null serverPath:null finished:false header:: 6,8  replyHeader:: 6,238,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
[2017-05-19 00:55:06,740][hconnection-0x142c7195-shared--pool1-t1][DEBUG]:Use SIMPLE authentication for service ClientService, sasl=false
[2017-05-19 00:55:06,740][hconnection-0x142c7195-shared--pool1-t1][DEBUG]:Not trying to connect to master.hadoop/192.168.1.104:16201 this server is in the failed servers list
[2017-05-19 00:55:06,975][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20006, packet:: clientPath:null serverPath:null finished:false header:: 7,4  replyHeader:: 7,238,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136323031fffffff366ffffffeeffffff9affffffc71525ffffffcb50425546a19ad6d61737465722e6861646f6f7010ffffffc97e18ffffff87ffffffa8ffffffa4ffffffe3ffffffc12b100183,s{216,216,1495125288124,1495125288124,0,0,0,0,66,0,216} 
[2017-05-19 00:55:06,977][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20006, packet:: clientPath:null serverPath:null finished:false header:: 8,8  replyHeader:: 8,238,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
[2017-05-19 00:55:06,978][hconnection-0x142c7195-shared--pool1-t1][DEBUG]:Use SIMPLE authentication for service ClientService, sasl=false
[2017-05-19 00:55:06,978][hconnection-0x142c7195-shared--pool1-t1][DEBUG]:Not trying to connect to master.hadoop/192.168.1.104:16201 this server is in the failed servers list
[2017-05-19 00:55:07,281][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20006, packet:: clientPath:null serverPath:null finished:false header:: 9,4  replyHeader:: 9,238,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136323031fffffff366ffffffeeffffff9affffffc71525ffffffcb50425546a19ad6d61737465722e6861646f6f7010ffffffc97e18ffffff87ffffffa8ffffffa4ffffffe3ffffffc12b100183,s{216,216,1495125288124,1495125288124,0,0,0,0,66,0,216} 
[2017-05-19 00:55:07,283][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20006, packet:: clientPath:null serverPath:null finished:false header:: 10,8  replyHeader:: 10,238,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
[2017-05-19 00:55:07,284][hconnection-0x142c7195-shared--pool1-t1][DEBUG]:Use SIMPLE authentication for service ClientService, sasl=false
[2017-05-19 00:55:07,284][hconnection-0x142c7195-shared--pool1-t1][DEBUG]:Not trying to connect to master.hadoop/192.168.1.104:16201 this server is in the failed servers list
[2017-05-19 00:55:07,790][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20006, packet:: clientPath:null serverPath:null finished:false header:: 11,4  replyHeader:: 11,238,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136323031fffffff366ffffffeeffffff9affffffc71525ffffffcb50425546a19ad6d61737465722e6861646f6f7010ffffffc97e18ffffff87ffffffa8ffffffa4ffffffe3ffffffc12b100183,s{216,216,1495125288124,1495125288124,0,0,0,0,66,0,216} 
[2017-05-19 00:55:07,792][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20006, packet:: clientPath:null serverPath:null finished:false header:: 12,8  replyHeader:: 12,238,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
[2017-05-19 00:55:07,792][hconnection-0x142c7195-shared--pool1-t1][DEBUG]:Use SIMPLE authentication for service ClientService, sasl=false
[2017-05-19 00:55:07,793][hconnection-0x142c7195-shared--pool1-t1][DEBUG]:Not trying to connect to master.hadoop/192.168.1.104:16201 this server is in the failed servers list
[2017-05-19 00:55:08,795][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20006, packet:: clientPath:null serverPath:null finished:false header:: 13,4  replyHeader:: 13,238,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136323031fffffff366ffffffeeffffff9affffffc71525ffffffcb50425546a19ad6d61737465722e6861646f6f7010ffffffc97e18ffffff87ffffffa8ffffffa4ffffffe3ffffffc12b100183,s{216,216,1495125288124,1495125288124,0,0,0,0,66,0,216} 
[2017-05-19 00:55:08,797][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20006, packet:: clientPath:null serverPath:null finished:false header:: 14,8  replyHeader:: 14,238,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
[2017-05-19 00:55:08,798][hconnection-0x142c7195-shared--pool1-t1][DEBUG]:Use SIMPLE authentication for service ClientService, sasl=false
[2017-05-19 00:55:08,799][hconnection-0x142c7195-shared--pool1-t1][DEBUG]:Connecting to master.hadoop/192.168.1.104:16201
[2017-05-19 00:55:20,821][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20006, packet:: clientPath:null serverPath:null finished:false header:: 15,4  replyHeader:: 15,238,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136323031fffffff366ffffffeeffffff9affffffc71525ffffffcb50425546a19ad6d61737465722e6861646f6f7010ffffffc97e18ffffff87ffffffa8ffffffa4ffffffe3ffffffc12b100183,s{216,216,1495125288124,1495125288124,0,0,0,0,66,0,216} 
[2017-05-19 00:55:20,821][main-SendThread(master.hadoop:2181)][DEBUG]:Got ping response for sessionid: 0x15c1c68faa20006 after 1ms
[2017-05-19 00:55:20,823][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20006, packet:: clientPath:null serverPath:null finished:false header:: 16,8  replyHeader:: 16,238,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
[2017-05-19 00:55:20,824][hconnection-0x142c7195-shared--pool1-t1][DEBUG]:Use SIMPLE authentication for service ClientService, sasl=false
[2017-05-19 00:55:20,824][hconnection-0x142c7195-shared--pool1-t1][DEBUG]:Connecting to master.hadoop/192.168.1.104:16201
[2017-05-19 00:55:34,838][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20006, packet:: clientPath:null serverPath:null finished:false header:: 17,4  replyHeader:: 17,238,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136323031fffffff366ffffffeeffffff9affffffc71525ffffffcb50425546a19ad6d61737465722e6861646f6f7010ffffffc97e18ffffff87ffffffa8ffffffa4ffffffe3ffffffc12b100183,s{216,216,1495125288124,1495125288124,0,0,0,0,66,0,216} 
[2017-05-19 00:55:34,839][main-SendThread(master.hadoop:2181)][DEBUG]:Got ping response for sessionid: 0x15c1c68faa20006 after 2ms
[2017-05-19 00:55:34,841][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20006, packet:: clientPath:null serverPath:null finished:false header:: 18,8  replyHeader:: 18,238,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
[2017-05-19 00:55:34,842][hconnection-0x142c7195-shared--pool1-t1][DEBUG]:Use SIMPLE authentication for service ClientService, sasl=false
[2017-05-19 00:55:34,842][hconnection-0x142c7195-shared--pool1-t1][DEBUG]:Connecting to master.hadoop/192.168.1.104:16201
[2017-05-19 00:55:54,896][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20006, packet:: clientPath:null serverPath:null finished:false header:: 19,4  replyHeader:: 19,238,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136323031fffffff366ffffffeeffffff9affffffc71525ffffffcb50425546a19ad6d61737465722e6861646f6f7010ffffffc97e18ffffff87ffffffa8ffffffa4ffffffe3ffffffc12b100183,s{216,216,1495125288124,1495125288124,0,0,0,0,66,0,216} 
[2017-05-19 00:55:54,896][main-SendThread(master.hadoop:2181)][DEBUG]:Got ping response for sessionid: 0x15c1c68faa20006 after 1ms
[2017-05-19 00:55:54,898][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20006, packet:: clientPath:null serverPath:null finished:false header:: 20,8  replyHeader:: 20,238,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
[2017-05-19 00:55:54,899][hconnection-0x142c7195-shared--pool1-t1][DEBUG]:Use SIMPLE authentication for service ClientService, sasl=false
[2017-05-19 00:55:54,899][hconnection-0x142c7195-shared--pool1-t1][DEBUG]:Connecting to master.hadoop/192.168.1.104:16201
[2017-05-19 00:56:04,931][main][INFO ]:Closing zookeeper sessionid=0x15c1c68faa20006
[2017-05-19 00:56:04,932][main][DEBUG]:Closing session: 0x15c1c68faa20006
[2017-05-19 00:56:04,932][main][DEBUG]:Closing client for session: 0x15c1c68faa20006
[2017-05-19 00:56:04,972][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20006, packet:: clientPath:null serverPath:null finished:false header:: 21,-11  replyHeader:: 21,239,0  request:: null response:: null
[2017-05-19 00:56:04,972][main][DEBUG]:Disconnecting client for session: 0x15c1c68faa20006
[2017-05-19 00:56:04,973][main][INFO ]:Session: 0x15c1c68faa20006 closed
[2017-05-19 00:56:04,973][main][DEBUG]:Stopping rpc client
[2017-05-19 00:56:04,977][main-EventThread][INFO ]:EventThread shut down
[2017-05-19 00:56:05,069][Thread-3][DEBUG]:stopping client from cache: org.apache.hadoop.ipc.Client@4715f3c5
[2017-05-19 00:56:05,069][Thread-3][DEBUG]:removing client from cache: org.apache.hadoop.ipc.Client@4715f3c5
[2017-05-19 00:56:05,069][Thread-3][DEBUG]:stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@4715f3c5
[2017-05-19 00:56:05,069][Thread-3][DEBUG]:Stopping client
[2017-05-19 01:02:26,043][main][DEBUG]: Creating new Groups object
[2017-05-19 01:02:26,106][main][DEBUG]:Trying to load the custom-built native-hadoop library...
[2017-05-19 01:02:26,111][main][DEBUG]:Loaded the native-hadoop library
[2017-05-19 01:02:26,112][main][DEBUG]:Using JniBasedUnixGroupsMapping for Group resolution
[2017-05-19 01:02:26,113][main][DEBUG]:Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
[2017-05-19 01:02:26,338][main][DEBUG]:Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
[2017-05-19 01:02:26,560][main][DEBUG]:field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)], about=, always=false, type=DEFAULT, sampleName=Ops)
[2017-05-19 01:02:26,579][main][DEBUG]:field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)], about=, always=false, type=DEFAULT, sampleName=Ops)
[2017-05-19 01:02:26,579][main][DEBUG]:field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[GetGroups], about=, always=false, type=DEFAULT, sampleName=Ops)
[2017-05-19 01:02:26,581][main][DEBUG]:UgiMetrics, User and group related metrics
[2017-05-19 01:02:26,808][main][DEBUG]:Kerberos krb5 configuration not found, setting default realm to empty
[2017-05-19 01:02:26,817][main][DEBUG]:hadoop login
[2017-05-19 01:02:26,818][main][DEBUG]:hadoop login commit
[2017-05-19 01:02:26,827][main][DEBUG]:using local user:NTUserPrincipal: FangMing
[2017-05-19 01:02:26,827][main][DEBUG]:Using user: "NTUserPrincipal: FangMing" with name FangMing
[2017-05-19 01:02:26,827][main][DEBUG]:User entry: "FangMing"
[2017-05-19 01:02:26,828][main][DEBUG]:UGI loginUser:FangMing (auth:SIMPLE)
[2017-05-19 01:02:27,361][main][INFO ]:Process identifier=hconnection-0xec2f1e1 connecting to ZooKeeper ensemble=master.hadoop:2181
[2017-05-19 01:02:27,368][main][INFO ]:Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
[2017-05-19 01:02:27,368][main][INFO ]:Client environment:host.name=FANGMING-THINK
[2017-05-19 01:02:27,368][main][INFO ]:Client environment:java.version=1.7.0_79
[2017-05-19 01:02:27,368][main][INFO ]:Client environment:java.vendor=Oracle Corporation
[2017-05-19 01:02:27,368][main][INFO ]:Client environment:java.home=C:\Program Files\Java\jdk7\jre
[2017-05-19 01:02:27,368][main][INFO ]:Client environment:java.class.path=D:\dev\java\workspaces\hadoop\hbase-quickstart01\target\test-classes;D:\dev\java\workspaces\hadoop\hbase-quickstart01\target\classes;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-client\1.3.1\hbase-client-1.3.1.jar;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-annotations\1.3.1\hbase-annotations-1.3.1.jar;C:\Users\FangMing\.m2\repository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-common\1.3.1\hbase-common-1.3.1.jar;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-protocol\1.3.1\hbase-protocol-1.3.1.jar;C:\Users\FangMing\.m2\repository\commons-codec\commons-codec\1.9\commons-codec-1.9.jar;C:\Users\FangMing\.m2\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;C:\Users\FangMing\.m2\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;C:\Users\FangMing\.m2\repository\commons-logging\commons-logging\1.2\commons-logging-1.2.jar;C:\Users\FangMing\.m2\repository\com\google\guava\guava\12.0.1\guava-12.0.1.jar;C:\Users\FangMing\.m2\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;C:\Users\FangMing\.m2\repository\io\netty\netty-all\4.0.23.Final\netty-all-4.0.23.Final.jar;C:\Users\FangMing\.m2\repository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;C:\Users\FangMing\.m2\repository\org\apache\htrace\htrace-core\3.1.0-incubating\htrace-core-3.1.0-incubating.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jackson\jackson-mapper-asl\1.9.13\jackson-mapper-asl-1.9.13.jar;C:\Users\FangMing\.m2\repository\org\jruby\jcodings\jcodings\1.0.8\jcodings-1.0.8.jar;C:\Users\FangMing\.m2\repository\org\jruby\joni\joni\2.1.2\joni-2.1.2.jar;C:\Users\FangMing\.m2\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\Program Files\Java\jdk\lib\tools.jar;C:\Users\FangMing\.m2\repository\junit\junit\4.12\junit-4.12.jar;C:\Users\FangMing\.m2\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-common\2.7.3\hadoop-common-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-annotations\2.7.3\hadoop-annotations-2.7.3.jar;C:\Users\FangMing\.m2\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;C:\Users\FangMing\.m2\repository\org\apache\commons\commons-math3\3.1.1\commons-math3-3.1.1.jar;C:\Users\FangMing\.m2\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;C:\Users\FangMing\.m2\repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;C:\Users\FangMing\.m2\repository\commons-net\commons-net\3.1\commons-net-3.1.jar;C:\Users\FangMing\.m2\repository\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;C:\Users\FangMing\.m2\repository\javax\servlet\servlet-api\2.5\servlet-api-2.5.jar;C:\Users\FangMing\.m2\repository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;C:\Users\FangMing\.m2\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;C:\Users\FangMing\.m2\repository\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;C:\Users\FangMing\.m2\repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;C:\Users\FangMing\.m2\repository\com\sun\jersey\jersey-json\1.9\jersey-json-1.9.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;C:\Users\FangMing\.m2\repository\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jackson\jackson-jaxrs\1.8.3\jackson-jaxrs-1.8.3.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jackson\jackson-xc\1.8.3\jackson-xc-1.8.3.jar;C:\Users\FangMing\.m2\repository\com\sun\jersey\jersey-server\1.9\jersey-server-1.9.jar;C:\Users\FangMing\.m2\repository\asm\asm\3.1\asm-3.1.jar;C:\Users\FangMing\.m2\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;C:\Users\FangMing\.m2\repository\net\java\dev\jets3t\jets3t\0.9.0\jets3t-0.9.0.jar;C:\Users\FangMing\.m2\repository\org\apache\httpcomponents\httpcore\4.1.2\httpcore-4.1.2.jar;C:\Users\FangMing\.m2\repository\com\jamesmurty\utils\java-xmlbuilder\0.4\java-xmlbuilder-0.4.jar;C:\Users\FangMing\.m2\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;C:\Users\FangMing\.m2\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;C:\Users\FangMing\.m2\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;C:\Users\FangMing\.m2\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;C:\Users\FangMing\.m2\repository\org\slf4j\slf4j-api\1.7.10\slf4j-api-1.7.10.jar;C:\Users\FangMing\.m2\repository\org\slf4j\slf4j-log4j12\1.7.10\slf4j-log4j12-1.7.10.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;C:\Users\FangMing\.m2\repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;C:\Users\FangMing\.m2\repository\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;C:\Users\FangMing\.m2\repository\org\xerial\snappy\snappy-java\1.0.4.1\snappy-java-1.0.4.1.jar;C:\Users\FangMing\.m2\repository\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;C:\Users\FangMing\.m2\repository\com\jcraft\jsch\0.1.42\jsch-0.1.42.jar;C:\Users\FangMing\.m2\repository\org\apache\curator\curator-client\2.7.1\curator-client-2.7.1.jar;C:\Users\FangMing\.m2\repository\org\apache\curator\curator-recipes\2.7.1\curator-recipes-2.7.1.jar;C:\Users\FangMing\.m2\repository\com\google\code\findbugs\jsr305\3.0.0\jsr305-3.0.0.jar;C:\Users\FangMing\.m2\repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;C:\Users\FangMing\.m2\repository\org\tukaani\xz\1.0\xz-1.0.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-client\2.7.3\hadoop-client-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-hdfs\2.7.3\hadoop-hdfs-2.7.3.jar;C:\Users\FangMing\.m2\repository\xerces\xercesImpl\2.9.1\xercesImpl-2.9.1.jar;C:\Users\FangMing\.m2\repository\xml-apis\xml-apis\1.3.04\xml-apis-1.3.04.jar;C:\Users\FangMing\.m2\repository\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.7.3\hadoop-mapreduce-client-app-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.7.3\hadoop-mapreduce-client-common-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-yarn-client\2.7.3\hadoop-yarn-client-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-yarn-server-common\2.7.3\hadoop-yarn-server-common-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.7.3\hadoop-mapreduce-client-shuffle-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-yarn-api\2.7.3\hadoop-yarn-api-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.7.3\hadoop-mapreduce-client-jobclient-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.7.3\hadoop-mapreduce-client-core-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-yarn-common\2.7.3\hadoop-yarn-common-2.7.3.jar;C:\Users\FangMing\.m2\repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;C:\Users\FangMing\.m2\repository\javax\xml\stream\stax-api\1.0-2\stax-api-1.0-2.jar;C:\Users\FangMing\.m2\repository\javax\activation\activation\1.1\activation-1.1.jar;C:\Users\FangMing\.m2\repository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;C:\Users\FangMing\.m2\repository\com\google\inject\guice\3.0\guice-3.0.jar;C:\Users\FangMing\.m2\repository\javax\inject\javax.inject\1\javax.inject-1.jar;C:\Users\FangMing\.m2\repository\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;C:\Users\FangMing\.m2\repository\com\sun\jersey\contribs\jersey-guice\1.9\jersey-guice-1.9.jar;C:\Users\FangMing\.m2\repository\com\google\inject\extensions\guice-servlet\3.0\guice-servlet-3.0.jar;C:\Users\FangMing\.m2\repository\io\netty\netty\3.6.2.Final\netty-3.6.2.Final.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-auth\2.7.3\hadoop-auth-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\httpcomponents\httpclient\4.2.5\httpclient-4.2.5.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\server\apacheds-kerberos-codec\2.0.0-M15\apacheds-kerberos-codec-2.0.0-M15.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\server\apacheds-i18n\2.0.0-M15\apacheds-i18n-2.0.0-M15.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\api\api-asn1-api\1.0.0-M20\api-asn1-api-1.0.0-M20.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\api\api-util\1.0.0-M20\api-util-1.0.0-M20.jar;C:\Users\FangMing\.m2\repository\org\apache\curator\curator-framework\2.7.1\curator-framework-2.7.1.jar;/D:/dev/java/eclipseNeon2/eclipse/configuration/org.eclipse.osgi/389/0/.cp/;/D:/dev/java/eclipseNeon2/eclipse/configuration/org.eclipse.osgi/388/0/.cp/
[2017-05-19 01:02:27,369][main][INFO ]:Client environment:java.library.path=C:\Program Files\Java\jdk7\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:/Program Files/Java/jre/bin/server;C:/Program Files/Java/jre/bin;C:/Program Files/Java/jre/lib/amd64;.;D:\dev\java\libs\hadoop\hadoop-2.7.3\bin;C:\ProgramData\Oracle\Java\javapath;D:\Dev\scripts;E:\study\maven\apache-maven-3.3.9\bin;e:\study\groovy\groovy-2.4.6\bin;E:/study/gradle/gradle-default/bin;C:\Program Files\Java\jdk\bin;E:\Study\ant\apache-ant-1.9.2\bin;C:\oracle\product\11.2.0\client_1;C:\oracle\product\11.2.0\client_1\bin;C:\Program Files (x86)\AMD APP\bin\x86_64;C:\Program Files (x86)\AMD APP\bin\x86;C:\Program Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\Microsoft SQL Server\100\Tools\Binn\;C:\Program Files\Microsoft SQL Server\100\Tools\Binn\;C:\Program Files\Microsoft SQL Server\100\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\100\Tools\Binn\VSShell\Common7\IDE\;C:\Program Files (x86)\Microsoft SQL Server\100\DTS\Binn\;C:\Program Files (x86)\Microsoft Visual Studio 9.0\Common7\IDE\PrivateAssemblies\;C:\Program Files\TortoiseSVN\bin;C:\Program Files\ThinkPad\Bluetooth Software\;C:\Program Files\ThinkPad\Bluetooth Software\syswow64;C:\Program Files\VisualSVN Server\bin;C:\Program Files\Git\cmd;C:\Users\FangMing\AppData\Local\Programs\Python\Python36\Scripts\;C:\Users\FangMing\AppData\Local\Programs\Python\Python36\;D:\dev\java\eclipseNeon2\eclipse;;.
[2017-05-19 01:02:27,369][main][INFO ]:Client environment:java.io.tmpdir=C:\Users\FangMing\AppData\Local\Temp\
[2017-05-19 01:02:27,369][main][INFO ]:Client environment:java.compiler=<NA>
[2017-05-19 01:02:27,369][main][INFO ]:Client environment:os.name=Windows 7
[2017-05-19 01:02:27,369][main][INFO ]:Client environment:os.arch=amd64
[2017-05-19 01:02:27,369][main][INFO ]:Client environment:os.version=6.1
[2017-05-19 01:02:27,370][main][INFO ]:Client environment:user.name=FangMing
[2017-05-19 01:02:27,370][main][INFO ]:Client environment:user.home=C:\Users\FangMing
[2017-05-19 01:02:27,370][main][INFO ]:Client environment:user.dir=D:\dev\java\workspaces\hadoop\hbase-quickstart01
[2017-05-19 01:02:27,371][main][INFO ]:Initiating client connection, connectString=master.hadoop:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@405a6d04
[2017-05-19 01:02:27,375][main][DEBUG]:zookeeper.disableAutoWatchReset is false
[2017-05-19 01:02:27,408][main-SendThread(master.hadoop:2181)][INFO ]:Opening socket connection to server master.hadoop/192.168.1.104:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-19 01:02:27,410][main-SendThread(master.hadoop:2181)][INFO ]:Socket connection established to master.hadoop/192.168.1.104:2181, initiating session
[2017-05-19 01:02:27,412][main-SendThread(master.hadoop:2181)][DEBUG]:Session establishment request sent on master.hadoop/192.168.1.104:2181
[2017-05-19 01:02:27,562][main-SendThread(master.hadoop:2181)][INFO ]:Session establishment complete on server master.hadoop/192.168.1.104:2181, sessionid = 0x15c1c68faa20007, negotiated timeout = 90000
[2017-05-19 01:02:27,564][main-EventThread][DEBUG]:hconnection-0xec2f1e10x0, quorum=master.hadoop:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
[2017-05-19 01:02:27,566][main-EventThread][DEBUG]:hconnection-0xec2f1e1-0x15c1c68faa20007 connected
[2017-05-19 01:02:27,570][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,240,0  request:: '/hbase/hbaseid,F  response:: s{17,201,1495101357287,1495125278719,1,0,0,0,67,0,17} 
[2017-05-19 01:02:27,574][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,240,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffffa1ffffffee3fffffffb5fffffff8ffffff95ffffffeeffffffc350425546a2465636135643364302d656165392d346238332d396665612d613662653530373465623331,s{17,201,1495101357287,1495125278719,1,0,0,0,67,0,17} 
[2017-05-19 01:02:27,998][main][DEBUG]:dfs.client.use.legacy.blockreader.local = false
[2017-05-19 01:02:27,998][main][DEBUG]:dfs.client.read.shortcircuit = false
[2017-05-19 01:02:27,998][main][DEBUG]:dfs.client.domain.socket.data.traffic = false
[2017-05-19 01:02:27,998][main][DEBUG]:dfs.domain.socket.path = 
[2017-05-19 01:02:28,058][main][DEBUG]:multipleLinearRandomRetry = null
[2017-05-19 01:02:28,080][main][DEBUG]:rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@73b05494
[2017-05-19 01:02:28,426][main][DEBUG]:getting client out of cache: org.apache.hadoop.ipc.Client@4beb407
[2017-05-19 01:02:28,769][main][DEBUG]:Both short-circuit local reads and UNIX domain socket are disabled.
[2017-05-19 01:02:28,776][main][DEBUG]:DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
[2017-05-19 01:02:28,846][main][DEBUG]:Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@2e512f9c, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
[2017-05-19 01:02:28,933][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 3,4  replyHeader:: 3,240,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136323031fffffff366ffffffeeffffff9affffffc71525ffffffcb50425546a19ad6d61737465722e6861646f6f7010ffffffc97e18ffffff87ffffffa8ffffffa4ffffffe3ffffffc12b100183,s{216,216,1495125288124,1495125288124,0,0,0,0,66,0,216} 
[2017-05-19 01:02:28,944][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 4,8  replyHeader:: 4,240,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
[2017-05-19 01:02:29,113][hconnection-0xec2f1e1-shared--pool1-t1][DEBUG]:Use SIMPLE authentication for service ClientService, sasl=false
[2017-05-19 01:02:29,131][hconnection-0xec2f1e1-shared--pool1-t1][DEBUG]:Connecting to master.hadoop/192.168.1.104:16201
[2017-05-19 01:02:29,446][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 5,3  replyHeader:: 5,240,0  request:: '/hbase,F  response:: s{2,2,1495101350570,1495101350570,0,22,0,0,0,16,216} 
[2017-05-19 01:02:29,450][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 6,4  replyHeader:: 6,240,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3136303030ffffffef4452666c58ffffffbfffffffd450425546a19ad6d61737465722e6861646f6f7010ffffff807d18ffffff80ffffffa8ffffffa4ffffffe3ffffffc12b10018ffffff8a7d,s{198,198,1495125275275,1495125275275,0,0,0,97984529102405632,61,0,198} 
[2017-05-19 01:02:29,499][main][DEBUG]:Use SIMPLE authentication for service MasterService, sasl=false
[2017-05-19 01:02:29,499][main][DEBUG]:Connecting to master.hadoop/192.168.1.104:16000
[2017-05-19 01:02:39,604][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 7,3  replyHeader:: 7,240,0  request:: '/hbase,F  response:: s{2,2,1495101350570,1495101350570,0,22,0,0,0,16,216} 
[2017-05-19 01:02:39,604][main-SendThread(master.hadoop:2181)][DEBUG]:Got ping response for sessionid: 0x15c1c68faa20007 after 1ms
[2017-05-19 01:02:39,606][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 8,4  replyHeader:: 8,240,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3136303030ffffffef4452666c58ffffffbfffffffd450425546a19ad6d61737465722e6861646f6f7010ffffff807d18ffffff80ffffffa8ffffffa4ffffffe3ffffffc12b10018ffffff8a7d,s{198,198,1495125275275,1495125275275,0,0,0,97984529102405632,61,0,198} 
[2017-05-19 01:02:39,606][main][DEBUG]:Use SIMPLE authentication for service MasterService, sasl=false
[2017-05-19 01:02:39,606][main][DEBUG]:Not trying to connect to master.hadoop/192.168.1.104:16000 this server is in the failed servers list
[2017-05-19 01:02:39,810][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 9,3  replyHeader:: 9,240,0  request:: '/hbase,F  response:: s{2,2,1495101350570,1495101350570,0,22,0,0,0,16,216} 
[2017-05-19 01:02:39,812][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 10,4  replyHeader:: 10,240,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3136303030ffffffef4452666c58ffffffbfffffffd450425546a19ad6d61737465722e6861646f6f7010ffffff807d18ffffff80ffffffa8ffffffa4ffffffe3ffffffc12b10018ffffff8a7d,s{198,198,1495125275275,1495125275275,0,0,0,97984529102405632,61,0,198} 
[2017-05-19 01:02:39,813][main][DEBUG]:Use SIMPLE authentication for service MasterService, sasl=false
[2017-05-19 01:02:39,813][main][DEBUG]:Not trying to connect to master.hadoop/192.168.1.104:16000 this server is in the failed servers list
[2017-05-19 01:02:40,132][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 11,3  replyHeader:: 11,240,0  request:: '/hbase,F  response:: s{2,2,1495101350570,1495101350570,0,22,0,0,0,16,216} 
[2017-05-19 01:02:40,135][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 12,4  replyHeader:: 12,240,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3136303030ffffffef4452666c58ffffffbfffffffd450425546a19ad6d61737465722e6861646f6f7010ffffff807d18ffffff80ffffffa8ffffffa4ffffffe3ffffffc12b10018ffffff8a7d,s{198,198,1495125275275,1495125275275,0,0,0,97984529102405632,61,0,198} 
[2017-05-19 01:02:40,135][main][DEBUG]:Use SIMPLE authentication for service MasterService, sasl=false
[2017-05-19 01:02:40,135][main][DEBUG]:Not trying to connect to master.hadoop/192.168.1.104:16000 this server is in the failed servers list
[2017-05-19 01:02:40,641][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 13,3  replyHeader:: 13,240,0  request:: '/hbase,F  response:: s{2,2,1495101350570,1495101350570,0,22,0,0,0,16,216} 
[2017-05-19 01:02:40,643][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 14,4  replyHeader:: 14,240,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3136303030ffffffef4452666c58ffffffbfffffffd450425546a19ad6d61737465722e6861646f6f7010ffffff807d18ffffff80ffffffa8ffffffa4ffffffe3ffffffc12b10018ffffff8a7d,s{198,198,1495125275275,1495125275275,0,0,0,97984529102405632,61,0,198} 
[2017-05-19 01:02:40,643][main][DEBUG]:Use SIMPLE authentication for service MasterService, sasl=false
[2017-05-19 01:02:40,643][main][DEBUG]:Not trying to connect to master.hadoop/192.168.1.104:16000 this server is in the failed servers list
[2017-05-19 01:02:41,675][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 15,3  replyHeader:: 15,240,0  request:: '/hbase,F  response:: s{2,2,1495101350570,1495101350570,0,22,0,0,0,16,216} 
[2017-05-19 01:02:41,679][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 16,4  replyHeader:: 16,240,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3136303030ffffffef4452666c58ffffffbfffffffd450425546a19ad6d61737465722e6861646f6f7010ffffff807d18ffffff80ffffffa8ffffffa4ffffffe3ffffffc12b10018ffffff8a7d,s{198,198,1495125275275,1495125275275,0,0,0,97984529102405632,61,0,198} 
[2017-05-19 01:02:41,680][main][DEBUG]:Use SIMPLE authentication for service MasterService, sasl=false
[2017-05-19 01:02:41,680][main][DEBUG]:Connecting to master.hadoop/192.168.1.104:16000
[2017-05-19 01:02:53,688][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 17,3  replyHeader:: 17,240,0  request:: '/hbase,F  response:: s{2,2,1495101350570,1495101350570,0,22,0,0,0,16,216} 
[2017-05-19 01:02:53,688][main-SendThread(master.hadoop:2181)][DEBUG]:Got ping response for sessionid: 0x15c1c68faa20007 after 2ms
[2017-05-19 01:02:53,690][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 18,4  replyHeader:: 18,240,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3136303030ffffffef4452666c58ffffffbfffffffd450425546a19ad6d61737465722e6861646f6f7010ffffff807d18ffffff80ffffffa8ffffffa4ffffffe3ffffffc12b10018ffffff8a7d,s{198,198,1495125275275,1495125275275,0,0,0,97984529102405632,61,0,198} 
[2017-05-19 01:02:53,691][main][DEBUG]:Use SIMPLE authentication for service MasterService, sasl=false
[2017-05-19 01:02:53,691][main][DEBUG]:Connecting to master.hadoop/192.168.1.104:16000
[2017-05-19 01:03:07,694][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 19,3  replyHeader:: 19,240,0  request:: '/hbase,F  response:: s{2,2,1495101350570,1495101350570,0,22,0,0,0,16,216} 
[2017-05-19 01:03:07,694][main-SendThread(master.hadoop:2181)][DEBUG]:Got ping response for sessionid: 0x15c1c68faa20007 after 1ms
[2017-05-19 01:03:07,696][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 20,4  replyHeader:: 20,240,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3136303030ffffffef4452666c58ffffffbfffffffd450425546a19ad6d61737465722e6861646f6f7010ffffff807d18ffffff80ffffffa8ffffffa4ffffffe3ffffffc12b10018ffffff8a7d,s{198,198,1495125275275,1495125275275,0,0,0,97984529102405632,61,0,198} 
[2017-05-19 01:03:07,697][main][DEBUG]:Use SIMPLE authentication for service MasterService, sasl=false
[2017-05-19 01:03:07,697][main][DEBUG]:Connecting to master.hadoop/192.168.1.104:16000
[2017-05-19 01:03:27,794][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 21,3  replyHeader:: 21,240,0  request:: '/hbase,F  response:: s{2,2,1495101350570,1495101350570,0,22,0,0,0,16,216} 
[2017-05-19 01:03:27,794][main-SendThread(master.hadoop:2181)][DEBUG]:Got ping response for sessionid: 0x15c1c68faa20007 after 1ms
[2017-05-19 01:03:27,796][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 22,4  replyHeader:: 22,240,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3136303030ffffffef4452666c58ffffffbfffffffd450425546a19ad6d61737465722e6861646f6f7010ffffff807d18ffffff80ffffffa8ffffffa4ffffffe3ffffffc12b10018ffffff8a7d,s{198,198,1495125275275,1495125275275,0,0,0,97984529102405632,61,0,198} 
[2017-05-19 01:03:27,796][main][DEBUG]:Use SIMPLE authentication for service MasterService, sasl=false
[2017-05-19 01:03:27,796][main][DEBUG]:Connecting to master.hadoop/192.168.1.104:16000
[2017-05-19 01:03:47,840][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 23,3  replyHeader:: 23,240,0  request:: '/hbase,F  response:: s{2,2,1495101350570,1495101350570,0,22,0,0,0,16,216} 
[2017-05-19 01:03:47,841][main-SendThread(master.hadoop:2181)][DEBUG]:Got ping response for sessionid: 0x15c1c68faa20007 after 1ms
[2017-05-19 01:03:47,843][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 24,4  replyHeader:: 24,240,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3136303030ffffffef4452666c58ffffffbfffffffd450425546a19ad6d61737465722e6861646f6f7010ffffff807d18ffffff80ffffffa8ffffffa4ffffffe3ffffffc12b10018ffffff8a7d,s{198,198,1495125275275,1495125275275,0,0,0,97984529102405632,61,0,198} 
[2017-05-19 01:03:47,844][main][DEBUG]:Use SIMPLE authentication for service MasterService, sasl=false
[2017-05-19 01:03:47,844][main][DEBUG]:Connecting to master.hadoop/192.168.1.104:16000
[2017-05-19 01:04:07,911][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 25,3  replyHeader:: 25,240,0  request:: '/hbase,F  response:: s{2,2,1495101350570,1495101350570,0,22,0,0,0,16,216} 
[2017-05-19 01:04:07,912][main-SendThread(master.hadoop:2181)][DEBUG]:Got ping response for sessionid: 0x15c1c68faa20007 after 1ms
[2017-05-19 01:04:07,913][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 26,4  replyHeader:: 26,240,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3136303030ffffffef4452666c58ffffffbfffffffd450425546a19ad6d61737465722e6861646f6f7010ffffff807d18ffffff80ffffffa8ffffffa4ffffffe3ffffffc12b10018ffffff8a7d,s{198,198,1495125275275,1495125275275,0,0,0,97984529102405632,61,0,198} 
[2017-05-19 01:04:07,914][main][DEBUG]:Use SIMPLE authentication for service MasterService, sasl=false
[2017-05-19 01:04:07,914][main][DEBUG]:Connecting to master.hadoop/192.168.1.104:16000
[2017-05-19 01:04:17,915][main][INFO ]:Call exception, tries=10, retries=35, started=108471 ms ago, cancelled=false, msg=com.google.protobuf.ServiceException: org.apache.hadoop.net.ConnectTimeoutException: 10000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=master.hadoop/192.168.1.104:16000] 
[2017-05-19 01:04:27,943][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 27,3  replyHeader:: 27,240,0  request:: '/hbase,F  response:: s{2,2,1495101350570,1495101350570,0,22,0,0,0,16,216} 
[2017-05-19 01:04:27,944][main-SendThread(master.hadoop:2181)][DEBUG]:Got ping response for sessionid: 0x15c1c68faa20007 after 1ms
[2017-05-19 01:04:27,945][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 28,4  replyHeader:: 28,240,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3136303030ffffffef4452666c58ffffffbfffffffd450425546a19ad6d61737465722e6861646f6f7010ffffff807d18ffffff80ffffffa8ffffffa4ffffffe3ffffffc12b10018ffffff8a7d,s{198,198,1495125275275,1495125275275,0,0,0,97984529102405632,61,0,198} 
[2017-05-19 01:04:27,946][main][DEBUG]:Use SIMPLE authentication for service MasterService, sasl=false
[2017-05-19 01:04:27,946][main][DEBUG]:Connecting to master.hadoop/192.168.1.104:16000
[2017-05-19 01:04:37,948][main][INFO ]:Call exception, tries=11, retries=35, started=128504 ms ago, cancelled=false, msg=com.google.protobuf.ServiceException: org.apache.hadoop.net.ConnectTimeoutException: 10000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=master.hadoop/192.168.1.104:16000] 
[2017-05-19 01:04:57,946][main-SendThread(master.hadoop:2181)][DEBUG]:Got ping response for sessionid: 0x15c1c68faa20007 after 0ms
[2017-05-19 01:04:58,056][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 29,3  replyHeader:: 29,240,0  request:: '/hbase,F  response:: s{2,2,1495101350570,1495101350570,0,22,0,0,0,16,216} 
[2017-05-19 01:04:58,058][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 30,4  replyHeader:: 30,240,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3136303030ffffffef4452666c58ffffffbfffffffd450425546a19ad6d61737465722e6861646f6f7010ffffff807d18ffffff80ffffffa8ffffffa4ffffffe3ffffffc12b10018ffffff8a7d,s{198,198,1495125275275,1495125275275,0,0,0,97984529102405632,61,0,198} 
[2017-05-19 01:04:58,059][main][DEBUG]:Use SIMPLE authentication for service MasterService, sasl=false
[2017-05-19 01:04:58,059][main][DEBUG]:Connecting to master.hadoop/192.168.1.104:16000
[2017-05-19 01:05:08,060][main][INFO ]:Call exception, tries=12, retries=35, started=158616 ms ago, cancelled=false, msg=com.google.protobuf.ServiceException: org.apache.hadoop.net.ConnectTimeoutException: 10000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=master.hadoop/192.168.1.104:16000] 
[2017-05-19 01:05:28,059][main-SendThread(master.hadoop:2181)][DEBUG]:Got ping response for sessionid: 0x15c1c68faa20007 after 0ms
[2017-05-19 01:05:28,243][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 31,3  replyHeader:: 31,240,0  request:: '/hbase,F  response:: s{2,2,1495101350570,1495101350570,0,22,0,0,0,16,216} 
[2017-05-19 01:05:28,244][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 32,4  replyHeader:: 32,240,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3136303030ffffffef4452666c58ffffffbfffffffd450425546a19ad6d61737465722e6861646f6f7010ffffff807d18ffffff80ffffffa8ffffffa4ffffffe3ffffffc12b10018ffffff8a7d,s{198,198,1495125275275,1495125275275,0,0,0,97984529102405632,61,0,198} 
[2017-05-19 01:05:28,245][main][DEBUG]:Use SIMPLE authentication for service MasterService, sasl=false
[2017-05-19 01:05:28,245][main][DEBUG]:Connecting to master.hadoop/192.168.1.104:16000
[2017-05-19 01:05:38,247][main][INFO ]:Call exception, tries=13, retries=35, started=188802 ms ago, cancelled=false, msg=com.google.protobuf.ServiceException: org.apache.hadoop.net.ConnectTimeoutException: 10000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=master.hadoop/192.168.1.104:16000] 
[2017-05-19 01:05:58,246][main-SendThread(master.hadoop:2181)][DEBUG]:Got ping response for sessionid: 0x15c1c68faa20007 after 0ms
[2017-05-19 01:05:58,389][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 33,3  replyHeader:: 33,240,0  request:: '/hbase,F  response:: s{2,2,1495101350570,1495101350570,0,22,0,0,0,16,216} 
[2017-05-19 01:05:58,391][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 34,4  replyHeader:: 34,240,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3136303030ffffffef4452666c58ffffffbfffffffd450425546a19ad6d61737465722e6861646f6f7010ffffff807d18ffffff80ffffffa8ffffffa4ffffffe3ffffffc12b10018ffffff8a7d,s{198,198,1495125275275,1495125275275,0,0,0,97984529102405632,61,0,198} 
[2017-05-19 01:05:58,392][main][DEBUG]:Use SIMPLE authentication for service MasterService, sasl=false
[2017-05-19 01:05:58,392][main][DEBUG]:Connecting to master.hadoop/192.168.1.104:16000
[2017-05-19 01:06:08,393][main][INFO ]:Call exception, tries=14, retries=35, started=218949 ms ago, cancelled=false, msg=com.google.protobuf.ServiceException: org.apache.hadoop.net.ConnectTimeoutException: 10000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=master.hadoop/192.168.1.104:16000] 
[2017-05-19 01:06:28,391][main-SendThread(master.hadoop:2181)][DEBUG]:Got ping response for sessionid: 0x15c1c68faa20007 after 0ms
[2017-05-19 01:06:28,499][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 35,3  replyHeader:: 35,240,0  request:: '/hbase,F  response:: s{2,2,1495101350570,1495101350570,0,22,0,0,0,16,216} 
[2017-05-19 01:06:28,503][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 36,4  replyHeader:: 36,240,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3136303030ffffffef4452666c58ffffffbfffffffd450425546a19ad6d61737465722e6861646f6f7010ffffff807d18ffffff80ffffffa8ffffffa4ffffffe3ffffffc12b10018ffffff8a7d,s{198,198,1495125275275,1495125275275,0,0,0,97984529102405632,61,0,198} 
[2017-05-19 01:06:28,504][main][DEBUG]:Use SIMPLE authentication for service MasterService, sasl=false
[2017-05-19 01:06:28,505][main][DEBUG]:Connecting to master.hadoop/192.168.1.104:16000
[2017-05-19 01:06:38,505][main][INFO ]:Call exception, tries=15, retries=35, started=249061 ms ago, cancelled=false, msg=com.google.protobuf.ServiceException: org.apache.hadoop.net.ConnectTimeoutException: 10000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=master.hadoop/192.168.1.104:16000] 
[2017-05-19 01:06:58,503][main-SendThread(master.hadoop:2181)][DEBUG]:Got ping response for sessionid: 0x15c1c68faa20007 after 0ms
[2017-05-19 01:06:58,600][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 37,3  replyHeader:: 37,240,0  request:: '/hbase,F  response:: s{2,2,1495101350570,1495101350570,0,22,0,0,0,16,216} 
[2017-05-19 01:06:58,601][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 38,4  replyHeader:: 38,240,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3136303030ffffffef4452666c58ffffffbfffffffd450425546a19ad6d61737465722e6861646f6f7010ffffff807d18ffffff80ffffffa8ffffffa4ffffffe3ffffffc12b10018ffffff8a7d,s{198,198,1495125275275,1495125275275,0,0,0,97984529102405632,61,0,198} 
[2017-05-19 01:06:58,602][main][DEBUG]:Use SIMPLE authentication for service MasterService, sasl=false
[2017-05-19 01:06:58,602][main][DEBUG]:Connecting to master.hadoop/192.168.1.104:16000
[2017-05-19 01:07:08,603][main][INFO ]:Call exception, tries=16, retries=35, started=279159 ms ago, cancelled=false, msg=com.google.protobuf.ServiceException: org.apache.hadoop.net.ConnectTimeoutException: 10000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=master.hadoop/192.168.1.104:16000] 
[2017-05-19 01:07:28,601][main-SendThread(master.hadoop:2181)][DEBUG]:Got ping response for sessionid: 0x15c1c68faa20007 after 0ms
[2017-05-19 01:07:28,748][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 39,3  replyHeader:: 39,240,0  request:: '/hbase,F  response:: s{2,2,1495101350570,1495101350570,0,22,0,0,0,16,216} 
[2017-05-19 01:07:28,750][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 40,4  replyHeader:: 40,240,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3136303030ffffffef4452666c58ffffffbfffffffd450425546a19ad6d61737465722e6861646f6f7010ffffff807d18ffffff80ffffffa8ffffffa4ffffffe3ffffffc12b10018ffffff8a7d,s{198,198,1495125275275,1495125275275,0,0,0,97984529102405632,61,0,198} 
[2017-05-19 01:07:28,750][main][DEBUG]:Use SIMPLE authentication for service MasterService, sasl=false
[2017-05-19 01:07:28,751][main][DEBUG]:Connecting to master.hadoop/192.168.1.104:16000
[2017-05-19 01:07:38,751][main][INFO ]:Call exception, tries=17, retries=35, started=309307 ms ago, cancelled=false, msg=com.google.protobuf.ServiceException: org.apache.hadoop.net.ConnectTimeoutException: 10000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=master.hadoop/192.168.1.104:16000] 
[2017-05-19 01:07:58,750][main-SendThread(master.hadoop:2181)][DEBUG]:Got ping response for sessionid: 0x15c1c68faa20007 after 0ms
[2017-05-19 01:07:58,903][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 41,3  replyHeader:: 41,240,0  request:: '/hbase,F  response:: s{2,2,1495101350570,1495101350570,0,22,0,0,0,16,216} 
[2017-05-19 01:07:58,905][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 42,4  replyHeader:: 42,240,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3136303030ffffffef4452666c58ffffffbfffffffd450425546a19ad6d61737465722e6861646f6f7010ffffff807d18ffffff80ffffffa8ffffffa4ffffffe3ffffffc12b10018ffffff8a7d,s{198,198,1495125275275,1495125275275,0,0,0,97984529102405632,61,0,198} 
[2017-05-19 01:07:58,906][main][DEBUG]:Use SIMPLE authentication for service MasterService, sasl=false
[2017-05-19 01:07:58,906][main][DEBUG]:Connecting to master.hadoop/192.168.1.104:16000
[2017-05-19 01:08:08,907][main][INFO ]:Call exception, tries=18, retries=35, started=339463 ms ago, cancelled=false, msg=com.google.protobuf.ServiceException: org.apache.hadoop.net.ConnectTimeoutException: 10000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=master.hadoop/192.168.1.104:16000] 
[2017-05-19 01:08:28,906][main-SendThread(master.hadoop:2181)][DEBUG]:Got ping response for sessionid: 0x15c1c68faa20007 after 0ms
[2017-05-19 01:08:28,985][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 43,3  replyHeader:: 43,240,0  request:: '/hbase,F  response:: s{2,2,1495101350570,1495101350570,0,22,0,0,0,16,216} 
[2017-05-19 01:08:28,987][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 44,4  replyHeader:: 44,240,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3136303030ffffffef4452666c58ffffffbfffffffd450425546a19ad6d61737465722e6861646f6f7010ffffff807d18ffffff80ffffffa8ffffffa4ffffffe3ffffffc12b10018ffffff8a7d,s{198,198,1495125275275,1495125275275,0,0,0,97984529102405632,61,0,198} 
[2017-05-19 01:08:28,988][main][DEBUG]:Use SIMPLE authentication for service MasterService, sasl=false
[2017-05-19 01:08:28,988][main][DEBUG]:Connecting to master.hadoop/192.168.1.104:16000
[2017-05-19 01:08:38,990][main][INFO ]:Call exception, tries=19, retries=35, started=369546 ms ago, cancelled=false, msg=com.google.protobuf.ServiceException: org.apache.hadoop.net.ConnectTimeoutException: 10000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=master.hadoop/192.168.1.104:16000] 
[2017-05-19 01:08:58,988][main-SendThread(master.hadoop:2181)][DEBUG]:Got ping response for sessionid: 0x15c1c68faa20007 after 0ms
[2017-05-19 01:08:59,188][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 45,3  replyHeader:: 45,240,0  request:: '/hbase,F  response:: s{2,2,1495101350570,1495101350570,0,22,0,0,0,16,216} 
[2017-05-19 01:08:59,191][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 46,4  replyHeader:: 46,240,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3136303030ffffffef4452666c58ffffffbfffffffd450425546a19ad6d61737465722e6861646f6f7010ffffff807d18ffffff80ffffffa8ffffffa4ffffffe3ffffffc12b10018ffffff8a7d,s{198,198,1495125275275,1495125275275,0,0,0,97984529102405632,61,0,198} 
[2017-05-19 01:08:59,192][main][DEBUG]:Use SIMPLE authentication for service MasterService, sasl=false
[2017-05-19 01:08:59,193][main][DEBUG]:Connecting to master.hadoop/192.168.1.104:16000
[2017-05-19 01:09:09,194][main][INFO ]:Call exception, tries=20, retries=35, started=399750 ms ago, cancelled=false, msg=com.google.protobuf.ServiceException: org.apache.hadoop.net.ConnectTimeoutException: 10000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=master.hadoop/192.168.1.104:16000] 
[2017-05-19 01:09:29,191][main-SendThread(master.hadoop:2181)][DEBUG]:Got ping response for sessionid: 0x15c1c68faa20007 after 0ms
[2017-05-19 01:09:29,390][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 47,3  replyHeader:: 47,240,0  request:: '/hbase,F  response:: s{2,2,1495101350570,1495101350570,0,22,0,0,0,16,216} 
[2017-05-19 01:09:29,391][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 48,4  replyHeader:: 48,240,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3136303030ffffffef4452666c58ffffffbfffffffd450425546a19ad6d61737465722e6861646f6f7010ffffff807d18ffffff80ffffffa8ffffffa4ffffffe3ffffffc12b10018ffffff8a7d,s{198,198,1495125275275,1495125275275,0,0,0,97984529102405632,61,0,198} 
[2017-05-19 01:09:29,392][main][DEBUG]:Use SIMPLE authentication for service MasterService, sasl=false
[2017-05-19 01:09:29,392][main][DEBUG]:Connecting to master.hadoop/192.168.1.104:16000
[2017-05-19 01:09:39,393][main][INFO ]:Call exception, tries=21, retries=35, started=429949 ms ago, cancelled=false, msg=com.google.protobuf.ServiceException: org.apache.hadoop.net.ConnectTimeoutException: 10000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=master.hadoop/192.168.1.104:16000] 
[2017-05-19 01:09:59,391][main-SendThread(master.hadoop:2181)][DEBUG]:Got ping response for sessionid: 0x15c1c68faa20007 after 0ms
[2017-05-19 01:09:59,532][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 49,3  replyHeader:: 49,240,0  request:: '/hbase,F  response:: s{2,2,1495101350570,1495101350570,0,22,0,0,0,16,216} 
[2017-05-19 01:09:59,534][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 50,4  replyHeader:: 50,240,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3136303030ffffffef4452666c58ffffffbfffffffd450425546a19ad6d61737465722e6861646f6f7010ffffff807d18ffffff80ffffffa8ffffffa4ffffffe3ffffffc12b10018ffffff8a7d,s{198,198,1495125275275,1495125275275,0,0,0,97984529102405632,61,0,198} 
[2017-05-19 01:09:59,534][main][DEBUG]:Use SIMPLE authentication for service MasterService, sasl=false
[2017-05-19 01:09:59,535][main][DEBUG]:Connecting to master.hadoop/192.168.1.104:16000
[2017-05-19 01:10:02,373][main][INFO ]:Created users
[2017-05-19 01:10:02,374][main][INFO ]:Closing master protocol: MasterService
[2017-05-19 01:10:02,374][main][INFO ]:Closing zookeeper sessionid=0x15c1c68faa20007
[2017-05-19 01:10:02,374][main][DEBUG]:Closing session: 0x15c1c68faa20007
[2017-05-19 01:10:02,374][main][DEBUG]:Closing client for session: 0x15c1c68faa20007
[2017-05-19 01:10:02,842][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20007, packet:: clientPath:null serverPath:null finished:false header:: 51,-11  replyHeader:: 51,252,0  request:: null response:: null
[2017-05-19 01:10:02,843][main][DEBUG]:Disconnecting client for session: 0x15c1c68faa20007
[2017-05-19 01:10:02,843][main][INFO ]:Session: 0x15c1c68faa20007 closed
[2017-05-19 01:10:02,843][main][DEBUG]:Stopping rpc client
[2017-05-19 01:10:02,843][main-SendThread(master.hadoop:2181)][DEBUG]:An exception was thrown while closing send thread for session 0x15c1c68faa20007 : Unable to read additional data from server sessionid 0x15c1c68faa20007, likely server has closed socket
[2017-05-19 01:10:02,844][main-EventThread][INFO ]:EventThread shut down
[2017-05-19 01:10:02,861][Thread-3][DEBUG]:stopping client from cache: org.apache.hadoop.ipc.Client@4beb407
[2017-05-19 01:10:02,861][Thread-3][DEBUG]:removing client from cache: org.apache.hadoop.ipc.Client@4beb407
[2017-05-19 01:10:02,861][Thread-3][DEBUG]:stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@4beb407
[2017-05-19 01:10:02,861][Thread-3][DEBUG]:Stopping client
[2017-05-19 01:19:58,438][main][DEBUG]: Creating new Groups object
[2017-05-19 01:19:58,503][main][DEBUG]:Trying to load the custom-built native-hadoop library...
[2017-05-19 01:19:58,509][main][DEBUG]:Loaded the native-hadoop library
[2017-05-19 01:19:58,510][main][DEBUG]:Using JniBasedUnixGroupsMapping for Group resolution
[2017-05-19 01:19:58,510][main][DEBUG]:Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
[2017-05-19 01:19:58,729][main][DEBUG]:Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
[2017-05-19 01:19:58,878][main][DEBUG]:field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)], about=, always=false, type=DEFAULT, sampleName=Ops)
[2017-05-19 01:19:58,894][main][DEBUG]:field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)], about=, always=false, type=DEFAULT, sampleName=Ops)
[2017-05-19 01:19:58,895][main][DEBUG]:field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[GetGroups], about=, always=false, type=DEFAULT, sampleName=Ops)
[2017-05-19 01:19:58,897][main][DEBUG]:UgiMetrics, User and group related metrics
[2017-05-19 01:19:59,123][main][DEBUG]:Kerberos krb5 configuration not found, setting default realm to empty
[2017-05-19 01:19:59,131][main][DEBUG]:hadoop login
[2017-05-19 01:19:59,132][main][DEBUG]:hadoop login commit
[2017-05-19 01:19:59,141][main][DEBUG]:using local user:NTUserPrincipal: FangMing
[2017-05-19 01:19:59,141][main][DEBUG]:Using user: "NTUserPrincipal: FangMing" with name FangMing
[2017-05-19 01:19:59,142][main][DEBUG]:User entry: "FangMing"
[2017-05-19 01:19:59,143][main][DEBUG]:UGI loginUser:FangMing (auth:SIMPLE)
[2017-05-19 01:19:59,697][main][INFO ]:Process identifier=hconnection-0x5459c1c5 connecting to ZooKeeper ensemble=master.hadoop:2181
[2017-05-19 01:19:59,705][main][INFO ]:Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
[2017-05-19 01:19:59,706][main][INFO ]:Client environment:host.name=FANGMING-THINK
[2017-05-19 01:19:59,706][main][INFO ]:Client environment:java.version=1.7.0_79
[2017-05-19 01:19:59,706][main][INFO ]:Client environment:java.vendor=Oracle Corporation
[2017-05-19 01:19:59,706][main][INFO ]:Client environment:java.home=C:\Program Files\Java\jdk7\jre
[2017-05-19 01:19:59,706][main][INFO ]:Client environment:java.class.path=D:\dev\java\workspaces\hadoop\hbase-quickstart01\target\test-classes;D:\dev\java\workspaces\hadoop\hbase-quickstart01\target\classes;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-client\1.3.1\hbase-client-1.3.1.jar;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-annotations\1.3.1\hbase-annotations-1.3.1.jar;C:\Users\FangMing\.m2\repository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-common\1.3.1\hbase-common-1.3.1.jar;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-protocol\1.3.1\hbase-protocol-1.3.1.jar;C:\Users\FangMing\.m2\repository\commons-codec\commons-codec\1.9\commons-codec-1.9.jar;C:\Users\FangMing\.m2\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;C:\Users\FangMing\.m2\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;C:\Users\FangMing\.m2\repository\commons-logging\commons-logging\1.2\commons-logging-1.2.jar;C:\Users\FangMing\.m2\repository\com\google\guava\guava\12.0.1\guava-12.0.1.jar;C:\Users\FangMing\.m2\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;C:\Users\FangMing\.m2\repository\io\netty\netty-all\4.0.23.Final\netty-all-4.0.23.Final.jar;C:\Users\FangMing\.m2\repository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;C:\Users\FangMing\.m2\repository\org\apache\htrace\htrace-core\3.1.0-incubating\htrace-core-3.1.0-incubating.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jackson\jackson-mapper-asl\1.9.13\jackson-mapper-asl-1.9.13.jar;C:\Users\FangMing\.m2\repository\org\jruby\jcodings\jcodings\1.0.8\jcodings-1.0.8.jar;C:\Users\FangMing\.m2\repository\org\jruby\joni\joni\2.1.2\joni-2.1.2.jar;C:\Users\FangMing\.m2\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\Program Files\Java\jdk\lib\tools.jar;C:\Users\FangMing\.m2\repository\junit\junit\4.12\junit-4.12.jar;C:\Users\FangMing\.m2\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-common\2.7.3\hadoop-common-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-annotations\2.7.3\hadoop-annotations-2.7.3.jar;C:\Users\FangMing\.m2\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;C:\Users\FangMing\.m2\repository\org\apache\commons\commons-math3\3.1.1\commons-math3-3.1.1.jar;C:\Users\FangMing\.m2\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;C:\Users\FangMing\.m2\repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;C:\Users\FangMing\.m2\repository\commons-net\commons-net\3.1\commons-net-3.1.jar;C:\Users\FangMing\.m2\repository\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;C:\Users\FangMing\.m2\repository\javax\servlet\servlet-api\2.5\servlet-api-2.5.jar;C:\Users\FangMing\.m2\repository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;C:\Users\FangMing\.m2\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;C:\Users\FangMing\.m2\repository\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;C:\Users\FangMing\.m2\repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;C:\Users\FangMing\.m2\repository\com\sun\jersey\jersey-json\1.9\jersey-json-1.9.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;C:\Users\FangMing\.m2\repository\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jackson\jackson-jaxrs\1.8.3\jackson-jaxrs-1.8.3.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jackson\jackson-xc\1.8.3\jackson-xc-1.8.3.jar;C:\Users\FangMing\.m2\repository\com\sun\jersey\jersey-server\1.9\jersey-server-1.9.jar;C:\Users\FangMing\.m2\repository\asm\asm\3.1\asm-3.1.jar;C:\Users\FangMing\.m2\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;C:\Users\FangMing\.m2\repository\net\java\dev\jets3t\jets3t\0.9.0\jets3t-0.9.0.jar;C:\Users\FangMing\.m2\repository\org\apache\httpcomponents\httpcore\4.1.2\httpcore-4.1.2.jar;C:\Users\FangMing\.m2\repository\com\jamesmurty\utils\java-xmlbuilder\0.4\java-xmlbuilder-0.4.jar;C:\Users\FangMing\.m2\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;C:\Users\FangMing\.m2\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;C:\Users\FangMing\.m2\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;C:\Users\FangMing\.m2\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;C:\Users\FangMing\.m2\repository\org\slf4j\slf4j-api\1.7.10\slf4j-api-1.7.10.jar;C:\Users\FangMing\.m2\repository\org\slf4j\slf4j-log4j12\1.7.10\slf4j-log4j12-1.7.10.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;C:\Users\FangMing\.m2\repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;C:\Users\FangMing\.m2\repository\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;C:\Users\FangMing\.m2\repository\org\xerial\snappy\snappy-java\1.0.4.1\snappy-java-1.0.4.1.jar;C:\Users\FangMing\.m2\repository\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;C:\Users\FangMing\.m2\repository\com\jcraft\jsch\0.1.42\jsch-0.1.42.jar;C:\Users\FangMing\.m2\repository\org\apache\curator\curator-client\2.7.1\curator-client-2.7.1.jar;C:\Users\FangMing\.m2\repository\org\apache\curator\curator-recipes\2.7.1\curator-recipes-2.7.1.jar;C:\Users\FangMing\.m2\repository\com\google\code\findbugs\jsr305\3.0.0\jsr305-3.0.0.jar;C:\Users\FangMing\.m2\repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;C:\Users\FangMing\.m2\repository\org\tukaani\xz\1.0\xz-1.0.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-client\2.7.3\hadoop-client-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-hdfs\2.7.3\hadoop-hdfs-2.7.3.jar;C:\Users\FangMing\.m2\repository\xerces\xercesImpl\2.9.1\xercesImpl-2.9.1.jar;C:\Users\FangMing\.m2\repository\xml-apis\xml-apis\1.3.04\xml-apis-1.3.04.jar;C:\Users\FangMing\.m2\repository\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.7.3\hadoop-mapreduce-client-app-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.7.3\hadoop-mapreduce-client-common-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-yarn-client\2.7.3\hadoop-yarn-client-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-yarn-server-common\2.7.3\hadoop-yarn-server-common-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.7.3\hadoop-mapreduce-client-shuffle-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-yarn-api\2.7.3\hadoop-yarn-api-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.7.3\hadoop-mapreduce-client-jobclient-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.7.3\hadoop-mapreduce-client-core-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-yarn-common\2.7.3\hadoop-yarn-common-2.7.3.jar;C:\Users\FangMing\.m2\repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;C:\Users\FangMing\.m2\repository\javax\xml\stream\stax-api\1.0-2\stax-api-1.0-2.jar;C:\Users\FangMing\.m2\repository\javax\activation\activation\1.1\activation-1.1.jar;C:\Users\FangMing\.m2\repository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;C:\Users\FangMing\.m2\repository\com\google\inject\guice\3.0\guice-3.0.jar;C:\Users\FangMing\.m2\repository\javax\inject\javax.inject\1\javax.inject-1.jar;C:\Users\FangMing\.m2\repository\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;C:\Users\FangMing\.m2\repository\com\sun\jersey\contribs\jersey-guice\1.9\jersey-guice-1.9.jar;C:\Users\FangMing\.m2\repository\com\google\inject\extensions\guice-servlet\3.0\guice-servlet-3.0.jar;C:\Users\FangMing\.m2\repository\io\netty\netty\3.6.2.Final\netty-3.6.2.Final.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-auth\2.7.3\hadoop-auth-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\httpcomponents\httpclient\4.2.5\httpclient-4.2.5.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\server\apacheds-kerberos-codec\2.0.0-M15\apacheds-kerberos-codec-2.0.0-M15.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\server\apacheds-i18n\2.0.0-M15\apacheds-i18n-2.0.0-M15.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\api\api-asn1-api\1.0.0-M20\api-asn1-api-1.0.0-M20.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\api\api-util\1.0.0-M20\api-util-1.0.0-M20.jar;C:\Users\FangMing\.m2\repository\org\apache\curator\curator-framework\2.7.1\curator-framework-2.7.1.jar;/D:/dev/java/eclipseNeon2/eclipse/configuration/org.eclipse.osgi/389/0/.cp/;/D:/dev/java/eclipseNeon2/eclipse/configuration/org.eclipse.osgi/388/0/.cp/
[2017-05-19 01:19:59,714][main][INFO ]:Client environment:java.library.path=C:\Program Files\Java\jdk7\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:/Program Files/Java/jre/bin/server;C:/Program Files/Java/jre/bin;C:/Program Files/Java/jre/lib/amd64;.;D:\dev\java\libs\hadoop\hadoop-2.7.3\bin;C:\ProgramData\Oracle\Java\javapath;D:\Dev\scripts;E:\study\maven\apache-maven-3.3.9\bin;e:\study\groovy\groovy-2.4.6\bin;E:/study/gradle/gradle-default/bin;C:\Program Files\Java\jdk\bin;E:\Study\ant\apache-ant-1.9.2\bin;C:\oracle\product\11.2.0\client_1;C:\oracle\product\11.2.0\client_1\bin;C:\Program Files (x86)\AMD APP\bin\x86_64;C:\Program Files (x86)\AMD APP\bin\x86;C:\Program Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\Microsoft SQL Server\100\Tools\Binn\;C:\Program Files\Microsoft SQL Server\100\Tools\Binn\;C:\Program Files\Microsoft SQL Server\100\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\100\Tools\Binn\VSShell\Common7\IDE\;C:\Program Files (x86)\Microsoft SQL Server\100\DTS\Binn\;C:\Program Files (x86)\Microsoft Visual Studio 9.0\Common7\IDE\PrivateAssemblies\;C:\Program Files\TortoiseSVN\bin;C:\Program Files\ThinkPad\Bluetooth Software\;C:\Program Files\ThinkPad\Bluetooth Software\syswow64;C:\Program Files\VisualSVN Server\bin;C:\Program Files\Git\cmd;C:\Users\FangMing\AppData\Local\Programs\Python\Python36\Scripts\;C:\Users\FangMing\AppData\Local\Programs\Python\Python36\;D:\dev\java\eclipseNeon2\eclipse;;.
[2017-05-19 01:19:59,714][main][INFO ]:Client environment:java.io.tmpdir=C:\Users\FangMing\AppData\Local\Temp\
[2017-05-19 01:19:59,714][main][INFO ]:Client environment:java.compiler=<NA>
[2017-05-19 01:19:59,714][main][INFO ]:Client environment:os.name=Windows 7
[2017-05-19 01:19:59,715][main][INFO ]:Client environment:os.arch=amd64
[2017-05-19 01:19:59,715][main][INFO ]:Client environment:os.version=6.1
[2017-05-19 01:19:59,715][main][INFO ]:Client environment:user.name=FangMing
[2017-05-19 01:19:59,715][main][INFO ]:Client environment:user.home=C:\Users\FangMing
[2017-05-19 01:19:59,715][main][INFO ]:Client environment:user.dir=D:\dev\java\workspaces\hadoop\hbase-quickstart01
[2017-05-19 01:19:59,717][main][INFO ]:Initiating client connection, connectString=master.hadoop:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@7ba28b34
[2017-05-19 01:19:59,723][main][DEBUG]:zookeeper.disableAutoWatchReset is false
[2017-05-19 01:19:59,758][main-SendThread(master.hadoop:2181)][INFO ]:Opening socket connection to server master.hadoop/192.168.1.104:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-19 01:19:59,761][main-SendThread(master.hadoop:2181)][INFO ]:Socket connection established to master.hadoop/192.168.1.104:2181, initiating session
[2017-05-19 01:19:59,763][main-SendThread(master.hadoop:2181)][DEBUG]:Session establishment request sent on master.hadoop/192.168.1.104:2181
[2017-05-19 01:19:59,814][main-SendThread(master.hadoop:2181)][INFO ]:Session establishment complete on server master.hadoop/192.168.1.104:2181, sessionid = 0x15c1c68faa20009, negotiated timeout = 90000
[2017-05-19 01:19:59,816][main-EventThread][DEBUG]:hconnection-0x5459c1c50x0, quorum=master.hadoop:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
[2017-05-19 01:19:59,817][main-EventThread][DEBUG]:hconnection-0x5459c1c5-0x15c1c68faa20009 connected
[2017-05-19 01:19:59,822][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20009, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,254,0  request:: '/hbase/hbaseid,F  response:: s{17,201,1495101357287,1495125278719,1,0,0,0,67,0,17} 
[2017-05-19 01:19:59,827][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20009, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,254,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffffa1ffffffee3fffffffb5fffffff8ffffff95ffffffeeffffffc350425546a2465636135643364302d656165392d346238332d396665612d613662653530373465623331,s{17,201,1495101357287,1495125278719,1,0,0,0,67,0,17} 
[2017-05-19 01:20:00,284][main][DEBUG]:dfs.client.use.legacy.blockreader.local = false
[2017-05-19 01:20:00,284][main][DEBUG]:dfs.client.read.shortcircuit = false
[2017-05-19 01:20:00,284][main][DEBUG]:dfs.client.domain.socket.data.traffic = false
[2017-05-19 01:20:00,284][main][DEBUG]:dfs.domain.socket.path = 
[2017-05-19 01:20:00,341][main][DEBUG]:multipleLinearRandomRetry = null
[2017-05-19 01:20:00,362][main][DEBUG]:rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@22c977fc
[2017-05-19 01:20:00,704][main][DEBUG]:getting client out of cache: org.apache.hadoop.ipc.Client@97faec2
[2017-05-19 01:20:01,038][main][DEBUG]:Both short-circuit local reads and UNIX domain socket are disabled.
[2017-05-19 01:20:01,045][main][DEBUG]:DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
[2017-05-19 01:20:01,106][main][DEBUG]:Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@5629409d, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
[2017-05-19 01:20:01,215][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20009, packet:: clientPath:null serverPath:null finished:false header:: 3,4  replyHeader:: 3,254,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136323031fffffff366ffffffeeffffff9affffffc71525ffffffcb50425546a19ad6d61737465722e6861646f6f7010ffffffc97e18ffffff87ffffffa8ffffffa4ffffffe3ffffffc12b100183,s{216,216,1495125288124,1495125288124,0,0,0,0,66,0,216} 
[2017-05-19 01:20:01,227][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20009, packet:: clientPath:null serverPath:null finished:false header:: 4,8  replyHeader:: 4,254,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
[2017-05-19 01:20:01,440][hconnection-0x5459c1c5-shared--pool1-t1][DEBUG]:Use SIMPLE authentication for service ClientService, sasl=false
[2017-05-19 01:20:01,457][hconnection-0x5459c1c5-shared--pool1-t1][DEBUG]:Connecting to master.hadoop/192.168.1.104:16201
[2017-05-19 01:20:01,661][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20009, packet:: clientPath:null serverPath:null finished:false header:: 5,3  replyHeader:: 5,254,0  request:: '/hbase,F  response:: s{2,2,1495101350570,1495101350570,0,22,0,0,0,16,216} 
[2017-05-19 01:20:01,665][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20009, packet:: clientPath:null serverPath:null finished:false header:: 6,4  replyHeader:: 6,254,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3136303030ffffffef4452666c58ffffffbfffffffd450425546a19ad6d61737465722e6861646f6f7010ffffff807d18ffffff80ffffffa8ffffffa4ffffffe3ffffffc12b10018ffffff8a7d,s{198,198,1495125275275,1495125275275,0,0,0,97984529102405632,61,0,198} 
[2017-05-19 01:20:01,672][main][DEBUG]:Use SIMPLE authentication for service MasterService, sasl=false
[2017-05-19 01:20:01,672][main][DEBUG]:Connecting to master.hadoop/192.168.1.104:16000
[2017-05-19 01:20:01,679][main][INFO ]:Started disable of users
[2017-05-19 01:20:04,115][main][INFO ]:Disabled users
[2017-05-19 01:20:05,436][main][INFO ]:Deleted users
[2017-05-19 01:20:05,437][main][INFO ]:Closing master protocol: MasterService
[2017-05-19 01:20:05,437][main][INFO ]:Closing zookeeper sessionid=0x15c1c68faa20009
[2017-05-19 01:20:05,437][main][DEBUG]:Closing session: 0x15c1c68faa20009
[2017-05-19 01:20:05,437][main][DEBUG]:Closing client for session: 0x15c1c68faa20009
[2017-05-19 01:20:05,553][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa20009, packet:: clientPath:null serverPath:null finished:false header:: 7,-11  replyHeader:: 7,267,0  request:: null response:: null
[2017-05-19 01:20:05,553][main][DEBUG]:Disconnecting client for session: 0x15c1c68faa20009
[2017-05-19 01:20:05,554][main][INFO ]:Session: 0x15c1c68faa20009 closed
[2017-05-19 01:20:05,554][main][DEBUG]:Stopping rpc client
[2017-05-19 01:20:05,554][main-EventThread][INFO ]:EventThread shut down
[2017-05-19 01:20:05,611][Thread-3][DEBUG]:stopping client from cache: org.apache.hadoop.ipc.Client@97faec2
[2017-05-19 01:20:05,611][Thread-3][DEBUG]:removing client from cache: org.apache.hadoop.ipc.Client@97faec2
[2017-05-19 01:20:05,611][Thread-3][DEBUG]:stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@97faec2
[2017-05-19 01:20:05,611][Thread-3][DEBUG]:Stopping client
[2017-05-19 02:42:49,025][main][DEBUG]: Creating new Groups object
[2017-05-19 02:42:49,081][main][DEBUG]:Trying to load the custom-built native-hadoop library...
[2017-05-19 02:42:49,085][main][DEBUG]:Loaded the native-hadoop library
[2017-05-19 02:42:49,086][main][DEBUG]:Using JniBasedUnixGroupsMapping for Group resolution
[2017-05-19 02:42:49,086][main][DEBUG]:Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
[2017-05-19 02:42:49,303][main][DEBUG]:Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
[2017-05-19 02:42:49,435][main][DEBUG]:field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time, always=false, type=DEFAULT, sampleName=Ops)
[2017-05-19 02:42:49,451][main][DEBUG]:field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time, always=false, type=DEFAULT, sampleName=Ops)
[2017-05-19 02:42:49,452][main][DEBUG]:field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, value=[GetGroups], valueName=Time, always=false, type=DEFAULT, sampleName=Ops)
[2017-05-19 02:42:49,454][main][DEBUG]:UgiMetrics, User and group related metrics
[2017-05-19 02:42:49,678][main][DEBUG]:Kerberos krb5 configuration not found, setting default realm to empty
[2017-05-19 02:42:49,687][main][DEBUG]:hadoop login
[2017-05-19 02:42:49,688][main][DEBUG]:hadoop login commit
[2017-05-19 02:42:49,697][main][DEBUG]:using local user:NTUserPrincipal: FangMing
[2017-05-19 02:42:49,697][main][DEBUG]:Using user: "NTUserPrincipal: FangMing" with name FangMing
[2017-05-19 02:42:49,697][main][DEBUG]:User entry: "FangMing"
[2017-05-19 02:42:49,698][main][DEBUG]:UGI loginUser:FangMing (auth:SIMPLE)
[2017-05-19 02:42:50,233][main][INFO ]:Process identifier=hconnection-0x16bdab45 connecting to ZooKeeper ensemble=master.hadoop:2181
[2017-05-19 02:42:50,241][main][INFO ]:Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
[2017-05-19 02:42:50,241][main][INFO ]:Client environment:host.name=FANGMING-THINK
[2017-05-19 02:42:50,241][main][INFO ]:Client environment:java.version=1.7.0_79
[2017-05-19 02:42:50,241][main][INFO ]:Client environment:java.vendor=Oracle Corporation
[2017-05-19 02:42:50,241][main][INFO ]:Client environment:java.home=C:\Program Files\Java\jdk7\jre
[2017-05-19 02:42:50,242][main][INFO ]:Client environment:java.class.path=D:\dev\java\workspaces\hadoop\hbase-quickstart01\target\test-classes;D:\dev\java\workspaces\hadoop\hbase-quickstart01\target\classes;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-client\1.3.1\hbase-client-1.3.1.jar;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-annotations\1.3.1\hbase-annotations-1.3.1.jar;C:\Users\FangMing\.m2\repository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-common\1.3.1\hbase-common-1.3.1.jar;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-protocol\1.3.1\hbase-protocol-1.3.1.jar;C:\Users\FangMing\.m2\repository\commons-codec\commons-codec\1.9\commons-codec-1.9.jar;C:\Users\FangMing\.m2\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;C:\Users\FangMing\.m2\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;C:\Users\FangMing\.m2\repository\commons-logging\commons-logging\1.2\commons-logging-1.2.jar;C:\Users\FangMing\.m2\repository\com\google\guava\guava\12.0.1\guava-12.0.1.jar;C:\Users\FangMing\.m2\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;C:\Users\FangMing\.m2\repository\io\netty\netty-all\4.0.23.Final\netty-all-4.0.23.Final.jar;C:\Users\FangMing\.m2\repository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;C:\Users\FangMing\.m2\repository\org\apache\htrace\htrace-core\3.1.0-incubating\htrace-core-3.1.0-incubating.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jackson\jackson-mapper-asl\1.9.13\jackson-mapper-asl-1.9.13.jar;C:\Users\FangMing\.m2\repository\org\jruby\jcodings\jcodings\1.0.8\jcodings-1.0.8.jar;C:\Users\FangMing\.m2\repository\org\jruby\joni\joni\2.1.2\joni-2.1.2.jar;C:\Users\FangMing\.m2\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\Program Files\Java\jdk\lib\tools.jar;C:\Users\FangMing\.m2\repository\junit\junit\4.12\junit-4.12.jar;C:\Users\FangMing\.m2\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-common\2.7.3\hadoop-common-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-annotations\2.7.3\hadoop-annotations-2.7.3.jar;C:\Users\FangMing\.m2\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;C:\Users\FangMing\.m2\repository\org\apache\commons\commons-math3\3.1.1\commons-math3-3.1.1.jar;C:\Users\FangMing\.m2\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;C:\Users\FangMing\.m2\repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;C:\Users\FangMing\.m2\repository\commons-net\commons-net\3.1\commons-net-3.1.jar;C:\Users\FangMing\.m2\repository\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;C:\Users\FangMing\.m2\repository\javax\servlet\servlet-api\2.5\servlet-api-2.5.jar;C:\Users\FangMing\.m2\repository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;C:\Users\FangMing\.m2\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;C:\Users\FangMing\.m2\repository\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;C:\Users\FangMing\.m2\repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;C:\Users\FangMing\.m2\repository\com\sun\jersey\jersey-json\1.9\jersey-json-1.9.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;C:\Users\FangMing\.m2\repository\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jackson\jackson-jaxrs\1.8.3\jackson-jaxrs-1.8.3.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jackson\jackson-xc\1.8.3\jackson-xc-1.8.3.jar;C:\Users\FangMing\.m2\repository\com\sun\jersey\jersey-server\1.9\jersey-server-1.9.jar;C:\Users\FangMing\.m2\repository\asm\asm\3.1\asm-3.1.jar;C:\Users\FangMing\.m2\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;C:\Users\FangMing\.m2\repository\net\java\dev\jets3t\jets3t\0.9.0\jets3t-0.9.0.jar;C:\Users\FangMing\.m2\repository\org\apache\httpcomponents\httpcore\4.1.2\httpcore-4.1.2.jar;C:\Users\FangMing\.m2\repository\com\jamesmurty\utils\java-xmlbuilder\0.4\java-xmlbuilder-0.4.jar;C:\Users\FangMing\.m2\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;C:\Users\FangMing\.m2\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;C:\Users\FangMing\.m2\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;C:\Users\FangMing\.m2\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;C:\Users\FangMing\.m2\repository\org\slf4j\slf4j-api\1.7.10\slf4j-api-1.7.10.jar;C:\Users\FangMing\.m2\repository\org\slf4j\slf4j-log4j12\1.7.10\slf4j-log4j12-1.7.10.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;C:\Users\FangMing\.m2\repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;C:\Users\FangMing\.m2\repository\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;C:\Users\FangMing\.m2\repository\org\xerial\snappy\snappy-java\1.0.4.1\snappy-java-1.0.4.1.jar;C:\Users\FangMing\.m2\repository\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;C:\Users\FangMing\.m2\repository\com\jcraft\jsch\0.1.42\jsch-0.1.42.jar;C:\Users\FangMing\.m2\repository\org\apache\curator\curator-client\2.7.1\curator-client-2.7.1.jar;C:\Users\FangMing\.m2\repository\org\apache\curator\curator-recipes\2.7.1\curator-recipes-2.7.1.jar;C:\Users\FangMing\.m2\repository\com\google\code\findbugs\jsr305\3.0.0\jsr305-3.0.0.jar;C:\Users\FangMing\.m2\repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;C:\Users\FangMing\.m2\repository\org\tukaani\xz\1.0\xz-1.0.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-client\2.7.3\hadoop-client-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-hdfs\2.7.3\hadoop-hdfs-2.7.3.jar;C:\Users\FangMing\.m2\repository\xerces\xercesImpl\2.9.1\xercesImpl-2.9.1.jar;C:\Users\FangMing\.m2\repository\xml-apis\xml-apis\1.3.04\xml-apis-1.3.04.jar;C:\Users\FangMing\.m2\repository\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.7.3\hadoop-mapreduce-client-app-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.7.3\hadoop-mapreduce-client-common-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-yarn-client\2.7.3\hadoop-yarn-client-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-yarn-server-common\2.7.3\hadoop-yarn-server-common-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.7.3\hadoop-mapreduce-client-shuffle-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-yarn-api\2.7.3\hadoop-yarn-api-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.7.3\hadoop-mapreduce-client-jobclient-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.7.3\hadoop-mapreduce-client-core-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-yarn-common\2.7.3\hadoop-yarn-common-2.7.3.jar;C:\Users\FangMing\.m2\repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;C:\Users\FangMing\.m2\repository\javax\xml\stream\stax-api\1.0-2\stax-api-1.0-2.jar;C:\Users\FangMing\.m2\repository\javax\activation\activation\1.1\activation-1.1.jar;C:\Users\FangMing\.m2\repository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;C:\Users\FangMing\.m2\repository\com\google\inject\guice\3.0\guice-3.0.jar;C:\Users\FangMing\.m2\repository\javax\inject\javax.inject\1\javax.inject-1.jar;C:\Users\FangMing\.m2\repository\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;C:\Users\FangMing\.m2\repository\com\sun\jersey\contribs\jersey-guice\1.9\jersey-guice-1.9.jar;C:\Users\FangMing\.m2\repository\com\google\inject\extensions\guice-servlet\3.0\guice-servlet-3.0.jar;C:\Users\FangMing\.m2\repository\io\netty\netty\3.6.2.Final\netty-3.6.2.Final.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-auth\2.7.3\hadoop-auth-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\httpcomponents\httpclient\4.2.5\httpclient-4.2.5.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\server\apacheds-kerberos-codec\2.0.0-M15\apacheds-kerberos-codec-2.0.0-M15.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\server\apacheds-i18n\2.0.0-M15\apacheds-i18n-2.0.0-M15.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\api\api-asn1-api\1.0.0-M20\api-asn1-api-1.0.0-M20.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\api\api-util\1.0.0-M20\api-util-1.0.0-M20.jar;C:\Users\FangMing\.m2\repository\org\apache\curator\curator-framework\2.7.1\curator-framework-2.7.1.jar;/D:/dev/java/eclipseNeon2/eclipse/configuration/org.eclipse.osgi/389/0/.cp/;/D:/dev/java/eclipseNeon2/eclipse/configuration/org.eclipse.osgi/388/0/.cp/
[2017-05-19 02:42:50,243][main][INFO ]:Client environment:java.library.path=C:\Program Files\Java\jdk7\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:/Program Files/Java/jre/bin/server;C:/Program Files/Java/jre/bin;C:/Program Files/Java/jre/lib/amd64;.;D:\dev\java\libs\hadoop\hadoop-2.7.3\bin;C:\ProgramData\Oracle\Java\javapath;D:\Dev\scripts;E:\study\maven\apache-maven-3.3.9\bin;e:\study\groovy\groovy-2.4.6\bin;E:/study/gradle/gradle-default/bin;C:\Program Files\Java\jdk\bin;E:\Study\ant\apache-ant-1.9.2\bin;C:\oracle\product\11.2.0\client_1;C:\oracle\product\11.2.0\client_1\bin;C:\Program Files (x86)\AMD APP\bin\x86_64;C:\Program Files (x86)\AMD APP\bin\x86;C:\Program Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\Microsoft SQL Server\100\Tools\Binn\;C:\Program Files\Microsoft SQL Server\100\Tools\Binn\;C:\Program Files\Microsoft SQL Server\100\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\100\Tools\Binn\VSShell\Common7\IDE\;C:\Program Files (x86)\Microsoft SQL Server\100\DTS\Binn\;C:\Program Files (x86)\Microsoft Visual Studio 9.0\Common7\IDE\PrivateAssemblies\;C:\Program Files\TortoiseSVN\bin;C:\Program Files\ThinkPad\Bluetooth Software\;C:\Program Files\ThinkPad\Bluetooth Software\syswow64;C:\Program Files\VisualSVN Server\bin;C:\Program Files\Git\cmd;C:\Users\FangMing\AppData\Local\Programs\Python\Python36\Scripts\;C:\Users\FangMing\AppData\Local\Programs\Python\Python36\;D:\dev\java\eclipseNeon2\eclipse;;.
[2017-05-19 02:42:50,243][main][INFO ]:Client environment:java.io.tmpdir=C:\Users\FangMing\AppData\Local\Temp\
[2017-05-19 02:42:50,243][main][INFO ]:Client environment:java.compiler=<NA>
[2017-05-19 02:42:50,243][main][INFO ]:Client environment:os.name=Windows 7
[2017-05-19 02:42:50,243][main][INFO ]:Client environment:os.arch=amd64
[2017-05-19 02:42:50,243][main][INFO ]:Client environment:os.version=6.1
[2017-05-19 02:42:50,243][main][INFO ]:Client environment:user.name=FangMing
[2017-05-19 02:42:50,243][main][INFO ]:Client environment:user.home=C:\Users\FangMing
[2017-05-19 02:42:50,243][main][INFO ]:Client environment:user.dir=D:\dev\java\workspaces\hadoop\hbase-quickstart01
[2017-05-19 02:42:50,244][main][INFO ]:Initiating client connection, connectString=master.hadoop:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@30df3bd5
[2017-05-19 02:42:50,250][main][DEBUG]:zookeeper.disableAutoWatchReset is false
[2017-05-19 02:42:50,284][main-SendThread(master.hadoop:2181)][INFO ]:Opening socket connection to server master.hadoop/192.168.1.104:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-19 02:42:50,288][main-SendThread(master.hadoop:2181)][INFO ]:Socket connection established to master.hadoop/192.168.1.104:2181, initiating session
[2017-05-19 02:42:50,289][main-SendThread(master.hadoop:2181)][DEBUG]:Session establishment request sent on master.hadoop/192.168.1.104:2181
[2017-05-19 02:42:50,398][main-SendThread(master.hadoop:2181)][INFO ]:Session establishment complete on server master.hadoop/192.168.1.104:2181, sessionid = 0x15c1c68faa2000a, negotiated timeout = 90000
[2017-05-19 02:42:50,400][main-EventThread][DEBUG]:hconnection-0x16bdab450x0, quorum=master.hadoop:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
[2017-05-19 02:42:50,401][main-EventThread][DEBUG]:hconnection-0x16bdab45-0x15c1c68faa2000a connected
[2017-05-19 02:42:50,406][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa2000a, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,268,0  request:: '/hbase/hbaseid,F  response:: s{17,201,1495101357287,1495125278719,1,0,0,0,67,0,17} 
[2017-05-19 02:42:50,409][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa2000a, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,268,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffffa1ffffffee3fffffffb5fffffff8ffffff95ffffffeeffffffc350425546a2465636135643364302d656165392d346238332d396665612d613662653530373465623331,s{17,201,1495101357287,1495125278719,1,0,0,0,67,0,17} 
[2017-05-19 02:42:50,860][main][DEBUG]:dfs.client.use.legacy.blockreader.local = false
[2017-05-19 02:42:50,861][main][DEBUG]:dfs.client.read.shortcircuit = false
[2017-05-19 02:42:50,861][main][DEBUG]:dfs.client.domain.socket.data.traffic = false
[2017-05-19 02:42:50,861][main][DEBUG]:dfs.domain.socket.path = 
[2017-05-19 02:42:50,915][main][DEBUG]:multipleLinearRandomRetry = null
[2017-05-19 02:42:50,936][main][DEBUG]:rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@28d89cb5
[2017-05-19 02:42:51,279][main][DEBUG]:getting client out of cache: org.apache.hadoop.ipc.Client@21a3018
[2017-05-19 02:42:51,616][main][DEBUG]:Both short-circuit local reads and UNIX domain socket are disabled.
[2017-05-19 02:42:51,623][main][DEBUG]:DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
[2017-05-19 02:42:51,688][main][DEBUG]:Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@6d3725a1, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
[2017-05-19 02:42:51,784][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa2000a, packet:: clientPath:null serverPath:null finished:false header:: 3,4  replyHeader:: 3,268,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136323031fffffff366ffffffeeffffff9affffffc71525ffffffcb50425546a19ad6d61737465722e6861646f6f7010ffffffc97e18ffffff87ffffffa8ffffffa4ffffffe3ffffffc12b100183,s{216,216,1495125288124,1495125288124,0,0,0,0,66,0,216} 
[2017-05-19 02:42:51,797][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa2000a, packet:: clientPath:null serverPath:null finished:false header:: 4,8  replyHeader:: 4,268,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
[2017-05-19 02:42:51,982][hconnection-0x16bdab45-shared--pool1-t1][DEBUG]:Use SIMPLE authentication for service ClientService, sasl=false
[2017-05-19 02:42:52,000][hconnection-0x16bdab45-shared--pool1-t1][DEBUG]:Connecting to master.hadoop/192.168.1.104:16201
[2017-05-19 02:42:52,198][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa2000a, packet:: clientPath:null serverPath:null finished:false header:: 5,3  replyHeader:: 5,268,0  request:: '/hbase,F  response:: s{2,2,1495101350570,1495101350570,0,22,0,0,0,16,216} 
[2017-05-19 02:42:52,202][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa2000a, packet:: clientPath:null serverPath:null finished:false header:: 6,4  replyHeader:: 6,268,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3136303030ffffffef4452666c58ffffffbfffffffd450425546a19ad6d61737465722e6861646f6f7010ffffff807d18ffffff80ffffffa8ffffffa4ffffffe3ffffffc12b10018ffffff8a7d,s{198,198,1495125275275,1495125275275,0,0,0,97984529102405632,61,0,198} 
[2017-05-19 02:42:52,209][main][DEBUG]:Use SIMPLE authentication for service MasterService, sasl=false
[2017-05-19 02:42:52,209][main][DEBUG]:Connecting to master.hadoop/192.168.1.104:16000
[2017-05-19 02:42:54,662][main][INFO ]:Created users
[2017-05-19 02:42:54,662][main][INFO ]:Closing master protocol: MasterService
[2017-05-19 02:42:54,663][main][INFO ]:Closing zookeeper sessionid=0x15c1c68faa2000a
[2017-05-19 02:42:54,663][main][DEBUG]:Closing session: 0x15c1c68faa2000a
[2017-05-19 02:42:54,663][main][DEBUG]:Closing client for session: 0x15c1c68faa2000a
[2017-05-19 02:42:54,712][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa2000a, packet:: clientPath:null serverPath:null finished:false header:: 7,-11  replyHeader:: 7,280,0  request:: null response:: null
[2017-05-19 02:42:54,712][main][DEBUG]:Disconnecting client for session: 0x15c1c68faa2000a
[2017-05-19 02:42:54,712][main][INFO ]:Session: 0x15c1c68faa2000a closed
[2017-05-19 02:42:54,713][main][DEBUG]:Stopping rpc client
[2017-05-19 02:42:54,713][main-EventThread][INFO ]:EventThread shut down
[2017-05-19 02:42:54,731][Thread-3][DEBUG]:stopping client from cache: org.apache.hadoop.ipc.Client@21a3018
[2017-05-19 02:42:54,731][Thread-3][DEBUG]:removing client from cache: org.apache.hadoop.ipc.Client@21a3018
[2017-05-19 02:42:54,731][Thread-3][DEBUG]:stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@21a3018
[2017-05-19 02:42:54,731][Thread-3][DEBUG]:Stopping client
[2017-05-19 02:43:40,698][main][DEBUG]: Creating new Groups object
[2017-05-19 02:43:40,760][main][DEBUG]:Trying to load the custom-built native-hadoop library...
[2017-05-19 02:43:40,763][main][DEBUG]:Loaded the native-hadoop library
[2017-05-19 02:43:40,764][main][DEBUG]:Using JniBasedUnixGroupsMapping for Group resolution
[2017-05-19 02:43:40,764][main][DEBUG]:Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
[2017-05-19 02:43:41,011][main][DEBUG]:Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
[2017-05-19 02:43:41,173][main][DEBUG]:field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)], about=, always=false, type=DEFAULT, sampleName=Ops)
[2017-05-19 02:43:41,192][main][DEBUG]:field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)], about=, always=false, type=DEFAULT, sampleName=Ops)
[2017-05-19 02:43:41,192][main][DEBUG]:field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[GetGroups], about=, always=false, type=DEFAULT, sampleName=Ops)
[2017-05-19 02:43:41,194][main][DEBUG]:UgiMetrics, User and group related metrics
[2017-05-19 02:43:41,446][main][DEBUG]:Kerberos krb5 configuration not found, setting default realm to empty
[2017-05-19 02:43:41,455][main][DEBUG]:hadoop login
[2017-05-19 02:43:41,456][main][DEBUG]:hadoop login commit
[2017-05-19 02:43:41,466][main][DEBUG]:using local user:NTUserPrincipal: FangMing
[2017-05-19 02:43:41,466][main][DEBUG]:Using user: "NTUserPrincipal: FangMing" with name FangMing
[2017-05-19 02:43:41,466][main][DEBUG]:User entry: "FangMing"
[2017-05-19 02:43:41,467][main][DEBUG]:UGI loginUser:FangMing (auth:SIMPLE)
[2017-05-19 02:43:42,044][main][INFO ]:Process identifier=hconnection-0x7e374aac connecting to ZooKeeper ensemble=master.hadoop:2181
[2017-05-19 02:43:42,054][main][INFO ]:Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
[2017-05-19 02:43:42,054][main][INFO ]:Client environment:host.name=FANGMING-THINK
[2017-05-19 02:43:42,054][main][INFO ]:Client environment:java.version=1.7.0_79
[2017-05-19 02:43:42,054][main][INFO ]:Client environment:java.vendor=Oracle Corporation
[2017-05-19 02:43:42,054][main][INFO ]:Client environment:java.home=C:\Program Files\Java\jdk7\jre
[2017-05-19 02:43:42,054][main][INFO ]:Client environment:java.class.path=D:\dev\java\workspaces\hadoop\hbase-quickstart01\target\test-classes;D:\dev\java\workspaces\hadoop\hbase-quickstart01\target\classes;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-client\1.3.1\hbase-client-1.3.1.jar;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-annotations\1.3.1\hbase-annotations-1.3.1.jar;C:\Users\FangMing\.m2\repository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-common\1.3.1\hbase-common-1.3.1.jar;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-protocol\1.3.1\hbase-protocol-1.3.1.jar;C:\Users\FangMing\.m2\repository\commons-codec\commons-codec\1.9\commons-codec-1.9.jar;C:\Users\FangMing\.m2\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;C:\Users\FangMing\.m2\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;C:\Users\FangMing\.m2\repository\commons-logging\commons-logging\1.2\commons-logging-1.2.jar;C:\Users\FangMing\.m2\repository\com\google\guava\guava\12.0.1\guava-12.0.1.jar;C:\Users\FangMing\.m2\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;C:\Users\FangMing\.m2\repository\io\netty\netty-all\4.0.23.Final\netty-all-4.0.23.Final.jar;C:\Users\FangMing\.m2\repository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;C:\Users\FangMing\.m2\repository\org\apache\htrace\htrace-core\3.1.0-incubating\htrace-core-3.1.0-incubating.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jackson\jackson-mapper-asl\1.9.13\jackson-mapper-asl-1.9.13.jar;C:\Users\FangMing\.m2\repository\org\jruby\jcodings\jcodings\1.0.8\jcodings-1.0.8.jar;C:\Users\FangMing\.m2\repository\org\jruby\joni\joni\2.1.2\joni-2.1.2.jar;C:\Users\FangMing\.m2\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\Program Files\Java\jdk\lib\tools.jar;C:\Users\FangMing\.m2\repository\junit\junit\4.12\junit-4.12.jar;C:\Users\FangMing\.m2\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-common\2.7.3\hadoop-common-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-annotations\2.7.3\hadoop-annotations-2.7.3.jar;C:\Users\FangMing\.m2\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;C:\Users\FangMing\.m2\repository\org\apache\commons\commons-math3\3.1.1\commons-math3-3.1.1.jar;C:\Users\FangMing\.m2\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;C:\Users\FangMing\.m2\repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;C:\Users\FangMing\.m2\repository\commons-net\commons-net\3.1\commons-net-3.1.jar;C:\Users\FangMing\.m2\repository\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;C:\Users\FangMing\.m2\repository\javax\servlet\servlet-api\2.5\servlet-api-2.5.jar;C:\Users\FangMing\.m2\repository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;C:\Users\FangMing\.m2\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;C:\Users\FangMing\.m2\repository\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;C:\Users\FangMing\.m2\repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;C:\Users\FangMing\.m2\repository\com\sun\jersey\jersey-json\1.9\jersey-json-1.9.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;C:\Users\FangMing\.m2\repository\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jackson\jackson-jaxrs\1.8.3\jackson-jaxrs-1.8.3.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jackson\jackson-xc\1.8.3\jackson-xc-1.8.3.jar;C:\Users\FangMing\.m2\repository\com\sun\jersey\jersey-server\1.9\jersey-server-1.9.jar;C:\Users\FangMing\.m2\repository\asm\asm\3.1\asm-3.1.jar;C:\Users\FangMing\.m2\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;C:\Users\FangMing\.m2\repository\net\java\dev\jets3t\jets3t\0.9.0\jets3t-0.9.0.jar;C:\Users\FangMing\.m2\repository\org\apache\httpcomponents\httpcore\4.1.2\httpcore-4.1.2.jar;C:\Users\FangMing\.m2\repository\com\jamesmurty\utils\java-xmlbuilder\0.4\java-xmlbuilder-0.4.jar;C:\Users\FangMing\.m2\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;C:\Users\FangMing\.m2\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;C:\Users\FangMing\.m2\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;C:\Users\FangMing\.m2\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;C:\Users\FangMing\.m2\repository\org\slf4j\slf4j-api\1.7.10\slf4j-api-1.7.10.jar;C:\Users\FangMing\.m2\repository\org\slf4j\slf4j-log4j12\1.7.10\slf4j-log4j12-1.7.10.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;C:\Users\FangMing\.m2\repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;C:\Users\FangMing\.m2\repository\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;C:\Users\FangMing\.m2\repository\org\xerial\snappy\snappy-java\1.0.4.1\snappy-java-1.0.4.1.jar;C:\Users\FangMing\.m2\repository\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;C:\Users\FangMing\.m2\repository\com\jcraft\jsch\0.1.42\jsch-0.1.42.jar;C:\Users\FangMing\.m2\repository\org\apache\curator\curator-client\2.7.1\curator-client-2.7.1.jar;C:\Users\FangMing\.m2\repository\org\apache\curator\curator-recipes\2.7.1\curator-recipes-2.7.1.jar;C:\Users\FangMing\.m2\repository\com\google\code\findbugs\jsr305\3.0.0\jsr305-3.0.0.jar;C:\Users\FangMing\.m2\repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;C:\Users\FangMing\.m2\repository\org\tukaani\xz\1.0\xz-1.0.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-client\2.7.3\hadoop-client-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-hdfs\2.7.3\hadoop-hdfs-2.7.3.jar;C:\Users\FangMing\.m2\repository\xerces\xercesImpl\2.9.1\xercesImpl-2.9.1.jar;C:\Users\FangMing\.m2\repository\xml-apis\xml-apis\1.3.04\xml-apis-1.3.04.jar;C:\Users\FangMing\.m2\repository\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.7.3\hadoop-mapreduce-client-app-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.7.3\hadoop-mapreduce-client-common-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-yarn-client\2.7.3\hadoop-yarn-client-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-yarn-server-common\2.7.3\hadoop-yarn-server-common-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.7.3\hadoop-mapreduce-client-shuffle-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-yarn-api\2.7.3\hadoop-yarn-api-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.7.3\hadoop-mapreduce-client-jobclient-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.7.3\hadoop-mapreduce-client-core-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-yarn-common\2.7.3\hadoop-yarn-common-2.7.3.jar;C:\Users\FangMing\.m2\repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;C:\Users\FangMing\.m2\repository\javax\xml\stream\stax-api\1.0-2\stax-api-1.0-2.jar;C:\Users\FangMing\.m2\repository\javax\activation\activation\1.1\activation-1.1.jar;C:\Users\FangMing\.m2\repository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;C:\Users\FangMing\.m2\repository\com\google\inject\guice\3.0\guice-3.0.jar;C:\Users\FangMing\.m2\repository\javax\inject\javax.inject\1\javax.inject-1.jar;C:\Users\FangMing\.m2\repository\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;C:\Users\FangMing\.m2\repository\com\sun\jersey\contribs\jersey-guice\1.9\jersey-guice-1.9.jar;C:\Users\FangMing\.m2\repository\com\google\inject\extensions\guice-servlet\3.0\guice-servlet-3.0.jar;C:\Users\FangMing\.m2\repository\io\netty\netty\3.6.2.Final\netty-3.6.2.Final.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-auth\2.7.3\hadoop-auth-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\httpcomponents\httpclient\4.2.5\httpclient-4.2.5.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\server\apacheds-kerberos-codec\2.0.0-M15\apacheds-kerberos-codec-2.0.0-M15.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\server\apacheds-i18n\2.0.0-M15\apacheds-i18n-2.0.0-M15.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\api\api-asn1-api\1.0.0-M20\api-asn1-api-1.0.0-M20.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\api\api-util\1.0.0-M20\api-util-1.0.0-M20.jar;C:\Users\FangMing\.m2\repository\org\apache\curator\curator-framework\2.7.1\curator-framework-2.7.1.jar;/D:/dev/java/eclipseNeon2/eclipse/configuration/org.eclipse.osgi/389/0/.cp/;/D:/dev/java/eclipseNeon2/eclipse/configuration/org.eclipse.osgi/388/0/.cp/
[2017-05-19 02:43:42,065][main][INFO ]:Client environment:java.library.path=C:\Program Files\Java\jdk7\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:/Program Files/Java/jre/bin/server;C:/Program Files/Java/jre/bin;C:/Program Files/Java/jre/lib/amd64;.;D:\dev\java\libs\hadoop\hadoop-2.7.3\bin;C:\ProgramData\Oracle\Java\javapath;D:\Dev\scripts;E:\study\maven\apache-maven-3.3.9\bin;e:\study\groovy\groovy-2.4.6\bin;E:/study/gradle/gradle-default/bin;C:\Program Files\Java\jdk\bin;E:\Study\ant\apache-ant-1.9.2\bin;C:\oracle\product\11.2.0\client_1;C:\oracle\product\11.2.0\client_1\bin;C:\Program Files (x86)\AMD APP\bin\x86_64;C:\Program Files (x86)\AMD APP\bin\x86;C:\Program Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\Microsoft SQL Server\100\Tools\Binn\;C:\Program Files\Microsoft SQL Server\100\Tools\Binn\;C:\Program Files\Microsoft SQL Server\100\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\100\Tools\Binn\VSShell\Common7\IDE\;C:\Program Files (x86)\Microsoft SQL Server\100\DTS\Binn\;C:\Program Files (x86)\Microsoft Visual Studio 9.0\Common7\IDE\PrivateAssemblies\;C:\Program Files\TortoiseSVN\bin;C:\Program Files\ThinkPad\Bluetooth Software\;C:\Program Files\ThinkPad\Bluetooth Software\syswow64;C:\Program Files\VisualSVN Server\bin;C:\Program Files\Git\cmd;C:\Users\FangMing\AppData\Local\Programs\Python\Python36\Scripts\;C:\Users\FangMing\AppData\Local\Programs\Python\Python36\;D:\dev\java\eclipseNeon2\eclipse;;.
[2017-05-19 02:43:42,065][main][INFO ]:Client environment:java.io.tmpdir=C:\Users\FangMing\AppData\Local\Temp\
[2017-05-19 02:43:42,065][main][INFO ]:Client environment:java.compiler=<NA>
[2017-05-19 02:43:42,065][main][INFO ]:Client environment:os.name=Windows 7
[2017-05-19 02:43:42,065][main][INFO ]:Client environment:os.arch=amd64
[2017-05-19 02:43:42,066][main][INFO ]:Client environment:os.version=6.1
[2017-05-19 02:43:42,066][main][INFO ]:Client environment:user.name=FangMing
[2017-05-19 02:43:42,066][main][INFO ]:Client environment:user.home=C:\Users\FangMing
[2017-05-19 02:43:42,066][main][INFO ]:Client environment:user.dir=D:\dev\java\workspaces\hadoop\hbase-quickstart01
[2017-05-19 02:43:42,067][main][INFO ]:Initiating client connection, connectString=master.hadoop:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@fd13604
[2017-05-19 02:43:42,076][main][DEBUG]:zookeeper.disableAutoWatchReset is false
[2017-05-19 02:43:42,111][main-SendThread(master.hadoop:2181)][INFO ]:Opening socket connection to server master.hadoop/192.168.1.104:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-19 02:43:42,138][main-SendThread(master.hadoop:2181)][INFO ]:Socket connection established to master.hadoop/192.168.1.104:2181, initiating session
[2017-05-19 02:43:42,139][main-SendThread(master.hadoop:2181)][DEBUG]:Session establishment request sent on master.hadoop/192.168.1.104:2181
[2017-05-19 02:43:42,248][main-SendThread(master.hadoop:2181)][INFO ]:Session establishment complete on server master.hadoop/192.168.1.104:2181, sessionid = 0x15c1c68faa2000b, negotiated timeout = 90000
[2017-05-19 02:43:42,250][main-EventThread][DEBUG]:hconnection-0x7e374aac0x0, quorum=master.hadoop:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
[2017-05-19 02:43:42,251][main-EventThread][DEBUG]:hconnection-0x7e374aac-0x15c1c68faa2000b connected
[2017-05-19 02:43:42,256][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa2000b, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,281,0  request:: '/hbase/hbaseid,F  response:: s{17,201,1495101357287,1495125278719,1,0,0,0,67,0,17} 
[2017-05-19 02:43:42,259][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa2000b, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,281,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffffa1ffffffee3fffffffb5fffffff8ffffff95ffffffeeffffffc350425546a2465636135643364302d656165392d346238332d396665612d613662653530373465623331,s{17,201,1495101357287,1495125278719,1,0,0,0,67,0,17} 
[2017-05-19 02:43:42,700][main][DEBUG]:dfs.client.use.legacy.blockreader.local = false
[2017-05-19 02:43:42,700][main][DEBUG]:dfs.client.read.shortcircuit = false
[2017-05-19 02:43:42,700][main][DEBUG]:dfs.client.domain.socket.data.traffic = false
[2017-05-19 02:43:42,700][main][DEBUG]:dfs.domain.socket.path = 
[2017-05-19 02:43:42,752][main][DEBUG]:multipleLinearRandomRetry = null
[2017-05-19 02:43:42,773][main][DEBUG]:rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@2ada9a2b
[2017-05-19 02:43:43,106][main][DEBUG]:getting client out of cache: org.apache.hadoop.ipc.Client@f669400
[2017-05-19 02:43:43,436][main][DEBUG]:Both short-circuit local reads and UNIX domain socket are disabled.
[2017-05-19 02:43:43,443][main][DEBUG]:DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
[2017-05-19 02:43:43,500][main][DEBUG]:Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@33cbcffe, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
[2017-05-19 02:43:43,551][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa2000b, packet:: clientPath:null serverPath:null finished:false header:: 3,3  replyHeader:: 3,281,0  request:: '/hbase,F  response:: s{2,2,1495101350570,1495101350570,0,22,0,0,0,16,216} 
[2017-05-19 02:43:43,555][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa2000b, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,281,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a3136303030ffffffef4452666c58ffffffbfffffffd450425546a19ad6d61737465722e6861646f6f7010ffffff807d18ffffff80ffffffa8ffffffa4ffffffe3ffffffc12b10018ffffff8a7d,s{198,198,1495125275275,1495125275275,0,0,0,97984529102405632,61,0,198} 
[2017-05-19 02:43:43,717][main][DEBUG]:Use SIMPLE authentication for service MasterService, sasl=false
[2017-05-19 02:43:43,740][main][DEBUG]:Connecting to master.hadoop/192.168.1.104:16000
[2017-05-19 02:43:43,979][main][INFO ]:Closing master protocol: MasterService
[2017-05-19 02:43:43,979][main][INFO ]:Closing zookeeper sessionid=0x15c1c68faa2000b
[2017-05-19 02:43:43,979][main][DEBUG]:Closing session: 0x15c1c68faa2000b
[2017-05-19 02:43:43,979][main][DEBUG]:Closing client for session: 0x15c1c68faa2000b
[2017-05-19 02:43:44,088][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa2000b, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,282,0  request:: null response:: null
[2017-05-19 02:43:44,088][main-SendThread(master.hadoop:2181)][DEBUG]:An exception was thrown while closing send thread for session 0x15c1c68faa2000b : Unable to read additional data from server sessionid 0x15c1c68faa2000b, likely server has closed socket
[2017-05-19 02:43:44,088][main][DEBUG]:Disconnecting client for session: 0x15c1c68faa2000b
[2017-05-19 02:43:44,088][main][INFO ]:Session: 0x15c1c68faa2000b closed
[2017-05-19 02:43:44,088][main-EventThread][INFO ]:EventThread shut down
[2017-05-19 02:43:44,089][main][DEBUG]:Stopping rpc client
[2017-05-19 02:43:44,106][Thread-3][DEBUG]:stopping client from cache: org.apache.hadoop.ipc.Client@f669400
[2017-05-19 02:43:44,107][Thread-3][DEBUG]:removing client from cache: org.apache.hadoop.ipc.Client@f669400
[2017-05-19 02:43:44,107][Thread-3][DEBUG]:stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@f669400
[2017-05-19 02:43:44,107][Thread-3][DEBUG]:Stopping client
[2017-05-19 02:46:29,547][main][DEBUG]: Creating new Groups object
[2017-05-19 02:46:29,613][main][DEBUG]:Trying to load the custom-built native-hadoop library...
[2017-05-19 02:46:29,617][main][DEBUG]:Loaded the native-hadoop library
[2017-05-19 02:46:29,618][main][DEBUG]:Using JniBasedUnixGroupsMapping for Group resolution
[2017-05-19 02:46:29,618][main][DEBUG]:Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
[2017-05-19 02:46:29,827][main][DEBUG]:Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
[2017-05-19 02:46:30,003][main][DEBUG]:field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)], about=, always=false, type=DEFAULT, sampleName=Ops)
[2017-05-19 02:46:30,021][main][DEBUG]:field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)], about=, always=false, type=DEFAULT, sampleName=Ops)
[2017-05-19 02:46:30,021][main][DEBUG]:field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[GetGroups], about=, always=false, type=DEFAULT, sampleName=Ops)
[2017-05-19 02:46:30,023][main][DEBUG]:UgiMetrics, User and group related metrics
[2017-05-19 02:46:30,219][main][DEBUG]:Kerberos krb5 configuration not found, setting default realm to empty
[2017-05-19 02:46:30,226][main][DEBUG]:hadoop login
[2017-05-19 02:46:30,227][main][DEBUG]:hadoop login commit
[2017-05-19 02:46:30,236][main][DEBUG]:using local user:NTUserPrincipal: FangMing
[2017-05-19 02:46:30,236][main][DEBUG]:Using user: "NTUserPrincipal: FangMing" with name FangMing
[2017-05-19 02:46:30,237][main][DEBUG]:User entry: "FangMing"
[2017-05-19 02:46:30,238][main][DEBUG]:UGI loginUser:FangMing (auth:SIMPLE)
[2017-05-19 02:46:30,796][main][INFO ]:Process identifier=hconnection-0x1607219a connecting to ZooKeeper ensemble=master.hadoop:2181
[2017-05-19 02:46:30,805][main][INFO ]:Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
[2017-05-19 02:46:30,805][main][INFO ]:Client environment:host.name=FANGMING-THINK
[2017-05-19 02:46:30,805][main][INFO ]:Client environment:java.version=1.7.0_79
[2017-05-19 02:46:30,805][main][INFO ]:Client environment:java.vendor=Oracle Corporation
[2017-05-19 02:46:30,805][main][INFO ]:Client environment:java.home=C:\Program Files\Java\jdk7\jre
[2017-05-19 02:46:30,805][main][INFO ]:Client environment:java.class.path=D:\dev\java\workspaces\hadoop\hbase-quickstart01\target\test-classes;D:\dev\java\workspaces\hadoop\hbase-quickstart01\target\classes;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-client\1.3.1\hbase-client-1.3.1.jar;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-annotations\1.3.1\hbase-annotations-1.3.1.jar;C:\Users\FangMing\.m2\repository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-common\1.3.1\hbase-common-1.3.1.jar;C:\Users\FangMing\.m2\repository\org\apache\hbase\hbase-protocol\1.3.1\hbase-protocol-1.3.1.jar;C:\Users\FangMing\.m2\repository\commons-codec\commons-codec\1.9\commons-codec-1.9.jar;C:\Users\FangMing\.m2\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;C:\Users\FangMing\.m2\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;C:\Users\FangMing\.m2\repository\commons-logging\commons-logging\1.2\commons-logging-1.2.jar;C:\Users\FangMing\.m2\repository\com\google\guava\guava\12.0.1\guava-12.0.1.jar;C:\Users\FangMing\.m2\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;C:\Users\FangMing\.m2\repository\io\netty\netty-all\4.0.23.Final\netty-all-4.0.23.Final.jar;C:\Users\FangMing\.m2\repository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;C:\Users\FangMing\.m2\repository\org\apache\htrace\htrace-core\3.1.0-incubating\htrace-core-3.1.0-incubating.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jackson\jackson-mapper-asl\1.9.13\jackson-mapper-asl-1.9.13.jar;C:\Users\FangMing\.m2\repository\org\jruby\jcodings\jcodings\1.0.8\jcodings-1.0.8.jar;C:\Users\FangMing\.m2\repository\org\jruby\joni\joni\2.1.2\joni-2.1.2.jar;C:\Users\FangMing\.m2\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\Program Files\Java\jdk\lib\tools.jar;C:\Users\FangMing\.m2\repository\junit\junit\4.12\junit-4.12.jar;C:\Users\FangMing\.m2\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-common\2.7.3\hadoop-common-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-annotations\2.7.3\hadoop-annotations-2.7.3.jar;C:\Users\FangMing\.m2\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;C:\Users\FangMing\.m2\repository\org\apache\commons\commons-math3\3.1.1\commons-math3-3.1.1.jar;C:\Users\FangMing\.m2\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;C:\Users\FangMing\.m2\repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;C:\Users\FangMing\.m2\repository\commons-net\commons-net\3.1\commons-net-3.1.jar;C:\Users\FangMing\.m2\repository\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;C:\Users\FangMing\.m2\repository\javax\servlet\servlet-api\2.5\servlet-api-2.5.jar;C:\Users\FangMing\.m2\repository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;C:\Users\FangMing\.m2\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;C:\Users\FangMing\.m2\repository\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;C:\Users\FangMing\.m2\repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;C:\Users\FangMing\.m2\repository\com\sun\jersey\jersey-json\1.9\jersey-json-1.9.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;C:\Users\FangMing\.m2\repository\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jackson\jackson-jaxrs\1.8.3\jackson-jaxrs-1.8.3.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jackson\jackson-xc\1.8.3\jackson-xc-1.8.3.jar;C:\Users\FangMing\.m2\repository\com\sun\jersey\jersey-server\1.9\jersey-server-1.9.jar;C:\Users\FangMing\.m2\repository\asm\asm\3.1\asm-3.1.jar;C:\Users\FangMing\.m2\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;C:\Users\FangMing\.m2\repository\net\java\dev\jets3t\jets3t\0.9.0\jets3t-0.9.0.jar;C:\Users\FangMing\.m2\repository\org\apache\httpcomponents\httpcore\4.1.2\httpcore-4.1.2.jar;C:\Users\FangMing\.m2\repository\com\jamesmurty\utils\java-xmlbuilder\0.4\java-xmlbuilder-0.4.jar;C:\Users\FangMing\.m2\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;C:\Users\FangMing\.m2\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;C:\Users\FangMing\.m2\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;C:\Users\FangMing\.m2\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;C:\Users\FangMing\.m2\repository\org\slf4j\slf4j-api\1.7.10\slf4j-api-1.7.10.jar;C:\Users\FangMing\.m2\repository\org\slf4j\slf4j-log4j12\1.7.10\slf4j-log4j12-1.7.10.jar;C:\Users\FangMing\.m2\repository\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;C:\Users\FangMing\.m2\repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;C:\Users\FangMing\.m2\repository\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;C:\Users\FangMing\.m2\repository\org\xerial\snappy\snappy-java\1.0.4.1\snappy-java-1.0.4.1.jar;C:\Users\FangMing\.m2\repository\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;C:\Users\FangMing\.m2\repository\com\jcraft\jsch\0.1.42\jsch-0.1.42.jar;C:\Users\FangMing\.m2\repository\org\apache\curator\curator-client\2.7.1\curator-client-2.7.1.jar;C:\Users\FangMing\.m2\repository\org\apache\curator\curator-recipes\2.7.1\curator-recipes-2.7.1.jar;C:\Users\FangMing\.m2\repository\com\google\code\findbugs\jsr305\3.0.0\jsr305-3.0.0.jar;C:\Users\FangMing\.m2\repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;C:\Users\FangMing\.m2\repository\org\tukaani\xz\1.0\xz-1.0.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-client\2.7.3\hadoop-client-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-hdfs\2.7.3\hadoop-hdfs-2.7.3.jar;C:\Users\FangMing\.m2\repository\xerces\xercesImpl\2.9.1\xercesImpl-2.9.1.jar;C:\Users\FangMing\.m2\repository\xml-apis\xml-apis\1.3.04\xml-apis-1.3.04.jar;C:\Users\FangMing\.m2\repository\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.7.3\hadoop-mapreduce-client-app-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.7.3\hadoop-mapreduce-client-common-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-yarn-client\2.7.3\hadoop-yarn-client-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-yarn-server-common\2.7.3\hadoop-yarn-server-common-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.7.3\hadoop-mapreduce-client-shuffle-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-yarn-api\2.7.3\hadoop-yarn-api-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.7.3\hadoop-mapreduce-client-jobclient-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.7.3\hadoop-mapreduce-client-core-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-yarn-common\2.7.3\hadoop-yarn-common-2.7.3.jar;C:\Users\FangMing\.m2\repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;C:\Users\FangMing\.m2\repository\javax\xml\stream\stax-api\1.0-2\stax-api-1.0-2.jar;C:\Users\FangMing\.m2\repository\javax\activation\activation\1.1\activation-1.1.jar;C:\Users\FangMing\.m2\repository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;C:\Users\FangMing\.m2\repository\com\google\inject\guice\3.0\guice-3.0.jar;C:\Users\FangMing\.m2\repository\javax\inject\javax.inject\1\javax.inject-1.jar;C:\Users\FangMing\.m2\repository\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;C:\Users\FangMing\.m2\repository\com\sun\jersey\contribs\jersey-guice\1.9\jersey-guice-1.9.jar;C:\Users\FangMing\.m2\repository\com\google\inject\extensions\guice-servlet\3.0\guice-servlet-3.0.jar;C:\Users\FangMing\.m2\repository\io\netty\netty\3.6.2.Final\netty-3.6.2.Final.jar;C:\Users\FangMing\.m2\repository\org\apache\hadoop\hadoop-auth\2.7.3\hadoop-auth-2.7.3.jar;C:\Users\FangMing\.m2\repository\org\apache\httpcomponents\httpclient\4.2.5\httpclient-4.2.5.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\server\apacheds-kerberos-codec\2.0.0-M15\apacheds-kerberos-codec-2.0.0-M15.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\server\apacheds-i18n\2.0.0-M15\apacheds-i18n-2.0.0-M15.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\api\api-asn1-api\1.0.0-M20\api-asn1-api-1.0.0-M20.jar;C:\Users\FangMing\.m2\repository\org\apache\directory\api\api-util\1.0.0-M20\api-util-1.0.0-M20.jar;C:\Users\FangMing\.m2\repository\org\apache\curator\curator-framework\2.7.1\curator-framework-2.7.1.jar;/D:/dev/java/eclipseNeon2/eclipse/configuration/org.eclipse.osgi/389/0/.cp/;/D:/dev/java/eclipseNeon2/eclipse/configuration/org.eclipse.osgi/388/0/.cp/
[2017-05-19 02:46:30,806][main][INFO ]:Client environment:java.library.path=C:\Program Files\Java\jdk7\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:/Program Files/Java/jre/bin/server;C:/Program Files/Java/jre/bin;C:/Program Files/Java/jre/lib/amd64;.;D:\dev\java\libs\hadoop\hadoop-2.7.3\bin;C:\ProgramData\Oracle\Java\javapath;D:\Dev\scripts;E:\study\maven\apache-maven-3.3.9\bin;e:\study\groovy\groovy-2.4.6\bin;E:/study/gradle/gradle-default/bin;C:\Program Files\Java\jdk\bin;E:\Study\ant\apache-ant-1.9.2\bin;C:\oracle\product\11.2.0\client_1;C:\oracle\product\11.2.0\client_1\bin;C:\Program Files (x86)\AMD APP\bin\x86_64;C:\Program Files (x86)\AMD APP\bin\x86;C:\Program Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\Microsoft SQL Server\100\Tools\Binn\;C:\Program Files\Microsoft SQL Server\100\Tools\Binn\;C:\Program Files\Microsoft SQL Server\100\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\100\Tools\Binn\VSShell\Common7\IDE\;C:\Program Files (x86)\Microsoft SQL Server\100\DTS\Binn\;C:\Program Files (x86)\Microsoft Visual Studio 9.0\Common7\IDE\PrivateAssemblies\;C:\Program Files\TortoiseSVN\bin;C:\Program Files\ThinkPad\Bluetooth Software\;C:\Program Files\ThinkPad\Bluetooth Software\syswow64;C:\Program Files\VisualSVN Server\bin;C:\Program Files\Git\cmd;C:\Users\FangMing\AppData\Local\Programs\Python\Python36\Scripts\;C:\Users\FangMing\AppData\Local\Programs\Python\Python36\;D:\dev\java\eclipseNeon2\eclipse;;.
[2017-05-19 02:46:30,807][main][INFO ]:Client environment:java.io.tmpdir=C:\Users\FangMing\AppData\Local\Temp\
[2017-05-19 02:46:30,807][main][INFO ]:Client environment:java.compiler=<NA>
[2017-05-19 02:46:30,807][main][INFO ]:Client environment:os.name=Windows 7
[2017-05-19 02:46:30,807][main][INFO ]:Client environment:os.arch=amd64
[2017-05-19 02:46:30,807][main][INFO ]:Client environment:os.version=6.1
[2017-05-19 02:46:30,807][main][INFO ]:Client environment:user.name=FangMing
[2017-05-19 02:46:30,807][main][INFO ]:Client environment:user.home=C:\Users\FangMing
[2017-05-19 02:46:30,807][main][INFO ]:Client environment:user.dir=D:\dev\java\workspaces\hadoop\hbase-quickstart01
[2017-05-19 02:46:30,809][main][INFO ]:Initiating client connection, connectString=master.hadoop:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@40ca99c9
[2017-05-19 02:46:30,815][main][DEBUG]:zookeeper.disableAutoWatchReset is false
[2017-05-19 02:46:30,852][main-SendThread(master.hadoop:2181)][INFO ]:Opening socket connection to server master.hadoop/192.168.1.104:2181. Will not attempt to authenticate using SASL (unknown error)
[2017-05-19 02:46:30,854][main-SendThread(master.hadoop:2181)][INFO ]:Socket connection established to master.hadoop/192.168.1.104:2181, initiating session
[2017-05-19 02:46:30,856][main-SendThread(master.hadoop:2181)][DEBUG]:Session establishment request sent on master.hadoop/192.168.1.104:2181
[2017-05-19 02:46:30,914][main-SendThread(master.hadoop:2181)][INFO ]:Session establishment complete on server master.hadoop/192.168.1.104:2181, sessionid = 0x15c1c68faa2000c, negotiated timeout = 90000
[2017-05-19 02:46:30,917][main-EventThread][DEBUG]:hconnection-0x1607219a0x0, quorum=master.hadoop:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
[2017-05-19 02:46:30,917][main-EventThread][DEBUG]:hconnection-0x1607219a-0x15c1c68faa2000c connected
[2017-05-19 02:46:30,923][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa2000c, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,283,0  request:: '/hbase/hbaseid,F  response:: s{17,201,1495101357287,1495125278719,1,0,0,0,67,0,17} 
[2017-05-19 02:46:30,927][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa2000c, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,283,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffffa1ffffffee3fffffffb5fffffff8ffffff95ffffffeeffffffc350425546a2465636135643364302d656165392d346238332d396665612d613662653530373465623331,s{17,201,1495101357287,1495125278719,1,0,0,0,67,0,17} 
[2017-05-19 02:46:31,382][main][DEBUG]:dfs.client.use.legacy.blockreader.local = false
[2017-05-19 02:46:31,382][main][DEBUG]:dfs.client.read.shortcircuit = false
[2017-05-19 02:46:31,382][main][DEBUG]:dfs.client.domain.socket.data.traffic = false
[2017-05-19 02:46:31,382][main][DEBUG]:dfs.domain.socket.path = 
[2017-05-19 02:46:31,435][main][DEBUG]:multipleLinearRandomRetry = null
[2017-05-19 02:46:31,459][main][DEBUG]:rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@2bdf07af
[2017-05-19 02:46:31,799][main][DEBUG]:getting client out of cache: org.apache.hadoop.ipc.Client@5fbefaf1
[2017-05-19 02:46:32,144][main][DEBUG]:Both short-circuit local reads and UNIX domain socket are disabled.
[2017-05-19 02:46:32,151][main][DEBUG]:DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
[2017-05-19 02:46:32,205][main][DEBUG]:Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@4d5af470, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
[2017-05-19 02:46:32,309][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa2000c, packet:: clientPath:null serverPath:null finished:false header:: 3,4  replyHeader:: 3,283,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136323031fffffff366ffffffeeffffff9affffffc71525ffffffcb50425546a19ad6d61737465722e6861646f6f7010ffffffc97e18ffffff87ffffffa8ffffffa4ffffffe3ffffffc12b100183,s{216,216,1495125288124,1495125288124,0,0,0,0,66,0,216} 
[2017-05-19 02:46:32,321][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa2000c, packet:: clientPath:null serverPath:null finished:false header:: 4,8  replyHeader:: 4,283,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
[2017-05-19 02:46:32,326][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa2000c, packet:: clientPath:null serverPath:null finished:false header:: 5,4  replyHeader:: 5,283,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136323031fffffff366ffffffeeffffff9affffffc71525ffffffcb50425546a19ad6d61737465722e6861646f6f7010ffffffc97e18ffffff87ffffffa8ffffffa4ffffffe3ffffffc12b100183,s{216,216,1495125288124,1495125288124,0,0,0,0,66,0,216} 
[2017-05-19 02:46:32,328][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa2000c, packet:: clientPath:null serverPath:null finished:false header:: 6,8  replyHeader:: 6,283,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'region-in-transition,'online-snapshot,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
[2017-05-19 02:46:32,499][hconnection-0x1607219a-metaLookup-shared--pool2-t1][DEBUG]:Use SIMPLE authentication for service ClientService, sasl=false
[2017-05-19 02:46:32,516][hconnection-0x1607219a-metaLookup-shared--pool2-t1][DEBUG]:Connecting to master.hadoop/192.168.1.104:16201
[2017-05-19 02:46:32,990][main][INFO ]:Closing zookeeper sessionid=0x15c1c68faa2000c
[2017-05-19 02:46:32,991][main][DEBUG]:Closing session: 0x15c1c68faa2000c
[2017-05-19 02:46:32,991][main][DEBUG]:Closing client for session: 0x15c1c68faa2000c
[2017-05-19 02:46:33,020][main-SendThread(master.hadoop:2181)][DEBUG]:Reading reply sessionid:0x15c1c68faa2000c, packet:: clientPath:null serverPath:null finished:false header:: 7,-11  replyHeader:: 7,284,0  request:: null response:: null
[2017-05-19 02:46:33,021][main][DEBUG]:Disconnecting client for session: 0x15c1c68faa2000c
[2017-05-19 02:46:33,021][main][INFO ]:Session: 0x15c1c68faa2000c closed
[2017-05-19 02:46:33,021][main][DEBUG]:Stopping rpc client
[2017-05-19 02:46:33,021][main-SendThread(master.hadoop:2181)][DEBUG]:An exception was thrown while closing send thread for session 0x15c1c68faa2000c : Unable to read additional data from server sessionid 0x15c1c68faa2000c, likely server has closed socket
[2017-05-19 02:46:33,021][main-EventThread][INFO ]:EventThread shut down
[2017-05-19 02:46:33,038][Thread-3][DEBUG]:stopping client from cache: org.apache.hadoop.ipc.Client@5fbefaf1
[2017-05-19 02:46:33,038][Thread-3][DEBUG]:removing client from cache: org.apache.hadoop.ipc.Client@5fbefaf1
[2017-05-19 02:46:33,038][Thread-3][DEBUG]:stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@5fbefaf1
[2017-05-19 02:46:33,038][Thread-3][DEBUG]:Stopping client
